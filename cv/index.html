<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#333333 name=theme-color> <base href=/ > <link href=global.css rel=stylesheet> <link href=manifest.json rel=manifest> <link href=favicon.ico rel=icon type=image/png> <link href="https://fonts.googleapis.com/css2?family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Roboto+Mono:ital,wght@0,100;0,300;0,400;0,500;0,700;1,100;1,300;1,400;1,500;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet> <link href=client/main.2434616356.css rel=stylesheet><link href=client/cv.d7c04c83.css rel=stylesheet><link href=client/client.eff93043.css rel=stylesheet> <noscript id=sapper-head-start></noscript><title>CV — Jay Wang</title><meta content="CV — Jay Wang" name=title><meta content="Zijie Jay Wang is a Ph.D. student in the College of Computing at Georgia Tech researching the intersection of machine learning and data visualization." name=description><meta content=website property=og:type><meta content=https://zijie.wang/cv property=og:url><meta content="CV — Jay Wang" property=og:title><meta content="Zijie Jay Wang is a Ph.D. student in the College of Computing at Georgia Tech researching the intersection of machine learning and data visualization." property=og:description><meta content=https://zijie.wang/images/teasers/preview.png property=og:image><meta content=summary_large_image property=twitter:card><meta content=https://zijie.wang/cv property=twitter:url><meta content="CV — Jay Wang" property=twitter:title><meta content="Zijie Jay Wang is a Ph.D. student in the College of Computing at Georgia Tech researching the intersection of machine learning and data visualization." property=twitter:description><meta content=https://zijie.wang/images/teasers/preview.png property=twitter:image><meta content=@jay4w property=twitter:site><meta content=@jay4w property=twitter:creator><script async src="https://www.googletagmanager.com/gtag/js?id=UA-130177683-1"></script><script>window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-130177683-1'); </script><noscript id=sapper-head-end></noscript> </head> <body> <div id=sapper> <main class=svelte-1jybnva> <div class="svelte-vbultu cv"><div class="svelte-vbultu left-padding"></div> <div class="svelte-vbultu article"> <div class="svelte-vbultu row-tb"><div class="svelte-vbultu title"><a href=.>Zijie Jay Wang</a></div> <div class="svelte-vbultu line--code title-info"><div class=svelte-vbultu><a href=https://zijie.wang target=_blank>https://zijie.wang</a></div> <div class=svelte-vbultu><a href=mailto:jayw@gatech.edu target=_blank>jayw@gatech.edu</a></div></div></div> <div class="svelte-vbultu row-lr section-header"><div class=row__left><a href=/cv#education id=education><h2 class=svelte-vbultu>Education</h2></a></div> <div class="svelte-vbultu row__right--line"></div></div> <div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong"><a href=https://www.gatech.edu target=_blank>Georgia Institute of Technology</a></div> <div class="svelte-vbultu row-grid--left-line line">Ph.D. in Machine Learning </div> <div class="svelte-vbultu row-grid--left-line line">Advisor: <a href=https://www.cc.gatech.edu/~dchau target=_blank>Duen Horng (Polo) Chau</a></div> <div class="svelte-vbultu row-grid--right-line-1 line--place">Atlanta, GA</div> <div class="svelte-vbultu line--time row-grid--right-line-2">Aug. 2019 — Present</div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong"><a href=https://www.wisc.edu target=_blank>University of Wisconsin–Madison</a></div> <div class="svelte-vbultu row-grid--left-line line">Bachelor of Science (B.S.), GPA: 3.95/4.00 </div><div class="svelte-vbultu row-grid--left-line line">Majors: Computer Sciences (Honor), Statistics (Honor), Mathematics </div> <div class="svelte-vbultu row-grid--left-line line--italic">Thesis: <a href=pdf/undergrad-thesis.pdf target=_blank>Classifying T Cell Activity with Convolutional Neural Networks</a> </div> <div class="svelte-vbultu row-grid--left-line line">Advisors: <a href=https://www.biostat.wisc.edu/~gitter target=_blank>Anthony Gitter</a>, <a href=http://pages.cs.wisc.edu/~gleicher/ target=_blank>Michael Gleicher</a>, <a href=http://homepages.cae.wisc.edu/~hu/ target=_blank>Yu Hen Hu</a></div> <div class="svelte-vbultu row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-vbultu line--time row-grid--right-line-2">Sept. 2015 — May 2019</div> </div> <div class="svelte-vbultu row-lr section-header"><div class=row__left><a href=/cv#experience id=experience><h2 class=svelte-vbultu>Research Experience</h2></a></div> <div class="svelte-vbultu row__right--line"></div></div> <div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong"><a href=https://www.wisc.edu target=_blank>Georgia Institute of Technology</a></div> <div class="svelte-vbultu row-grid--left-line line--italic">Ph.D. Researcher, <a href=https://www.cs.wisc.edu target=_blank>School of Computational Science and Engineering</a></div> <div class="svelte-vbultu row-grid--left-line line">Mentor: <a href=https://www.cc.gatech.edu/~dchau target=_blank>Duen Horng (Polo) Chau</a></div> <div class="svelte-vbultu row-grid--right-line-1 line--place">Atlanta, GA</div> <div class="svelte-vbultu line--time row-grid--right-line-2">Aug. 2019 — Present</div> <div class="svelte-vbultu line--small row-grid--full-line">Member of the Polo Club of Data Science where we innovate scalable, interactive, and interpretable tools that amplify human's ability to understand and interact with billion-scale data and machine learning models. </div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong"><a href=https://www.wisc.edu target=_blank>University of Wisconsin–Madison</a></div> <div class="svelte-vbultu row-grid--left-line line--italic">Undergraduate Researcher, <a href=https://www.cs.wisc.edu target=_blank>Department of Computer Sciences</a></div> <div class="svelte-vbultu row-grid--left-line line">Mentor: <a href=http://pages.cs.wisc.edu/~gleicher/ target=_blank>Michael Gleicher</a></div> <div class="svelte-vbultu row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-vbultu line--time row-grid--right-line-2">Dec. 2018 — June 2019</div> <div class="svelte-vbultu line--small row-grid--full-line">Design and implement a visual analytics tool for recommender system resaerchers. Interactively visualized user-item rating matrix with statistics-conditioned sub-sampling to spot abnormal ratings and predictions. </div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong"><a href=https://morgridge.org target=_blank>Morgridge Institute for Research</a></div> <div class="svelte-vbultu row-grid--left-line line--italic">Undergraduate Researcher, <a href=https://morgridge.org/research/virology/ target=_blank>John W. and Jeanne M. Rowe Center for Research in Virology</a></div> <div class="svelte-vbultu row-grid--left-line line">Mentor: <a href=https://www.biostat.wisc.edu/~gitter target=_blank>Anthony Gitter</a></div> <div class="svelte-vbultu row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-vbultu line--time row-grid--right-line-2">Dec. 2017 — Aug. 2019</div> <div class="svelte-vbultu line--small row-grid--full-line">Classify T-cell and breast cancer cell types using fluorescent images with machine learning classifiers with a gradient of complexity. Interpre feature representations of each classifiers. Analyze about 1 million 5-channel cell-painting images of bone tumor cells. Explore latent space between image space and chemical molecule space. </div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong"><a href=https://www.wisc.edu target=_blank>University of Wisconsin–Madison</a></div> <div class="svelte-vbultu row-grid--left-line line--italic">Research Assistant, <a href=https://www.engr.wisc.edu/department/electrical-computer-engineering/ target=_blank>Electrical & Computer Engineering</a></div> <div class="svelte-vbultu row-grid--left-line line">Mentor: <a href=http://homepages.cae.wisc.edu/~hu/ target=_blank>Yu Hen Hu</a></div> <div class="svelte-vbultu row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-vbultu line--time row-grid--right-line-2">Feb. 2017 — Dec. 2017</div> <div class="svelte-vbultu line--small row-grid--full-line">Study how to track car driver’s head position and orientation from low-qualitytraffic video. Develop semi-automatic video annotation software with Viola-Jones frontal facedetector for training object tracking algorithms. Implement real-time face tracking algorithms on iOS devices. Train a facial reenactment model using GANs and port it to iOS device. </div> </div> <div class="svelte-vbultu row-lr section-header"><div class=row__left><a href=/cv#publications id=publications><h2 class=svelte-vbultu>Publications</h2></a></div> <div class="svelte-vbultu row__right--line"></div></div> <div class="svelte-vbultu row-tb"> <div class="svelte-vbultu line--strong"><a href=/papers/cnn-explainer target=_self>CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization</a></div> <div class="svelte-vbultu line"><a href=https://zijie.wang target=_blank style=font-weight:700>Zijie J. Wang</a>, <a href=https://www.linkedin.com/in/robert-turko/ target=_blank>Robert Turko</a>, <a href=http://oshaikh.com/ target=_blank>Omar Shaikh</a>, <a href=https://haekyu.com target=_blank>Haekyu Park</a>, <a href=https://nilakshdas.com target=_blank>Nilaksh Das</a>, <a href=https://fredhohman.com target=_blank>Fred Hohman</a>, <a href=https://minsuk.com target=_blank>Minsuk Kahng</a>, <a href=https://www.cc.gatech.edu/~dchau target=_blank>Duen Horng (Polo) Chau</a></div> <div class="svelte-vbultu line--italic"><a href=https://www.computer.org/csdl/journal/tg target=_blank>IEEE Transactions on Visualization and Computer Graphics</a> (TVCG). 2021. </div> <div class="svelte-vbultu row--icons"><a href=/papers/cnn-explainer target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#link-solid></use></svg></div> <span class=svelte-vbultu>Project</span> </a> <a href=https://poloclub.github.io/cnn-explainer/ target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#play-solid></use></svg></div> <span class=svelte-vbultu>Demo</span> </a> <a href=https://youtu.be/HnWIHWFbuUQ target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#film-solid></use></svg></div> <span class=svelte-vbultu>Video</span> </a> <a href=https://arxiv.org/abs/2004.15004 target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-vbultu>PDF</span> </a> <div class="svelte-vbultu icon-container"><a href=https://github.com/poloclub/cnn-explainer target=_self class="svelte-vbultu icon-container no-right-margin"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-vbultu>Code</span></a> <div class="svelte-vbultu star-container"><div style=display:flex>(<a href=https://github.com/poloclub/cnn-explainer/stargazers target=_self class="svelte-vbultu svg-icon" style=font-weight:500;margin-right:-3px> loading </a>)</div> </div> </div> <div class="svelte-vbultu icon-container bibtex-button"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-vbultu>BibTeX</span> </div> <div class="svelte-vbultu icon-container award"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#award-solid></use></svg></div> <span class=svelte-vbultu><a href=https://web.archive.org/web/20200505121955/https://github.com/trending target=_blank>Trending (#2) on GitHub for 3 days</a></span> </div></div> <div class="svelte-vbultu bibtex hidden"><pre class=svelte-vbultu>@article{wangCNNExplainerLearning2021,
  title = {{{CNN Explainer}}: {{Learning Convolutional Neural Networks}} with {{Interactive Visualization}}},
  shorttitle = {{{CNN Explainer}}},
  author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},
  journal={IEEE Transactions on Visualization and Computer Graphics (TVCG)},
  publisher={IEEE},
  year={2021},
}</pre> </div> </div><div class="svelte-vbultu row-tb"> <div class="svelte-vbultu line--strong"><a href=/papers/bluff target=_self>Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks</a></div> <div class="svelte-vbultu line"><a href=https://nilakshdas.com target=_blank>Nilaksh Das</a>*, <a href=https://haekyu.com target=_blank>Haekyu Park</a>*, <a href=https://zijie.wang target=_blank style=font-weight:700>Zijie J. Wang</a>, <a href=https://fredhohman.com target=_blank>Fred Hohman</a>, <a href=https://www.robfirstman.com/ target=_blank>Robert Firstman</a>, <a href=https://www.linkedin.com/in/emily-rogers-1a828598 target=_blank>Emily Rogers</a>, <a href=https://www.cc.gatech.edu/~dchau target=_blank>Duen Horng (Polo) Chau</a></div> <div class="svelte-vbultu line--italic"><a href=http://ieeevis.org/year/2020/welcome target=_blank>IEEE Visualization Conference</a> (VIS). 2020. </div> <div class="svelte-vbultu row--icons"><a href=/papers/bluff target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#link-solid></use></svg></div> <span class=svelte-vbultu>Project</span> </a> <a href=https://poloclub.github.io/bluff/ target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#play-solid></use></svg></div> <span class=svelte-vbultu>Demo</span> </a> <a href=https://arxiv.org/abs/2009.02608 target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-vbultu>PDF</span> </a> <div class="svelte-vbultu icon-container"><a href=https://github.com/poloclub/bluff target=_self class="svelte-vbultu icon-container no-right-margin"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-vbultu>Code</span></a> </div> <div class="svelte-vbultu icon-container bibtex-button"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-vbultu>BibTeX</span> </div> <div class="svelte-vbultu icon-container">( * Authors contributed equally )</div> </div> <div class="svelte-vbultu bibtex hidden"><pre class=svelte-vbultu>@article{dasBluffInteractivelyDeciphering2020,
  title={Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks},
  author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng},
  booktitle={IEEE Visualization Conference (VIS)},
  publisher={IEEE},
  year={2020}
}</pre> </div> </div><div class="svelte-vbultu row-tb"> <div class="svelte-vbultu line--strong"><a href=/papers/argo-lite target=_self>Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers</a></div> <div class="svelte-vbultu line"><a href=https://rsli.github.io/ target=_blank>Siwei Li</a>, <a href=https://www.linkedin.com/in/frank-zhou-b19515159/ target=_blank>Zhiyan Zhou</a>, <a href=https://github.com/aupadhayay3 target=_blank>Anish Upadhayay</a>, <a href=http://oshaikh.com/ target=_blank>Omar Shaikh</a>, <a href=https://www.scottfreitas.com/ target=_blank>Scott Freitas</a>, <a href=https://haekyu.com target=_blank>Haekyu Park</a>, <a href=https://zijie.wang target=_blank style=font-weight:700>Zijie J. Wang</a>, <a href=https://www.linkedin.com/in/susantaroutray/ target=_blank>Susanta Routray</a>, <a href=https://www.linkedin.com/in/mdhull/ target=_blank>Matthew Hull</a>, <a href=https://www.cc.gatech.edu/~dchau target=_blank>Duen Horng (Polo) Chau</a></div> <div class="svelte-vbultu line--italic"><a href=https://www.cikm2020.org/ target=_blank>The Conference on Information and Knowledge Management</a> (CIKM). 2020. </div> <div class="svelte-vbultu row--icons"><a href=/papers/argo-lite target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#link-solid></use></svg></div> <span class=svelte-vbultu>Project</span> </a> <a href=https://poloclub.github.io/argo-graph-lite/ target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#play-solid></use></svg></div> <span class=svelte-vbultu>Demo</span> </a> <a href=https://arxiv.org/abs/2008.11844 target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-vbultu>PDF</span> </a> <div class="svelte-vbultu icon-container"><a href=https://github.com/poloclub/argo-graph-lite target=_self class="svelte-vbultu icon-container no-right-margin"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-vbultu>Code</span></a> <div class="svelte-vbultu star-container"><div style=display:flex>(<a href=https://github.com/poloclub/argo-graph-lite/stargazers target=_self class="svelte-vbultu svg-icon" style=font-weight:500;margin-right:-3px> loading </a>)</div> </div> </div> <div class="svelte-vbultu icon-container bibtex-button"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-vbultu>BibTeX</span> </div> </div> <div class="svelte-vbultu bibtex hidden"><pre class=svelte-vbultu>@article{liArgoLiteOpenSource2020,
  title={Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers},
  author={Li, Siwei and Zhou, Zhiyan and Upadhayay, Anish and Shaikh, Omar and Freitas, Scott and Park, Haekyu and Wang, Zijie J and Routray, Susanta and Hull, Matthew and Chau, Duen Horng},
  booktitle={Proceedings of the International Conference on Information and Knowledge Management},
  year={2020},
  organization={ACM}
}</pre> </div> </div><div class="svelte-vbultu row-tb"> <div class="svelte-vbultu line--strong"><a href=/papers/people-map target=_self>PeopleMap: Visualization Tool for Mapping Out Researchers using Natural Language Processing</a></div> <div class="svelte-vbultu line"><a href=https://www.linkedin.com/in/jonsaadfalcon/ target=_blank>Jon Saad-Falcon</a>, <a href=http://oshaikh.com/ target=_blank>Omar Shaikh</a>, <a href=https://zijie.wang target=_blank style=font-weight:700>Zijie J. Wang</a>, <a href=https://austinpwright.com/ target=_blank>Austin P. Wright</a>, <a href=https://www.linkedin.com/in/sasha-richardson/ target=_blank>Sasha Richardson</a>, <a href=https://www.cc.gatech.edu/~dchau target=_blank>Duen Horng (Polo) Chau</a></div> <div class="svelte-vbultu line--italic"><a href=https://arxiv.org/abs/2006.06105 target=_blank>arXiv:2006.06105 [cs]</a>. 2020. </div> <div class="svelte-vbultu row--icons"><a href=/papers/people-map target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#link-solid></use></svg></div> <span class=svelte-vbultu>Project</span> </a> <a href=https://poloclub.github.io/people-map/ideas/ target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#play-solid></use></svg></div> <span class=svelte-vbultu>Demo</span> </a> <a href=https://arxiv.org/abs/2006.06105 target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-vbultu>PDF</span> </a> <div class="svelte-vbultu icon-container"><a href=https://github.com/poloclub/people-map target=_self class="svelte-vbultu icon-container no-right-margin"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-vbultu>Code</span></a> </div> <div class="svelte-vbultu icon-container bibtex-button"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-vbultu>BibTeX</span> </div> </div> <div class="svelte-vbultu bibtex hidden"><pre class=svelte-vbultu>@article{saad-falconPeopleMapVisualizationTool2020,
  title = {{{PeopleMap}}: {{Visualization Tool}} for {{Mapping Out Researchers}} Using {{Natural Language Processing}}},
  shorttitle = {{{PeopleMap}}},
  author = {{Saad-Falcon}, Jon and Shaikh, Omar and Wang, Zijie J. and Wright, Austin P. and Richardson, Sasha and Chau, Duen Horng},
  year = {2020},
  month = jun,
  archivePrefix = {arXiv},
  eprint = {2006.06105},
  eprinttype = {arxiv},
  journal = {arXiv:2006.06105 [cs]},
  primaryClass = {cs}
}</pre> </div> </div><div class="svelte-vbultu row-tb"> <div class="svelte-vbultu line--strong"><a href=/papers/unmask target=_self>UnMask: Adversarial Detection and Defense Through Robust Feature Alignment</a></div> <div class="svelte-vbultu line"><a href=https://www.scottfreitas.com/ target=_blank>Scott Freitas</a>, <a href=https://www.cc.gatech.edu/~schen351/ target=_blank>Shang-Tse Chen</a>, <a href=https://zijie.wang target=_blank style=font-weight:700>Zijie J. Wang</a>, <a href=https://www.cc.gatech.edu/~dchau target=_blank>Duen Horng (Polo) Chau</a></div> <div class="svelte-vbultu line--italic"><a href=https://arxiv.org/abs/2002.09576 target=_blank>arXiv:22002.09576 [cs]</a>. 2020. </div> <div class="svelte-vbultu row--icons"><a href=/papers/unmask target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#link-solid></use></svg></div> <span class=svelte-vbultu>Project</span> </a> <a href=https://arxiv.org/abs/2002.09576 target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-vbultu>PDF</span> </a> <div class="svelte-vbultu icon-container"><a href=https://github.com/unmaskd/unmask target=_self class="svelte-vbultu icon-container no-right-margin"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-vbultu>Code</span></a> </div> <div class="svelte-vbultu icon-container bibtex-button"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-vbultu>BibTeX</span> </div> </div> <div class="svelte-vbultu bibtex hidden"><pre class=svelte-vbultu>@article{freitasUnMaskAdversarialDetection2020,
  title = {{{UnMask}}: {{Adversarial Detection}} and {{Defense Through Robust Feature Alignment}}},
  shorttitle = {{{UnMask}}},
  author = {Freitas, Scott and Chen, Shang-Tse and Wang, Zijie J. and Chau, Duen Horng},
  year = {2020},
  archivePrefix = {arXiv},
  eprint = {2002.09576},
  eprinttype = {arxiv},
  journal = {arXiv:2002.09576}
}</pre> </div> </div><div class="svelte-vbultu row-tb"> <div class="svelte-vbultu line--strong"><a href=/papers/massif target=_self>Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning</a></div> <div class="svelte-vbultu line"><a href=https://nilakshdas.com target=_blank>Nilaksh Das</a>*, <a href=https://haekyu.com target=_blank>Haekyu Park</a>*, <a href=https://zijie.wang target=_blank style=font-weight:700>Zijie J. Wang</a>, <a href=https://fredhohman.com target=_blank>Fred Hohman</a>, <a href=https://www.robfirstman.com/ target=_blank>Robert Firstman</a>, <a href=https://www.linkedin.com/in/emily-rogers-1a828598 target=_blank>Emily Rogers</a>, <a href=https://www.cc.gatech.edu/~dchau target=_blank>Duen Horng (Polo) Chau</a></div> <div class="svelte-vbultu line--italic"><a href=https://dl.acm.org/doi/abs/10.1145/3334480.3382977 target=_blank>Extended Abstracts on ACM Human Factors in Computing Systems</a> (CHI). Honolulu, HI, USA, 2020. </div> <div class="svelte-vbultu row--icons"><a href=/papers/massif target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#link-solid></use></svg></div> <span class=svelte-vbultu>Project</span> </a> <a href=https://arxiv.org/abs/2001.07769 target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-vbultu>PDF</span> </a> <div class="svelte-vbultu icon-container bibtex-button"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-vbultu>BibTeX</span> </div> <div class="svelte-vbultu icon-container">( * Authors contributed equally )</div> </div> <div class="svelte-vbultu bibtex hidden"><pre class=svelte-vbultu>@inproceedings{das2020massif,
  title={Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning},
  author={Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},
  booktitle={Proceedings of the 2020 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
  publisher={ACM},
  year={2020}
}</pre> </div> </div><div class="svelte-vbultu row-tb"> <div class="svelte-vbultu line--strong"><a href=/papers/cnn-101 target=_self>CNN 101: Interactive Visual Learning for Convolutional Neural Networks</a></div> <div class="svelte-vbultu line"><a href=https://zijie.wang target=_blank style=font-weight:700>Zijie J. Wang</a>, <a href=https://www.linkedin.com/in/robert-turko/ target=_blank>Robert Turko</a>, <a href=http://oshaikh.com/ target=_blank>Omar Shaikh</a>, <a href=https://haekyu.com target=_blank>Haekyu Park</a>, <a href=https://nilakshdas.com target=_blank>Nilaksh Das</a>, <a href=https://fredhohman.com target=_blank>Fred Hohman</a>, <a href=https://minsuk.com target=_blank>Minsuk Kahng</a>, <a href=https://www.cc.gatech.edu/~dchau target=_blank>Duen Horng (Polo) Chau</a></div> <div class="svelte-vbultu line--italic"><a href=https://dl.acm.org/doi/abs/10.1145/3334480.3382899 target=_blank>Extended Abstracts on ACM Human Factors in Computing Systems</a> (CHI). Honolulu, HI, USA, 2020. </div> <div class="svelte-vbultu row--icons"><a href=/papers/cnn-101 target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#link-solid></use></svg></div> <span class=svelte-vbultu>Project</span> </a> <a href=https://youtu.be/g082-zitM7s target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#film-solid></use></svg></div> <span class=svelte-vbultu>Video</span> </a> <a href=https://arxiv.org/abs/2001.02004 target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-vbultu>PDF</span> </a> <div class="svelte-vbultu icon-container bibtex-button"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-vbultu>BibTeX</span> </div> </div> <div class="svelte-vbultu bibtex hidden"><pre class=svelte-vbultu>@inproceedings{wangCNN101Interactive2020,
  title = {{{CNN}} 101: {{Interactive}} Visual Learning for Convolutional Neural Networks},
  booktitle = {Extended Abstracts of the 2020 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},
  year = {2020},
  publisher = {{ACM}},
  place = {{Honolulu, HI, USA}}
}</pre> </div> </div><div class="svelte-vbultu row-tb"> <div class="svelte-vbultu line--strong"><a href=/papers/t-cell target=_self>Classifying T cell activity in autofluorescence intensity images with convolutional neural networks</a></div> <div class="svelte-vbultu line"><a href=https://zijie.wang target=_blank style=font-weight:700>Zijie J. Wang</a>, <a href=https://qoil.engr.tamu.edu target=_blank>Alex J. Walsh</a>, <a href=https://morgridge.org/research/medical-engineering/optical-microscopy target=_blank>Melissa C. Skala</a>, <a href=https://www.biostat.wisc.edu/~gitter target=_blank>Anthony Gitter</a></div> <div class="svelte-vbultu line--italic"><a href=https://onlinelibrary.wiley.com/journal/18640648 target=_blank>Journal of Biophotonics</a> (J. Biophotonics). 2019. </div> <div class="svelte-vbultu row--icons"><a href=/papers/t-cell target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#link-solid></use></svg></div> <span class=svelte-vbultu>Project</span> </a> <a href=https://onlinelibrary.wiley.com/doi/epdf/10.1002/jbio.201960050 target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-vbultu>PDF</span> </a> <a href=/slides/honor_thesis_symposium_2019.pdf target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#chalkboard-teacher-solid></use></svg></div> <span class=svelte-vbultu>Slides</span> </a> <div class="svelte-vbultu icon-container"><a href=https://github.com/gitter-lab/t-cell-classification target=_self class="svelte-vbultu icon-container no-right-margin"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-vbultu>Code</span></a> </div> <a href=https://doi.org/10.5281/zenodo.2640835 target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#database-solid></use></svg></div> <span class=svelte-vbultu>Data</span> </a> <div class="svelte-vbultu icon-container bibtex-button"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-vbultu>BibTeX</span> </div> </div> <div class="svelte-vbultu bibtex hidden"><pre class=svelte-vbultu>@article{wang_classifying_2019,
  title = {Classifying {T} cell activity in autofluorescence intensity images with convolutional neural networks},
  issn = {1864-063X, 1864-0648},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jbio.201960050},
  doi = {10.1002/jbio.201960050},
  language = {en},
  urldate = {2020-01-12},
  journal = {Journal of Biophotonics},
  author = {Wang, Zijie J. and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},
  month = dec,
  year = {2019}
}</pre> </div> </div><div class="svelte-vbultu row-tb"> <div class="svelte-vbultu line--strong"><a href=/papers/t-cell-poster target=_self>Classifying T cell activity with convolutional neural networks</a></div> <div class="svelte-vbultu line"><a href=https://zijie.wang target=_blank style=font-weight:700>Zijie J. Wang</a>, <a href=https://qoil.engr.tamu.edu target=_blank>Alex J. Walsh</a>, <a href=https://morgridge.org/research/medical-engineering/optical-microscopy target=_blank>Melissa C. Skala</a>, <a href=https://www.biostat.wisc.edu/~gitter target=_blank>Anthony Gitter</a></div> <div class="svelte-vbultu line--italic"><a href=https://www.iscb.org/glbio2019 target=_blank>International Society for Computational Biology Great Lakes Bioinformatics Conference</a> (ISCB GLBIO). Madison, WI, USA, 2019. </div> <div class="svelte-vbultu row--icons"><a href=/papers/t-cell-poster target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#link-solid></use></svg></div> <span class=svelte-vbultu>Project</span> </a> <a href=/pdf/19-tcell-glbio.pdf target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-vbultu>PDF</span> </a> <div class="svelte-vbultu icon-container bibtex-button"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-vbultu>BibTeX</span> </div> </div> <div class="svelte-vbultu bibtex hidden"><pre class=svelte-vbultu>@inproceedings{wang_classifying_poster_2019,
  title = {Classifying {T} cell activity with convolutional neural networks},
  language = {en},
  conference = {International Society for Computational Biology Great Lakes Bioinformatics Conference},
  author = {Wang, Zijie J. and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},
  year = {2019}
}</pre> </div> </div><div class="svelte-vbultu row-tb"> <div class="svelte-vbultu line--strong"><a href=/papers/breast-poster target=_self>Using Transfer Learning to Classify Breast Cancer Cells with Fluorescence Imaging</a></div> <div class="svelte-vbultu line"><a href=https://zijie.wang target=_blank style=font-weight:700>Zijie J. Wang</a>, <a href=https://morgridge.org/profile/tiffany-heaster/ target=_blank>Tiffany M. Heaster</a>, <a href=https://www.linkedin.com/in/quan-yin/ target=_blank>Quan Yin</a>, <a href=https://qoil.engr.tamu.edu target=_blank>Alex J. Walsh</a>, <a href=https://morgridge.org/research/medical-engineering/optical-microscopy target=_blank>Melissa C. Skala</a>, <a href=https://www.biostat.wisc.edu/~gitter target=_blank>Anthony Gitter</a></div> <div class="svelte-vbultu line--italic"><a href=https://ugradsymposium.wisc.edu target=_blank>University of Wisconsin–Madison Undergraduate Symposium</a>. 2018. </div> <div class="svelte-vbultu row--icons"><a href=/papers/breast-poster target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#link-solid></use></svg></div> <span class=svelte-vbultu>Project</span> </a> <a href=/pdf/18-breast-symposium.pdf target=_self class="svelte-vbultu icon-container"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-vbultu>PDF</span> </a> <div class="svelte-vbultu icon-container bibtex-button"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-vbultu>BibTeX</span> </div> </div> <div class="svelte-vbultu bibtex hidden"><pre class=svelte-vbultu>@inproceedings{wang_using_poster_2018,
  title = {Using Transfer Learning to Classify Breast Cancer Cells with Fluorescence Imaging},
  language = {en},
  conference = {University of Wisconsin–Madison Undergraduate Symposium},
  author = {Wang, Zijie J. and Heaster, Tiffany M. and Yin, Quan and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},
  year = {2018}
}</pre> </div> </div> <div class="svelte-vbultu row-lr section-header"><div class=row__left><a href=/cv#talks id=talks><h2 class=svelte-vbultu>Invited Talks</h2></a></div> <div class="svelte-vbultu row__right--line"></div></div> <div class="svelte-vbultu talk-block"><div class="svelte-vbultu line--strong">Classifying T cell activity with convolutional neural networks</div> <div class="svelte-vbultu row-grid"> <a href=https://honors.ls.wisc.edu/wp-content/uploads/sites/1038/2019/04/SymposiumSchedule2019email.pdf target=_self class="svelte-vbultu icon-container row-grid--left-line"><div class="svelte-vbultu line">UW–Madison Senior Honors Thesis Symposium </div></a> <div class="svelte-vbultu line--time dark row-grid--right-line-1">April 2019</div> </div> </div> <div class="svelte-vbultu row-lr section-header"><div class=row__left><a href=/cv#awards id=awards><h2 class=svelte-vbultu>Grants and Awards</h2></a></div> <div class="svelte-vbultu row__right--line"></div></div> <div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong">Dean's List</div> <div class="svelte-vbultu line--small row-grid--full-line">Achieved at least a 3.60 GPA as freshmen and sophomores, a 3.85 GPA as juniors and seniors</div> <div class="svelte-vbultu line--time dark row-grid--right-line-1" style=min-width:145px> Aug. 2015 – May 2019</div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong">University Book Store Academic Excellence Award ($1000)</div> <div class="svelte-vbultu line--small row-grid--full-line">An award recognizing undergraduate students who have completed an outstanding independent project, such as a senior thesis, at the University of Wisconsin–Madison</div> <div class="svelte-vbultu line--time dark row-grid--right-line-1" style=min-width:145px> May 2019</div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong">Honors Senior Thesis Summer Research Grant ($3000)</div> <div class="svelte-vbultu line--small row-grid--full-line">A research grant funding students to undertake more demanding and extensive senior thesis research projects</div> <div class="svelte-vbultu line--time dark row-grid--right-line-1" style=min-width:145px> June 2018</div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong">Welton Summer Sophomore Apprenticeship ($2500)</div> <div class="svelte-vbultu line--small row-grid--full-line">A research grant awarded to talented students to participate in actual, cutting-edge research</div> <div class="svelte-vbultu line--time dark row-grid--right-line-1" style=min-width:145px> June 2017</div> </div> <div class="svelte-vbultu row-lr section-header"><div class=row__left><a href=/cv#teaching id=teaching><h2 class=svelte-vbultu>Teaching</h2></a></div> <div class="svelte-vbultu row__right--line"></div></div> <div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong">Undergraduate Teaching Assistant</div> <div class="svelte-vbultu row-grid--left-line line--italic"><a href=https://www.wisc.edu/ target=_blank>University of Wisconsin–Madison</a></div> <div class="svelte-vbultu row-grid--left-line line"><a href=https://graphics.cs.wisc.edu/WP/cs559-sp2019/overview/ target=_blank>Computer Graphics (CS 559)</a> , Instructor: <a href=http://pages.cs.wisc.edu/~gleicher/ target=_blank>Michael Gleicher</a></div> <div class="svelte-vbultu row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-vbultu line--time row-grid--right-line-2">Dec. 2018 — May 2019</div> <div class="svelte-vbultu line--small row-grid--full-line">Created course notes and weekly assignments, held weekly office hours, and answered student questions on Piazza. The course had 180 undergraduates enrolled. </div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong">Notetaker</div> <div class="svelte-vbultu row-grid--left-line line--italic"><a href=https://www.wisc.edu/ target=_blank>University of Wisconsin–Madison</a></div> <div class="svelte-vbultu row-grid--left-line line"><a href=https://mcburney.wisc.edu/ target=_blank>McBurney Disability Resource Center</a> </div> <div class="svelte-vbultu row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-vbultu line--time row-grid--right-line-2">Sep. 2016 — May 2019</div> <div class="svelte-vbultu line--small row-grid--full-line">Provided clearly-written math and statistics notes to students with disability, answered course-related questions. </div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong">Academic Coach</div> <div class="svelte-vbultu row-grid--left-line line--italic"><a href=https://www.wisc.edu/ target=_blank>University of Wisconsin–Madison</a></div> <div class="svelte-vbultu row-grid--left-line line"><a href=https://diversity.wisc.edu/about/about-ddeea/ target=_blank>Division of Diversity, Equity and Educational Achievement</a> </div> <div class="svelte-vbultu row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-vbultu line--time row-grid--right-line-2">Nov. 2016 — May 2017</div> <div class="svelte-vbultu line--small row-grid--full-line">Mentored undergraduate students in DDEEA programs for Data Structure course, designed two worksheets and provided detailed solutions every week. </div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong">Tutor</div> <div class="svelte-vbultu row-grid--left-line line--italic"><a href=https://www.wisc.edu/ target=_blank>University of Wisconsin–Madison</a></div> <div class="svelte-vbultu row-grid--left-line line"><a href=https://guts.wisc.edu/ target=_blank>Greater University Tutoring Service</a> </div> <div class="svelte-vbultu row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-vbultu line--time row-grid--right-line-2">Jan. 2016 — Jan. 2017</div> <div class="svelte-vbultu line--small row-grid--full-line">Instructed peers one-on-one in programming and math problems for three hours weekly, led review sections to help students study for calculus exams. </div> </div> <div class="svelte-vbultu row-lr section-header"><div class=row__left><a href=/cv#mentoring id=mentoring><h2 class=svelte-vbultu>Mentoring</h2></a></div> <div class="svelte-vbultu row__right--line"></div></div> <div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong"><a href=https://www.linkedin.com/in/jonsaadfalcon/ target=_blank>Jon Saad-Falcon</a></div> <div class="svelte-vbultu row-grid--left-line line--italic">B.S. in Computer Science, Georgia Institute of Technology</div> <div class="svelte-vbultu line--time dark row-grid--right-line-1">May 2020 — Present</div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong"><a href=https://www.linkedin.com/in/robert-turko/ target=_blank>Robert Turko</a></div> <div class="svelte-vbultu row-grid--left-line line--italic">B.S. in Computer Science, Georgia Institute of Technology</div> <div class="svelte-vbultu line--time dark row-grid--right-line-1">Aug. 2019 — Present</div> <div class="svelte-vbultu line--small row-grid--full-line"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#award-solid></use></svg></div> <span>PURA Travel Award (2020)</span> </div> </div><div class="svelte-vbultu row-grid"> <div class="svelte-vbultu row-grid--left-line line--strong"><a href=http://oshaikh.com/ target=_blank>Omar Shaikh</a></div> <div class="svelte-vbultu row-grid--left-line line--italic">B.S. in Computer Science, Georgia Institute of Technology</div> <div class="svelte-vbultu line--time dark row-grid--right-line-1">Aug. 2019 — Present</div> <div class="svelte-vbultu line--small row-grid--full-line"><div class="svelte-vbultu svg-icon"><svg class=svelte-vbultu viewBox="0 0 100 100"><use xlink:href=/sprite.svg#award-solid></use></svg></div> <span>Outstanding Freshman Award (2020)</span> </div> </div> <div class="svelte-vbultu row-lr section-header"><div class=row__left><a href=/cv#service id=service><h2 class=svelte-vbultu>Service</h2></a></div> <div class="svelte-vbultu row__right--line"></div></div> <div class="svelte-vbultu line--strong">Reviewer</div> <div class="svelte-vbultu line">IEEE Visual Analytics Science and Technology (<span style=font-weight:500>VAST</span>) <a href=http://ieeevis.org/year/2020/welcome target=_self>2020 </a> </div><div class="svelte-vbultu line">ACM Conference on Information and Knowledge Management (<span style=font-weight:500>CIKM</span>) <a href=https://www.cikm2020.org/ target=_self>2020 </a> </div> <div class="svelte-vbultu line--strong" style=margin-top:15px>Member</div> <div class="svelte-vbultu row-grid" style=margin-bottom:0><div class="svelte-vbultu row-grid--left-line line"><a href=https://www.ieee.org/ target=_self>Institute of Electrical and Electronics Engineers (<span style=font-weight:500>IEEE</span>) </a></div> <div class="svelte-vbultu line--time dark row-grid--right-line-1">July 2019 — Present</div> </div><div class="svelte-vbultu row-grid" style=""><div class="svelte-vbultu row-grid--left-line line"><a href=https://www.acm.org/ target=_self>Association for Computing Machinery (<span style=font-weight:500>ACM</span>) </a></div> <div class="svelte-vbultu line--time dark row-grid--right-line-1">Dec. 2019 — Present</div> </div> <div class="svelte-vbultu row-lr section-header"><div class=row__left><a href=/cv#skills id=skills><h2 class=svelte-vbultu>Skills</h2></a></div> <div class="svelte-vbultu row__right--line"></div></div> <div class="svelte-vbultu row-lr" style=margin-bottom:.5rem><div class=row__left><div class="svelte-vbultu line--strong">Programming</div> <div class="svelte-vbultu line">Python, JavaScript, Swift, R, Julia, PyTorch, TensorFlow, Keras, HTML, CSS, LaTeX, SQL, C++, Git </div></div> </div><div class="svelte-vbultu row-lr" style=margin-bottom:.5rem><div class=row__left><div class="svelte-vbultu line--strong">Design</div> <div class="svelte-vbultu line">Affinity Designer, Affinity Photo, Final Cut Pro, Sketch, Keynote, Illustrator, Photoshop </div></div> </div><div class="svelte-vbultu row-lr" style=""><div class=row__left><div class="svelte-vbultu line--strong">HCI</div> <div class="svelte-vbultu line">Think-aloud protocol, User Personas, Rapid Paper Prototyping, Affinity Diagraming </div></div> </div> <div class="svelte-vbultu row-lr section-header"><div class=row__left><a href=/cv#references id=references><h2 class=svelte-vbultu>References</h2></a></div> <div class="svelte-vbultu row__right--line"></div></div> <div class="svelte-vbultu row"><div class="svelte-vbultu row-item"> <div class="svelte-vbultu line no-wrap"><a href=https://cc.gatech.edu/~dchau/ target=_self style=font-weight:700;font-size:1.2em>Polo Chau</a>, Associate Professor</div> <div class="svelte-vbultu line no-wrap"><a href=null target=_blank>School of Computational Science and Engineering</a></div> <div class="svelte-vbultu line--italic no-wrap"><a href=null target=_blank>Georgia Institute of Technology</a></div> <div class="svelte-vbultu line--code"><a href=https://cc.gatech.edu/~dchau/ target=_blank>https://cc.gatech.edu/~dchau/</a></div> </div><div class="svelte-vbultu row-item"> <div class="svelte-vbultu line no-wrap"><a href=https://www.biostat.wisc.edu/~gitter/ target=_self style=font-weight:700;font-size:1.2em>Anghony Gitter</a>, Assistant Professor</div> <div class="svelte-vbultu line no-wrap"><a href=https://www.biostat.wisc.edu/ target=_blank>Department of Biostatistics and Medical Informatics</a></div> <div class="svelte-vbultu line--italic no-wrap"><a href=https://www.wisc.edu target=_blank>University of Wisconsin–Madison</a></div> <div class="svelte-vbultu line--code"><a href=https://www.biostat.wisc.edu/~gitter/ target=_blank>https://www.biostat.wisc.edu/~gitter/</a></div> </div><div class="svelte-vbultu row-item"> <div class="svelte-vbultu line no-wrap"><a href=http://pages.cs.wisc.edu/~gleicher/ target=_self style=font-weight:700;font-size:1.2em>Michael Gleicher</a>, Professor</div> <div class="svelte-vbultu line no-wrap"><a href=https://www.cs.wisc.edu/ target=_blank>Department of Computer Sciences</a></div> <div class="svelte-vbultu line--italic no-wrap"><a href=https://www.wisc.edu target=_blank>University of Wisconsin–Madison</a></div> <div class="svelte-vbultu line--code"><a href=http://pages.cs.wisc.edu/~gleicher/ target=_blank>http://pages.cs.wisc.edu/~gleicher/</a></div> </div></div></div> <div class="svelte-vbultu right-padding"></div></div></main> </div> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,(function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa){return {data:{people:{"Zijie J. Wang":{url:"https:\u002F\u002Fzijie.wang",isMe:f},"Anthony Gitter":{url:"https:\u002F\u002Fwww.biostat.wisc.edu\u002F~gitter"},"Melissa C. Skala":{url:"https:\u002F\u002Fmorgridge.org\u002Fresearch\u002Fmedical-engineering\u002Foptical-microscopy"},"Alex J. Walsh":{url:"https:\u002F\u002Fqoil.engr.tamu.edu"},"Duen Horng (Polo) Chau":{url:y},"Polo Chau":{url:y},"Fred Hohman":{url:"https:\u002F\u002Ffredhohman.com"},"Minsuk Kahng":{url:"https:\u002F\u002Fminsuk.com"},"Haekyu Park":{url:"https:\u002F\u002Fhaekyu.com"},"Nilaksh Das":{url:"https:\u002F\u002Fnilakshdas.com"},"Robert Turko":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Frobert-turko\u002F"},"Omar Shaikh":{url:"http:\u002F\u002Foshaikh.com\u002F"},"Michael Gleicher":{url:z},"Yu Hen Hu":{url:"http:\u002F\u002Fhomepages.cae.wisc.edu\u002F~hu\u002F"},"Tiffany M. Heaster":{url:"https:\u002F\u002Fmorgridge.org\u002Fprofile\u002Ftiffany-heaster\u002F"},"Quan Yin":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fquan-yin\u002F"},"Emily Rogers":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Femily-rogers-1a828598"},"Robert Firstman":{url:"https:\u002F\u002Fwww.robfirstman.com\u002F"},"Scott Freitas":{url:"https:\u002F\u002Fwww.scottfreitas.com\u002F"},"Shang-Tse Chen":{url:"https:\u002F\u002Fwww.cc.gatech.edu\u002F~schen351\u002F"},"Jon Saad-Falcon":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fjonsaadfalcon\u002F"},"Austin P. Wright":{url:"https:\u002F\u002Faustinpwright.com\u002F"},"Sasha Richardson":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fsasha-richardson\u002F"},"Siwei Li":{url:"https:\u002F\u002Frsli.github.io\u002F"},"Zhiyan Zhou":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Ffrank-zhou-b19515159\u002F"},"Anish Upadhayay":{url:"https:\u002F\u002Fgithub.com\u002Faupadhayay3"},"Susanta Routray":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fsusantaroutray\u002F"},"Matthew Hull":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fmdhull\u002F"}},education:[{school:t,schoolURL:"https:\u002F\u002Fwww.gatech.edu",place:A,timeStart:k,timeEnd:g,descriptions:["Ph.D. in Machine Learning"],advisors:[b]},{school:c,schoolURL:i,place:d,timeStart:"Sept. 2015",timeEnd:o,descriptions:["Bachelor of Science (B.S.), GPA: 3.95\u002F4.00","Majors: Computer Sciences (Honor), Statistics (Honor), Mathematics"],advisors:[l,p,B],thesis:{title:"Classifying T Cell Activity with Convolutional Neural Networks",file:"pdf\u002Fundergrad-thesis.pdf"}}],experience:[{institution:t,place:A,position:"Ph.D. Researcher",group:C,timeStart:k,timeEnd:g,mentors:[b],description:"Member of the Polo Club of Data Science where we innovate scalable, interactive, and interpretable tools that amplify human's ability to understand and interact with billion-scale data and machine learning models.\n",institutionURL:i,groupURL:D,type:q},{institution:c,place:d,position:E,group:F,timeStart:G,timeEnd:"June 2019",mentors:[p],description:"Design and implement a visual analytics tool for recommender system resaerchers. Interactively visualized user-item rating matrix with statistics-conditioned sub-sampling to spot abnormal ratings and predictions.\n",institutionURL:i,groupURL:D,type:q},{institution:"Morgridge Institute for Research",place:d,position:E,group:"John W. and Jeanne M. Rowe Center for Research in Virology",timeStart:H,timeEnd:k,mentors:[l],description:"Classify T-cell and breast cancer cell types using fluorescent images with machine learning classifiers with a gradient of complexity. Interpre feature representations of each classifiers. Analyze about 1 million 5-channel cell-painting images of bone tumor cells. Explore latent space between image space and chemical molecule space.\n",institutionURL:"https:\u002F\u002Fmorgridge.org",groupURL:"https:\u002F\u002Fmorgridge.org\u002Fresearch\u002Fvirology\u002F",type:q},{institution:c,place:d,position:"Research Assistant",group:"Electrical & Computer Engineering",timeStart:"Feb. 2017",timeEnd:H,mentors:[B],description:"Study how to track car driver’s head position and orientation from low-qualitytraffic video. Develop semi-automatic video annotation software with Viola-Jones frontal facedetector for training object tracking algorithms. Implement real-time face tracking algorithms on iOS devices. Train a facial reenactment model using GANs and port it to iOS device.\n",institutionURL:i,groupURL:"https:\u002F\u002Fwww.engr.wisc.edu\u002Fdepartment\u002Felectrical-computer-engineering\u002F",type:q}],publication:[{id:I,title:"CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization",authors:[a,u,m,h,j,r,J,b],venue:"IEEE Transactions on Visualization and Computer Graphics",venueURL:"https:\u002F\u002Fwww.computer.org\u002Fcsdl\u002Fjournal\u002Ftg",venueShort:"TVCG",year:2021,url:"\u002Fpapers\u002Fcnn-explainer",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.15004",repo:"poloclub\u002Fcnn-explainer",showStar:f,awards:[{name:"Trending (#2) on GitHub for 3 days",url:"https:\u002F\u002Fweb.archive.org\u002Fweb\u002F20200505121955\u002Fhttps:\u002F\u002Fgithub.com\u002Ftrending"}],video:"https:\u002F\u002Fyoutu.be\u002FHnWIHWFbuUQ",demo:"https:\u002F\u002Fpoloclub.github.io\u002Fcnn-explainer\u002F",abstract:"Deep learning's great success motivates many practitioners and students to\nlearn about this exciting technology. However, it is often challenging for\nbeginners to take their first step due to the complexity of understanding\nand applying deep learning. We present CNN Explainer, an interactive\nvisualization tool designed for non-experts to learn and examine\nconvolutional neural networks (CNNs), a foundational deep learning model\narchitecture. Our tool addresses key challenges that novices face while\nlearning about CNNs, which we identify from interviews with instructors and\na survey with past students. CNN Explainer tightly integrates a model\noverview that summarizes a CNN's structure, and on-demand, dynamic visual\nexplanation views that help users understand the underlying components of\nCNNs. Through smooth transitions across levels of abstraction, our tool\nenables users to inspect the interplay between low-level mathematical\noperations and high-level model structures. A qualitative user study shows\nthat CNN Explainer helps users more easily understand the inner workings of\nCNNs, and is engaging and enjoyable to use. We also derive design lessons\nfrom our study. Developed using modern web technologies, CNN Explainer runs\nlocally in users' web browsers without the need for installation or\nspecialized hardware, broadening the public's education access to modern\ndeep learning techniques.",crownCaption:"With CNN Explainer, learners can visually examine how Convolutional Neural\nNetworks (CNNs) transform input images into classification predictions\n(e.g., predicting espresso for an image of a coffee cup), and interactively\nlearn about their underlying mathematical operations. In this example, a\nlearner uses CNN Explainer to understand how convolutional layers work\nthrough three tightly integrated views, each explaining the convolutional\nprocess in increasing levels of detail. (A) The Overview visualizes a CNN\narchitecture where each neuron is encoded as a square with a heatmap\nrepresenting the neuron’s output, and each edge connects the neuron with its\ncorresponding inputs and outputs. (B) Clicking a neuron reveals how its\nactivations are computed by the previous layer’s neurons, displaying the\noften-overlooked intermediate computation through animations of sliding\nkernels. (C) The Convolutional Interactive Formula View allows users to\ninteractively inspect the underlying mathematics of the dot-product\noperation core to convolution, through hovering the 3×3 kernel over the\ninput, and interactively studying the corresponding output. For clarity,\nvisibility of Overview and annotation text is improved, and the overlay is\nre-positioned.",bibtex:"@article{wangCNNExplainerLearning2021,\n  title = {{{CNN Explainer}}: {{Learning Convolutional Neural Networks}} with {{Interactive Visualization}}},\n  shorttitle = {{{CNN Explainer}}},\n  author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},\n  journal={IEEE Transactions on Visualization and Computer Graphics (TVCG)},\n  publisher={IEEE},\n  year={2021},\n}"},{id:K,title:"Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks",authors:[j,h,a,r,L,M,b],equals:[j,h],venue:"IEEE Visualization Conference",venueURL:N,venueShort:"VIS",year:e,url:"\u002Fpapers\u002Fbluff",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2009.02608",repo:"poloclub\u002Fbluff",showStar:false,demo:"https:\u002F\u002Fpoloclub.github.io\u002Fbluff\u002F",abstract:"Deep neural networks (DNNs) are now commonly used in many domains. However,\nthey are vulnerable to adversarial attacks: carefully crafted perturbations\non data inputs that can fool a model into making incorrect predictions.\nDespite significant research on developing DNN attack and defense\ntechniques, people still lack an understanding of how such attacks penetrate\na model's internals. We present Bluff, an interactive system for\nvisualizing, characterizing, and deciphering adversarial attacks on\nvision-based neural networks. Bluff allows people to flexibly visualize and\ncompare the activation pathways for benign and attacked images, revealing\nmechanisms that adversarial attacks employ to inflict harm on a model. Bluff\nis open-sourced and runs in modern web browsers. ",crownCaption:"With Bluff, users interactively visualize how adversarial attacks penetrate\na deep neural network to induce incorrect outcomes. Here, a user inspects\nwhy Inception V1 misclassifies adversarial giant panda images, crafted by\nthe Projected Gradient Descent (PGD) attack, as armadillo. PGD successfully\nperturbed pixels to induce the “brown bird” feature, an appearance more\nlikely shared by an armadillo (small, roundish, brown body) than a panda,\nactivating more features that contribute to the armadillo (mis)classification\n(e.g., “scales,” “bumps,” “mesh”). The adversarial pathways, formed by these\nneurons and their connections, overwhelm the benign panda pathways and lead\nto the ultimate misclassification. (A) Control Side bar allows users to\nspecify what data is to be included and highlighted. (B) Graph Summary View\nvisualizes pathways most activated or changed by an attack as a network\ngraph of neurons (each labeled by the channel ID in its layer) and their\nconnections. When hovering over a neuron, (C) Detail View displays its\nfeature visualization, representative dataset examples, and activation\npatterns over attack strengths.",bibtex:"@article{dasBluffInteractivelyDeciphering2020,\n  title={Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks},\n  author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng},\n  booktitle={IEEE Visualization Conference (VIS)},\n  publisher={IEEE},\n  year={2020}\n}"},{id:"argo-lite",title:"Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers",authors:["Siwei Li","Zhiyan Zhou","Anish Upadhayay",m,O,h,a,"Susanta Routray","Matthew Hull",b],venue:"The Conference on Information and Knowledge Management",venueShort:P,venueURL:Q,year:e,url:"\u002Fpapers\u002Fargo-lite",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2008.11844",repo:"poloclub\u002Fargo-graph-lite",showStar:f,type:n,demo:"https:\u002F\u002Fpoloclub.github.io\u002Fargo-graph-lite\u002F",abstract:"Graph data have become increasingly common. Visualizing them helps people\nbetter understand relations among entities. Unfortunately, existing graph\nvisualization tools are primarily designed for single-person desktop use,\noffering limited support for interactive web-based exploration and online\ncollaborative analysis. To address these issues, we have developed Argo\nLite, a new in-browser interactive graph exploration and visualization tool.\nArgo Lite enables users to publish and share interactive graph\nvisualizations as URLs and embedded web widgets. Users can explore graphs\nincrementally by adding more related nodes, such as highly cited papers\ncited by or citing a paper of interest in a citation network. Argo Lite\nworks across devices and platforms, leveraging WebGL for high-performance\nrendering. Argo Lite has been used by over 1,000 students at Georgia Tech's\nData and Visual Analytics class. Argo Lite may serve as a valuable\nopen-source tool for advancing multiple CIKM research areas, from data\npresentation, to interfaces for information systems and more.",crownCaption:"Argo Lite visualizing a citation network of recent COVID-19 publications.\nArgo Lite users can explore graphs incrementally by adding more\nrelated papers (e.g., highly cited papers cited by or citing a paper of\ninterest) to the visualization. Using WebGL for high-performance\ncross-platform graph rendering, Argo Lite runs in all modern web\nbrowsers without requiring any installation.",bibtex:"@article{liArgoLiteOpenSource2020,\n  title={Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers},\n  author={Li, Siwei and Zhou, Zhiyan and Upadhayay, Anish and Shaikh, Omar and Freitas, Scott and Park, Haekyu and Wang, Zijie J and Routray, Susanta and Hull, Matthew and Chau, Duen Horng},\n  booktitle={Proceedings of the International Conference on Information and Knowledge Management},\n  year={2020},\n  organization={ACM}\n}"},{id:"people-map",title:"PeopleMap: Visualization Tool for Mapping Out Researchers using Natural Language Processing",authors:[R,m,a,"Austin P. Wright","Sasha Richardson",b],venue:"arXiv:2006.06105 [cs]",venueURL:S,year:e,url:"\u002Fpapers\u002Fpeople-map",pdf:S,repo:"poloclub\u002Fpeople-map",type:n,demo:"https:\u002F\u002Fpoloclub.github.io\u002Fpeople-map\u002Fideas\u002F",abstract:"Discovering research expertise at institutions can be a difficult task.\nManually curated university directories easily become out of date and they\noften lack the information necessary for understanding a researcher's\ninterests and past work, making it harder to explore the diversity of\nresearch at an institution and identify research talents. This results in\nlost opportunities for both internal and external entities to discover new\nconnections and nurture research collaboration. To solve this problem, we\nhave developed PeopleMap, the first interactive, open-source, web-based tool\nthat visually \"maps out\" researchers based on their research interests and\npublications by leveraging embeddings generated by natural language\nprocessing (NLP) techniques. PeopleMap provides a new engaging way for\ninstitutions to summarize their research talents and for people to discover\nnew connections. The platform is developed with ease-of-use and\nsustainability in mind. Using only researchers' Google Scholar profiles as\ninput, PeopleMap can be readily adopted by any institution using its\npublicly-accessible repository and detailed documentation.",crownCaption:"PeopleMap visually maps out researchers based on their research interests\nand publications. Here, a PeopleMap user is exploring the research topics of\nthe faculty members at the Institute of Data Engineering and Science (IDEaS)\nat Georgia Tech (https:\u002F\u002Fpoloclub.github.io\u002Fpeople-map\u002Fideas\u002F) A. Map View\nvisualizes the embedding of researchers generated using their research\ntopics and publication data, with each dot representing a researcher. B.\nResearch Query allows users to search for researchers and query areas of\nstudy, allowing the user to both locate specific individuals and see the\nresearchers most associated with a queried field in the Map View. C.\nResearcher View shows the detailed information (e.g., affiliation,\ncitations, interests) of a researcher highlighted in Map View. D. Control\nPanel allows users to adjust the hyperparameters of the Map View\nvisualization (e.g., show research names and cluster information).",bibtex:"@article{saad-falconPeopleMapVisualizationTool2020,\n  title = {{{PeopleMap}}: {{Visualization Tool}} for {{Mapping Out Researchers}} Using {{Natural Language Processing}}},\n  shorttitle = {{{PeopleMap}}},\n  author = {{Saad-Falcon}, Jon and Shaikh, Omar and Wang, Zijie J. and Wright, Austin P. and Richardson, Sasha and Chau, Duen Horng},\n  year = {2020},\n  month = jun,\n  archivePrefix = {arXiv},\n  eprint = {2006.06105},\n  eprinttype = {arxiv},\n  journal = {arXiv:2006.06105 [cs]},\n  primaryClass = {cs}\n}"},{id:T,title:"UnMask: Adversarial Detection and Defense Through Robust Feature Alignment",authors:[O,"Shang-Tse Chen",a,b],venue:"arXiv:22002.09576 [cs]",venueURL:U,year:e,url:"\u002Fpapers\u002Funmask",pdf:U,repo:"unmaskd\u002Funmask",type:n,abstract:"Deep learning models are being integrated into a wide range of high-impact,\nsecurity-critical systems, from self-driving cars to medical diagnosis.\nHowever, recent research has demonstrated that many of these deep learning\narchitectures are vulnerable to adversarial attacks--highlighting the vital\nneed for defensive techniques to detect and mitigate these attacks before\nthey occur. To combat these adversarial attacks, we developed UnMask, an\nadversarial detection and defense framework based on robust feature\nalignment. The core idea behind UnMask is to protect these models by\nverifying that an image's predicted class (\"bird\") contains the expected\nrobust features (e.g., beak, wings, eyes). For example, if an image is\nclassified as \"bird\", but the extracted features are wheel, saddle and\nframe, the model may be under attack. UnMask detects such attacks and\ndefends the model by rectifying the misclassification, re-classifying the\nimage based on its robust features. Our extensive evaluation shows that\nUnMask (1) detects up to 96.75% of attacks, with a false positive rate of\n9.66% and (2) defends the model by correctly classifying up to 93% of\nadversarial images produced by the current strongest attack, Projected\nGradient Descent, in the gray-box setting. UnMask provides significantly\nbetter protection than adversarial training across 8 attack vectors,\naveraging 31.18% higher accuracy. Our proposed method is architecture\nagnostic and fast. We open source the code repository and data with this\npaper: https:\u002F\u002Fgithub.com\u002Funmaskd\u002Funmask. ",crownShowBorder:f,crownCaption:"UnMask Framework Overview. UnMask combats adversarial attacks (in\nred) through extracting robust features from an image (“Bicycle” at top), and\ncomparing them to expected features of the classification (“Bird” at bottom)\nfrom the unprotected model. Low feature overlap signals an\nattack. UnMask rectifies misclassification using the image’s extracted\nfeatures. Our approach detects 96.75% of gray-box attacks (at 9.66% false\npositive rate) and defends the model by correctly classifying up to 93%\nof adversarial images crafted by Projected Gradient Descent (PGD).",bibtex:"@article{freitasUnMaskAdversarialDetection2020,\n  title = {{{UnMask}}: {{Adversarial Detection}} and {{Defense Through Robust Feature Alignment}}},\n  shorttitle = {{{UnMask}}},\n  author = {Freitas, Scott and Chen, Shang-Tse and Wang, Zijie J. and Chau, Duen Horng},\n  year = {2020},\n  archivePrefix = {arXiv},\n  eprint = {2002.09576},\n  eprinttype = {arxiv},\n  journal = {arXiv:2002.09576}\n}"},{id:"massif",title:"Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning",authors:[j,h,a,r,L,M,b],equals:[j,h],venue:V,venueURL:"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fabs\u002F10.1145\u002F3334480.3382977",venueShort:W,location:X,year:e,url:"\u002Fpapers\u002Fmassif",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2001.07769",type:n,abstract:"Deep neural networks (DNNs) are increasingly powering high-stakes\napplications such as autonomous cars and healthcare; however, DNNs are often\ntreated as \"black boxes\" in such applications. Recent research has also\nrevealed that DNNs are highly vulnerable to adversarial attacks, raising\nserious concerns over deploying DNNs in the real world. To overcome these\ndeficiencies, we are developing Massif, an interactive tool for deciphering\nadversarial attacks. Massif identifies and interactively visualizes neurons\nand their connections inside a DNN that are strongly activated or suppressed\nby an adversarial attack. Massif provides both a high-level, interpretable\noverview of the effect of an attack on a DNN, and a low-level, detailed\ndescription of the affected neurons. Massif's tightly coupled views help\npeople better understand which input features are most vulnerable and\nimportant for correct predictions.",crownCaption:"The MASSIF interface. A user Hailey is studying the targeted Fast Gradient\nMethod (FGM) attack performed on the InceptionV1 model. Using the control\npanel (A), she selects “giant panda” as the benign class and “armadillo” as\nthe attack target class. MASSIF generates an attribution graph (B), which\nshows Hailey the neurons within the network that are suppressed in the\nattacked images (B1, blue), shared by both benign and attacked images (B2,\npurple), and emphasized only in the attacked images (B3, orange). Each\nneuron is represented by a node and its feature visualization (C). Hovering\nover any neuron displays example dataset patches that maximally activate\nthe neuron, providing stronger evidence for what a neuron has learned to\ndetect. Hovering over a neuron also highlights its most influential\nconnections from the previous layer (D), allowing Hailey to determine where\nin the network the prediction diverges from the benign class to the attacked\nclass.",bibtex:"@inproceedings{das2020massif,\n  title={Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning},\n  author={Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},\n  booktitle={Proceedings of the 2020 CHI Conference Extended Abstracts on Human Factors in Computing Systems},\n  publisher={ACM},\n  year={2020}\n}"},{id:"cnn-101",title:"CNN 101: Interactive Visual Learning for Convolutional Neural Networks",authors:[a,u,m,h,j,r,J,b],venue:V,venueShort:W,location:X,venueURL:"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fabs\u002F10.1145\u002F3334480.3382899",year:e,url:"\u002Fpapers\u002Fcnn-101",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2001.02004",type:n,video:"https:\u002F\u002Fyoutu.be\u002Fg082-zitM7s",crownCaption:"The Overview (A) visualizes activation maps of all neurons as heatmaps\nconnected with edges. When user clicks a convolutional neuron in (A), the\nview transitions to the Convolutional Intermediate View (A=\u003EB).The Flatten\nIntermediate View appears when an output neuron is selected instead\n(A=\u003EC). (B) demonstrates the relationship between selected convolutional\nneuron and its previous layer. (B) transitions to the Detail View which illustrates\nthe convolution operation on selected input neuron (B=\u003ED). (C) explains\nthe flatten layer between the second last layer and output layer.",abstract:"The success of deep learning solving previously-thought hard problems has\ninspired many non-experts to learn and understand this exciting technology.\nHowever, it is often challenging for learners to take the first steps due to\nthe complexity of deep learning models. We present our ongoing work, CNN\n101, an interactive visualization system for explaining and teaching\nconvolutional neural networks. Through tightly integrated interactive views,\nCNN 101 offers both overview and detailed descriptions of how a model works.\nBuilt using modern web technologies, CNN 101 runs locally in users' web\nbrowsers without requiring specialized hardware, broadening the public's\neducation access to modern deep learning techniques. ",bibtex:"@inproceedings{wangCNN101Interactive2020,\n  title = {{{CNN}} 101: {{Interactive}} Visual Learning for Convolutional Neural Networks},\n  booktitle = {Extended Abstracts of the 2020 {{CHI}} Conference on Human Factors in Computing Systems},\n  author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},\n  year = {2020},\n  publisher = {{ACM}},\n  place = {{Honolulu, HI, USA}}\n}"},{id:"t-cell",title:"Classifying T cell activity in autofluorescence intensity images with convolutional neural networks",authors:[a,v,w,l],venue:"Journal of Biophotonics",venueShort:"J. Biophotonics",venueURL:"https:\u002F\u002Fonlinelibrary.wiley.com\u002Fjournal\u002F18640648",year:Y,url:"\u002Fpapers\u002Ft-cell",pdf:"https:\u002F\u002Fonlinelibrary.wiley.com\u002Fdoi\u002Fepdf\u002F10.1002\u002Fjbio.201960050",slides:"\u002Fslides\u002Fhonor_thesis_symposium_2019.pdf",repo:"gitter-lab\u002Ft-cell-classification",showStar:"flase",data:"https:\u002F\u002Fdoi.org\u002F10.5281\u002Fzenodo.2640835",type:"journal",crownShowBorder:f,crownCaption:"Our T cell image data processing workflow.",abstract:"The importance of T cells in immunotherapy has motivated developing\ntechnologies to better characterize T cells and improve therapeutic\nefficacy. One specific objective is assessing antigen-induced T cell\nactivation because only functionally active T cells are capable of killing\nthe desired targets. Autofluorescence imaging can distinguish T cell\nactivity states of individual cells in a non-destructive manner by detecting\nendogenous changes in metabolic co-enzymes such as NAD(P)H. However,\nrecognizing robust patterns of T cell activity is computationally\nchallenging in the absence of exogenous labels or information-rich\nautofluorescence lifetime measurements. We demonstrate that advanced machine\nlearning can accurately classify T cell activity from NAD(P)H intensity\nimages and that those image-based signatures transfer across human donors.\nUsing a dataset of 8,260 cropped single-cell images from six donors, we\nmeticulously evaluate multiple machine learning models. These range from\ntraditional models that represent images using summary statistics or extract\nimage features with CellProfiler to deep convolutional neural networks\n(CNNs) pre-trained on general non-biological images. Adapting pre-trained\nCNNs for the T cell activity classification task provides substantially\nbetter performance than traditional models or a simple CNN trained with the\nautofluorescence images alone. Visualizing the images with dimension\nreduction provides intuition into why the CNNs achieve higher accuracy than\nother approaches. However, we observe that fine-tuning all layers of the\npre-trained CNN does not provide a classification performance boost\ncommensurate with the additional computational cost. Our software detailing\nour image processing and model training pipeline is available as Jupyter\nnotebooks at https:\u002F\u002Fgithub.com\u002Fgitter-lab\u002Ft-cell-classification.",bibtex:"@article{wang_classifying_2019,\n  title = {Classifying {T} cell activity in autofluorescence intensity images with convolutional neural networks},\n  issn = {1864-063X, 1864-0648},\n  url = {https:\u002F\u002Fonlinelibrary.wiley.com\u002Fdoi\u002Fabs\u002F10.1002\u002Fjbio.201960050},\n  doi = {10.1002\u002Fjbio.201960050},\n  language = {en},\n  urldate = {2020-01-12},\n  journal = {Journal of Biophotonics},\n  author = {Wang, Zijie J. and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},\n  month = dec,\n  year = {2019}\n}"},{id:"t-cell-poster",title:Z,authors:[a,v,w,l],venue:"International Society for Computational Biology Great Lakes Bioinformatics Conference",venueShort:"ISCB GLBIO",venueURL:"https:\u002F\u002Fwww.iscb.org\u002Fglbio2019",location:"Madison, WI, USA",year:Y,url:"\u002Fpapers\u002Ft-cell-poster",pdf:"\u002Fpdf\u002F19-tcell-glbio.pdf",code:"https:\u002F\u002Fgithub.com\u002Fgitter-lab\u002Ft-cell-classification",type:_,crownShowBorder:f,crownCaption:"Poster presented at the International Society for Computational Biology\nGreat Lakes Bioinformatics Conference (ISCB GLBIO).",abstract:"T cell activity state is an important component of immunotherapy efficacy in\nclinical cancer treatment. However, current image-based activity profiling\nmethods destroy cells and require exogenous contrast agents, making them\nunsuitable for clinical applications. In this study, we use non-destructive,\nT cell autofluorescence microscopy images to measure NAD(P)H intensity and\nclassify individual T cells as activated or quiescent. We assess five\nmachine learning methods of increasing complexity, ranging from linear\nclassifiers to deep convolutional neural networks pre-trained on generic\nimages. To evaluate these models and determine whether they are accurate\nacross different human T cell donors, we designed a meticulous nested\ncross-validation scheme to tune and test each model. A retrained\nconvolutional neural network, the most advanced model, achieved an average\naccuracy of 91.4% when classifying quiescent and activated T cells.\nImportantly, it gave 98% accuracy on an independent donor that was held out\nuntil all aspects of the training and tuning procedures were finalized. This\nshows that autofluorescence microscopy with a state-of-the-art image\nclassification algorithm is a powerful tool for label-free and\nnon-destructive assessment of T cell activity state, even when only NAD(P)H\nintensity is provided as the input feature. In addition, our high-throughput\nhyperparameter selection results give empirical insights on practical deep\nlearning deployment with microscopy image data. Similarly, the model\ncomparisons examined the tradeoff between performance and model complexity,\nwhich provides alternative methods that are suitable when computing resource\nare limited. We observe that retraining more layers in a pre-trained\nconvolutional neural network does not bring performance improvements that\njustify the high computational costs. Finally, we are preparing all of our\ncode in Jupyter notebooks with reproducible examples of image processing and\nclassification. These comprehensive notebooks serve as an instructional tool\nfor readers who are not familiar with machine learning application on\nmicroscopy images.",bibtex:"@inproceedings{wang_classifying_poster_2019,\n  title = {Classifying {T} cell activity with convolutional neural networks},\n  language = {en},\n  conference = {International Society for Computational Biology Great Lakes Bioinformatics Conference},\n  author = {Wang, Zijie J. and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},\n  year = {2019}\n}"},{id:"breast-poster",title:"Using Transfer Learning to Classify Breast Cancer Cells with Fluorescence Imaging",authors:[a,"Tiffany M. Heaster","Quan Yin",v,w,l],venue:"University of Wisconsin–Madison Undergraduate Symposium","venue-short":"",venueURL:"https:\u002F\u002Fugradsymposium.wisc.edu",year:2018,url:"\u002Fpapers\u002Fbreast-poster",pdf:"\u002Fpdf\u002F18-breast-symposium.pdf",type:_,abstract:"Studying tumor heterogeneity by analyzing protein or gene expression levels\nover thousands of cells is very challenging. In this project, we instead use\na transfer learning approach to classify cancer cell types solely based on\nfluorescence imaging. We used images of two types of breast cancer cell\nlines – MDA-MB-231 and SKBr3 – to partially retrain a deep convolutional\nneural network Inception v3, which was pre-trained on 10 million natural\nimages with over 400 categories. We hypothesize features extracted from\ngeneral pictures by a deep neural network are portable to classify breast\ncancer cell types. The ability to recognize distinct cell types within\ntumors would provide a powerful tool for analyzing clinical samples.",crownCaption:"Poster presented at the University of Wisconsin–Madison Undergraduate Symposium.",crownShowBorder:f,bibtex:"@inproceedings{wang_using_poster_2018,\n  title = {Using Transfer Learning to Classify Breast Cancer Cells with Fluorescence Imaging},\n  language = {en},\n  conference = {University of Wisconsin–Madison Undergraduate Symposium},\n  author = {Wang, Zijie J. and Heaster, Tiffany M. and Yin, Quan and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},\n  year = {2018}\n}"}],talk:[{name:Z,events:[{time:"April 2019",place:"UW–Madison Senior Honors Thesis Symposium",url:"https:\u002F\u002Fhonors.ls.wisc.edu\u002Fwp-content\u002Fuploads\u002Fsites\u002F1038\u002F2019\u002F04\u002FSymposiumSchedule2019email.pdf"}]}],award:[{name:"Dean's List",description:"Achieved at least a 3.60 GPA as freshmen and sophomores, a 3.85 GPA as juniors and seniors",time:"Aug. 2015 – May 2019"},{name:"University Book Store Academic Excellence Award ($1000)",description:"An award recognizing undergraduate students who have completed an outstanding independent project, such as a senior thesis, at the University of Wisconsin–Madison",time:o},{name:"Honors Senior Thesis Summer Research Grant ($3000)",description:"A research grant funding students to undertake more demanding and extensive senior thesis research projects",time:"June 2018"},{name:"Welton Summer Sophomore Apprenticeship ($2500)",description:"A research grant awarded to talented students to participate in actual, cutting-edge research",time:"June 2017"}],teaching:[{title:"Undergraduate Teaching Assistant",school:c,schoolURL:s,course:"Computer Graphics (CS 559)",courseURL:"https:\u002F\u002Fgraphics.cs.wisc.edu\u002FWP\u002Fcs559-sp2019\u002Foverview\u002F",instructor:p,timeStart:G,timeEnd:o,place:d,description:"Created course notes and weekly assignments, held weekly office hours, and answered student questions on Piazza. The course had 180 undergraduates enrolled.\n"},{title:"Notetaker",school:c,schoolURL:s,course:"McBurney Disability Resource Center",courseURL:"https:\u002F\u002Fmcburney.wisc.edu\u002F",timeStart:"Sep. 2016",timeEnd:o,place:d,description:"Provided clearly-written math and statistics notes to students with disability, answered course-related questions.\n"},{title:"Academic Coach",school:c,schoolURL:s,course:"Division of Diversity, Equity and Educational Achievement",courseURL:"https:\u002F\u002Fdiversity.wisc.edu\u002Fabout\u002Fabout-ddeea\u002F",timeStart:"Nov. 2016",timeEnd:"May 2017",place:d,description:"Mentored undergraduate students in DDEEA programs for Data Structure course, designed two worksheets and provided detailed solutions every week.\n"},{title:"Tutor",school:c,schoolURL:s,course:"Greater University Tutoring Service",courseURL:"https:\u002F\u002Fguts.wisc.edu\u002F",timeStart:"Jan. 2016",timeEnd:"Jan. 2017",place:d,description:"Instructed peers one-on-one in programming and math problems for three hours weekly, led review sections to help students study for calculus exams.\n"}],mentoring:[{name:R,timeStart:"May 2020",timeEnd:g,degree:x},{name:u,timeStart:k,timeEnd:g,degree:x,description:"Machine learning and visualization",awards:["PURA Travel Award (2020)"]},{name:m,timeStart:k,timeEnd:g,degree:x,awards:["Outstanding Freshman Award (2020)"]}],service:{review:[{venue:"IEEE Visual Analytics Science and Technology",venueShort:"VAST",years:[{year:e,yearURL:N}]},{venue:"ACM Conference on Information and Knowledge Management",venueShort:P,years:[{year:e,yearURL:Q}]}],membership:[{org:"Institute of Electrical and Electronics Engineers",orgShort:"IEEE",orgURL:"https:\u002F\u002Fwww.ieee.org\u002F",timeStart:"July 2019",timeEnd:g},{org:"Association for Computing Machinery",orgShort:"ACM",orgURL:"https:\u002F\u002Fwww.acm.org\u002F",timeStart:"Dec. 2019",timeEnd:g}]},reference:[{name:"Polo Chau",position:"Associate Professor",department:C,departmentURL:$,institution:t,institutionURL:$,url:"https:\u002F\u002Fcc.gatech.edu\u002F~dchau\u002F"},{name:"Anghony Gitter",position:"Assistant Professor",department:"Department of Biostatistics and Medical Informatics",departmentURL:"https:\u002F\u002Fwww.biostat.wisc.edu\u002F",institution:c,institutionURL:i,url:"https:\u002F\u002Fwww.biostat.wisc.edu\u002F~gitter\u002F"},{name:p,position:"Professor",department:F,departmentURL:"https:\u002F\u002Fwww.cs.wisc.edu\u002F",institution:c,institutionURL:i,url:z}],skill:[{group:"Programming",items:["Python","JavaScript","Swift","R","Julia","PyTorch","TensorFlow","Keras","HTML","CSS","LaTeX","SQL","C++","Git"]},{group:"Design",items:["Affinity Designer","Affinity Photo","Final Cut Pro","Sketch","Keynote","Illustrator","Photoshop"]},{group:"HCI",items:["Think-aloud protocol","User Personas","Rapid Paper Prototyping","Affinity Diagraming"]}],news:[{date:"Aug. 14, 2020",news:"My paper \u003Ca href='papers\u002Fcnn-explainer' target='_self'\u003ECNN Explainer\u003C\u002Fa\u003E is accepted for IEEE VIS 2020 VAST (TVCG Journal Track)!\n"},{date:"June 18, 2020",news:"Started my first internship at \u003Ca href='https:\u002F\u002Fwww.bosch.us\u002Four-company\u002Fbosch-in-the-usa\u002Fsunnyvale\u002F' target='_self'\u003EBosch (Sunnyvale)\u003C\u002Fa\u003E , working with \u003Ca href='https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Flianggou\u002F' target='_self'\u003ELiang Gou\u003C\u002Fa\u003E on visual analytics for autonomous driving.\n"},{date:"April 30, 2020",news:"Posted my \u003Ca href='https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.15004' target='_self'\u003ECNN Explainer paper\u003C\u002Fa\u003E on arXiv. CNN Explainer an \u003Ca href='http:\u002F\u002Fpoloclub.github.io\u002Fcnn-explainer\u002F' target='_self'\u003Einteractive tool\u003C\u002Fa\u003E that helps beginners learn CNNs. It is also \u003Ca href='https:\u002F\u002Fgithub.com\u002Fpoloclub\u002Fcnn-explainer' target='_self'\u003Eopen-sourced\u003C\u002Fa\u003E on GitHub.\n"},{date:"Jan 15, 2020",news:"Two papers, \u003Ca href='papers\u002Fcnn-101' target='_self'\u003ECNN 101\u003C\u002Fa\u003E and \u003Ca href='papers\u002Fmassif' target='_self'\u003EMassif\u003C\u002Fa\u003E, are accepted for CHI 2020 Late-Breaking Works!\n"},{date:"Nov. 15, 2019",news:"I will present my T Cell Classification \u003Ca href='\u002Fpdf\u002Fglbio_2019.pdf' target='_self'\u003Eposter\u003C\u002Fa\u003E at \u003Ca href='https:\u002F\u002Fostem.org\u002Fpage\u002Fconference-2019' target='_self'\u003EoSTEM'19\u003C\u002Fa\u003E. See you in Detroit (really miss the Midwest winter!). \n"},{date:"Oct. 1, 2019",news:"I will attend \u003Ca href='http:\u002F\u002Fieeevis.org\u002Fyear\u002F2019\u002Fwelcome' target='_self'\u003EVIS'19\u003C\u002Fa\u003E in Vancouver. Come to talk to me :) \n"},{date:"Aug. 15, 2019",news:"Submitted my first \u003Ca href='https:\u002F\u002Fwww.biorxiv.org\u002Fcontent\u002F10.1101\u002F737346' target='_self'\u003Epaper\u003C\u002Fa\u003E on bioRxiv. Check it out!\n"},{date:"May. 11, 2019",news:"I \u003Ca href='https:\u002F\u002Fwww.biorxiv.org\u002Fcontent\u002F10.1101\u002F737346' target='_self'\u003Egraduated\u003C\u002Fa\u003E! Will always be a proud badger!! 🦡\n"},{date:"April 20, 2019",news:"Honored to receive the 2019 \u003Ca href='https:\u002F\u002Fawards.advising.wisc.edu\u002Fcampus-wide-award-recipients\u002F2016-university-book-store-award-recipients\u002F' target='_self'\u003E University Book Store Academic Excellence Award\u003C\u002Fa\u003E.\n"},{date:"April 10, 2019",news:"Excited to present my T-cell classification project as a poster in     \u003Ca href='https:\u002F\u002Fwww.iscb.org\u002Fglbio2019' target='_self'\u003EGLBIO'19\u003C\u002Fa\u003E.\n"}],featured:[{id:I,featureImg:"\u002Fimages\u002Fteasers\u002Fcnn-explainer.png"},{id:K,featureImg:"\u002Fimages\u002Fteasers\u002Fbluff.png"},{id:T,featureImg:"\u002Fimages\u002Fteasers\u002Funmask.png"}],project:[{name:"Clip2imgur",repo:"xiaohk\u002Fclip2imgur",teaser:"\u002Fimages\u002Fteasers\u002Fproject-clip2imgur.png",award:{name:"Featured on Imgur",url:"https:\u002F\u002Fhelp.imgur.com\u002Fhc\u002Fen-us\u002Farticles\u002F209592766-Tools-for-Imgur"},description:"Convenient macOS command line tool for uploading screen-shots from the clipboard to Imgur. \n"},{name:"FaceData",repo:"xiaohk\u002FFaceData",teaser:"\u002Fimages\u002Fteasers\u002Fproject-face.jpg",description:"MacOS GUI to auto-annotate facial landmarks from a video. Landmarks can be used to train GANs.\n"},{name:"Graphics on the Web",repo:aa,demo:"http:\u002F\u002Fjayw-www.cs.wisc.edu\u002Fcs559\u002Fp10\u002F",teaser:"\u002Fimages\u002Fteasers\u002Fproject-graphics.png",description:"Interactive 2D, 2.5D and 3D computational graphics with shaders and textures, created with HTML canvas and webGL.\n"},{name:"Group Assignment Problem",repo:aa,demo:"https:\u002F\u002Fnbviewer.jupyter.org\u002Fgithub\u002Fxiaohk\u002FCS524-Group-Assignment-Optimization\u002Fblob\u002Fmaster\u002FWang.ipynb",teaser:"\u002Fimages\u002Fteasers\u002Fproject-optim.png",award:{name:"Best project",url:"https:\u002F\u002Flaurentlessard.com\u002Fteaching\u002F524-intro-to-optimization\u002F"},description:"Flexible and robust Mixed Integer Quadratic Programming model written in Julia to solve a real-life optimization problem.\n"},{name:"Dean's list Vis",demo:"http:\u002F\u002Fjayw-www.cs.wisc.edu\u002Fd3-china-map\u002F",repo:"xiaohk\u002Fd3-china-map",teaser:"\u002Fimages\u002Fteasers\u002Fproject-map.png",description:"Interactive geo-visualization to explore where UW–Madison Chinese students are from.\n"},{name:"Yelp Sentiment",repo:"xiaohk\u002Fstat333_project_2",teaser:"\u002Fimages\u002Fteasers\u002Fproject-review.png",award:{name:"In-class Kaggle winner",url:"https:\u002F\u002Fwww.kaggle.com\u002Fc\u002Fuw-madison-sp17-stat333"},description:"Predicting Yelp ratings based on text comments of Madison restaurants.\n"}]}}}("Zijie J. Wang","Duen Horng (Polo) Chau","University of Wisconsin–Madison","Madison, WI",2020,true,"Present","Haekyu Park","https:\u002F\u002Fwww.wisc.edu","Nilaksh Das","Aug. 2019","Anthony Gitter","Omar Shaikh","arxiv","May 2019","Michael Gleicher","academic","Fred Hohman","https:\u002F\u002Fwww.wisc.edu\u002F","Georgia Institute of Technology","Robert Turko","Alex J. Walsh","Melissa C. Skala","B.S. in Computer Science, Georgia Institute of Technology","https:\u002F\u002Fwww.cc.gatech.edu\u002F~dchau","http:\u002F\u002Fpages.cs.wisc.edu\u002F~gleicher\u002F","Atlanta, GA","Yu Hen Hu","School of Computational Science and Engineering","https:\u002F\u002Fwww.cs.wisc.edu","Undergraduate Researcher","Department of Computer Sciences","Dec. 2018","Dec. 2017","cnn-explainer","Minsuk Kahng","bluff","Robert Firstman","Emily Rogers","http:\u002F\u002Fieeevis.org\u002Fyear\u002F2020\u002Fwelcome","Scott Freitas","CIKM","https:\u002F\u002Fwww.cikm2020.org\u002F","Jon Saad-Falcon","https:\u002F\u002Farxiv.org\u002Fabs\u002F2006.06105","unmask","https:\u002F\u002Farxiv.org\u002Fabs\u002F2002.09576","Extended Abstracts on ACM Human Factors in Computing Systems","CHI","Honolulu, HI, USA",2019,"Classifying T cell activity with convolutional neural networks","poster",null,"xiaohk\u002FCS559-computational-graphics"))]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');(function(){try{eval("async function x(){}");var main="/client/client.eff93043.js"}catch(e){main="/client/legacy/client.3bcdc8ca.js"};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src=main;s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@1.0.1.js";s.setAttribute("data-main",main);}document.head.appendChild(s);}());</script> 