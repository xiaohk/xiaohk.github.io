<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#333333 name=theme-color> <base href=/ > <link href=global.css rel=stylesheet> <link href=manifest.json rel=manifest> <link href=favicon.ico rel=icon type=image/png> <link href="https://fonts.googleapis.com/css2?family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Roboto+Mono:ital,wght@0,100;0,300;0,400;0,500;0,700;1,100;1,300;1,400;1,500;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet> <link href=client/main.3754935911.css rel=stylesheet><link href=client/cv.c571b917.css rel=stylesheet><link href=client/client.65134f1f.css rel=stylesheet> <noscript id=sapper-head-start></noscript><title>CV — Jay Wang</title><meta content="CV — Jay Wang" name=title><meta content="Zijie Jay Wang is a Ph.D. student in the College of Computing at Georgia Tech researching the intersection of machine learning and data visualization." name=description><meta content=website property=og:type><meta content=https://zijie.wang/cv property=og:url><meta content="CV — Jay Wang" property=og:title><meta content="Zijie Jay Wang is a Ph.D. student in the College of Computing at Georgia Tech researching the intersection of machine learning and data visualization." property=og:description><meta content=https://zijie.wang/images/teasers/preview.png property=og:image><meta content=summary_large_image property=twitter:card><meta content=https://zijie.wang/cv property=twitter:url><meta content="CV — Jay Wang" property=twitter:title><meta content="Zijie Jay Wang is a Ph.D. student in the College of Computing at Georgia Tech researching the intersection of machine learning and data visualization." property=twitter:description><meta content=https://zijie.wang/images/teasers/preview.png property=twitter:image><meta content=@jay4w property=twitter:site><meta content=@jay4w property=twitter:creator><script async src="https://www.googletagmanager.com/gtag/js?id=UA-130177683-1"></script><script>window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-130177683-1'); </script><noscript id=sapper-head-end></noscript> </head> <body> <div id=sapper> <main class=svelte-1jybnva> <div class="svelte-1cxbaue cv"><div class="svelte-1cxbaue left-padding"></div> <div class="svelte-1cxbaue article"> <div class="svelte-1cxbaue row-tb"><h1 class="svelte-1cxbaue title"><a href=. class="svelte-1cxbaue header-item">Zijie Jay Wang </a></h1> <div class="svelte-1cxbaue line--code title-info"><div class=svelte-1cxbaue><a href=https://zijie.wang target=_self>https://zijie.wang</a></div> <div class=svelte-1cxbaue><a href=mailto:jayw@gatech.edu target=_self>jayw@gatech.edu</a></div></div></div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#education id=education><h2 class=svelte-1cxbaue>Education</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://www.gatech.edu target=_self>Georgia Institute of Technology</a></div> <div class="svelte-1cxbaue row-grid--left-line line">Ph.D. in Machine Learning </div> <div class="svelte-1cxbaue row-grid--left-line line">Advisor: <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Atlanta, GA</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Aug. 2019 — Present</div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://www.wisc.edu target=_self>University of Wisconsin–Madison</a></div> <div class="svelte-1cxbaue row-grid--left-line line">Bachelor of Science (B.S.), GPA: 3.95/4.00 </div><div class="svelte-1cxbaue row-grid--left-line line">Majors: Computer Sciences (Honor), Statistics (Honor), Mathematics </div> <div class="svelte-1cxbaue row-grid--left-line line--italic">Thesis: <a href=pdf/undergrad-thesis.pdf target=_self>Classifying T Cell Activity with Convolutional Neural Networks</a> </div> <div class="svelte-1cxbaue row-grid--left-line line">Advisors: <a href=https://www.biostat.wisc.edu/~gitter target=_self>Anthony Gitter</a>, <a href=http://pages.cs.wisc.edu/~gleicher/ target=_self>Michael Gleicher</a>, <a href=http://homepages.cae.wisc.edu/~hu/ target=_self>Yu Hen Hu</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Sept. 2015 — May 2019</div> </div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#academic-experience id=academic-experience><h2 class=svelte-1cxbaue>Academic Research Experience</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://www.gatech.edu target=_self>Georgia Institute of Technology</a></div> <div class="svelte-1cxbaue row-grid--left-line line--italic">Ph.D. Researcher, <a href=https://cse.gatech.eduu target=_self>School of Computational Science and Engineering</a></div> <div class="svelte-1cxbaue row-grid--left-line line">Mentor: <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Atlanta, GA</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Aug. 2019 — Present</div> <div class="svelte-1cxbaue line--small row-grid--full-line">Member of the Polo Club of Data Science where we innovate scalable, interactive, and interpretable tools that amplify human's ability to understand and interact with billion-scale data and machine learning models. </div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://morgridge.org target=_self>Morgridge Institute for Research</a></div> <div class="svelte-1cxbaue row-grid--left-line line--italic">Undergraduate Researcher, <a href=https://morgridge.org/research/virology/ target=_self>John W. and Jeanne M. Rowe Center for Research in Virology</a></div> <div class="svelte-1cxbaue row-grid--left-line line">Mentor: <a href=https://www.biostat.wisc.edu/~gitter target=_self>Anthony Gitter</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Dec. 2017 — Aug. 2019</div> <div class="svelte-1cxbaue line--small row-grid--full-line">Classify T-cell and breast cancer cell types using fluorescent images with machine learning classifiers with a gradient of complexity. Interpre feature representations of each classifiers. Analyze about 1 million 5-channel cell-painting images of bone tumor cells. Explore latent space between image space and chemical molecule space. </div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://www.wisc.edu target=_self>University of Wisconsin–Madison</a></div> <div class="svelte-1cxbaue row-grid--left-line line--italic">Undergraduate Researcher, <a href=https://www.cs.wisc.edu target=_self>Department of Computer Sciences</a></div> <div class="svelte-1cxbaue row-grid--left-line line">Mentor: <a href=http://pages.cs.wisc.edu/~gleicher/ target=_self>Michael Gleicher</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Dec. 2018 — June 2019</div> <div class="svelte-1cxbaue line--small row-grid--full-line">Design and develop a visual analytics tool for recommender system resaerchers. Interactively visualized user-item rating matrix with statistics-conditioned sub-sampling to spot abnormal ratings and predictions. </div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://www.wisc.edu target=_self>University of Wisconsin–Madison</a></div> <div class="svelte-1cxbaue row-grid--left-line line--italic">Research Assistant, <a href=https://www.engr.wisc.edu/department/electrical-computer-engineering/ target=_self>Electrical & Computer Engineering</a></div> <div class="svelte-1cxbaue row-grid--left-line line">Mentor: <a href=http://homepages.cae.wisc.edu/~hu/ target=_self>Yu Hen Hu</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Feb. 2017 — Dec. 2017</div> <div class="svelte-1cxbaue line--small row-grid--full-line">Study how to track car driver’s head position and orientation from low-qualitytraffic video. Develop semi-automatic video annotation software with Viola-Jones frontal facedetector for training object tracking algorithms. Implement real-time face tracking algorithms on iOS devices. Train a facial reenactment model using GANs and port it to iOS device. </div> </div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#industry-experience id=industry-experience><h2 class=svelte-1cxbaue>Industry Research Experience</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://www.bosch.us/our-company/bosch-in-the-usa/sunnyvale/ target=_self>Bosch Research</a></div> <div class="svelte-1cxbaue row-grid--left-line line--italic">Research Intern, <a href=https://www.bosch.us/our-company/bosch-in-the-usa/sunnyvale/ target=_self>Human–Machine Interaction</a></div> <div class="svelte-1cxbaue row-grid--left-line line">Mentor: <a href=https://www.linkedin.com/in/lianggou/ target=_self>Liang Gou</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Sunnyvale, CA</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">June 2020 — Aug. 2020</div> <div class="svelte-1cxbaue line--small row-grid--full-line">Research and develop explainable machine learning models and visual analytics solutions to help autonomous driving domain experts understand and control adversarial case generation for object recognition. </div> </div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#publications id=publications><h2 class=svelte-1cxbaue>Publications</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/dodrio target=_self>Dodrio: Exploring Transformer Models with Interactive Visualization</a></div> <div class="svelte-1cxbaue line"><a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://www.linkedin.com/in/robert-turko/ target=_self>Robert Turko</a>, <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://arxiv.org/abs/2103.14625 target=_self>arXiv:2103.14625</a> (arXiv). 2021. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/dodrio target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://poloclub.github.io/dodrio/ target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#rocket-sharp></use></svg></div> <span class=svelte-1cxbaue>Demo</span> </a> <a href=https://youtu.be/qB-T9j7UTgE target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#play-solid></use></svg></div> <span class=svelte-1cxbaue>Video</span> </a> <a href=https://arxiv.org/abs/2103.14625 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container"><a href=https://github.com/poloclub/dodrio target=_self class="svelte-1cxbaue icon-container no-right-margin"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1cxbaue>Code</span></a> <div class="svelte-1cxbaue star-container"><div style=display:flex>(<a href=https://github.com/poloclub/dodrio/stargazers target=_self class="svelte-1cxbaue svg-icon" style=font-weight:500;margin-right:-3px> loading </a>)</div> </div> </div> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@article{wangDodrioExploringTransformer2021,
  title = {Dodrio: {{Exploring Transformer Models}} with {{Interactive Visualization}}},
  shorttitle = {Dodrio},
  author = {Wang, Zijie J. and Turko, Robert and Chau, Duen Horng},
  year = {2021},
  month = mar,
  url = {http://arxiv.org/abs/2103.14625},
  archiveprefix = {arXiv},
  eprint = {2103.14625},
  journal = {arXiv:2103.14625}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/human-in-the-loop-nlp target=_self>Putting Humans in the Natural Language Processing Loop: A Survey</a></div> <div class="svelte-1cxbaue line"><a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>*, <a href=https://www.jinchoi.xyz target=_self>Dongjin Choi</a>*, <a href=https://thomasxu2009.github.io target=_self>Shenyu Xu</a>*, <a href=https://www.cc.gatech.edu/~dyang888/ target=_self>Diyi Yang</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://sites.google.com/view/hciandnlp/home target=_self>EACL Workshop on Bridging Human–Computer Interaction and Natural Language Processing</a> (HCI+NLP). Kyiv, Ukraine, 2021. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/human-in-the-loop-nlp target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://arxiv.org/abs/2103.04044 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> <div class="svelte-1cxbaue icon-container">( * Authors contributed equally )</div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@inproceedings{wangPuttingHumansNatural2021,
  title = {Putting {{Humans}} in the {{Natural Language Processing Loop}}: {{A Survey}}},
  shorttitle = {Putting {{Humans}} in the {{Natural Language Processing Loop}}},
  author = {Wang, Zijie J. and Choi, Dongjin and Xu, Shenyu and Yang, Diyi},
  year = {2021},
  month = mar,
  booktitle = "Proceedings of the First Workshop on Bridging Human–Computer Interaction and Natural Language Processing",
  publisher = "Association for Computational Linguistics",
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/skeleton-vis target=_self>SkeletonVis: Interactive Visualization for Understanding Adversarial Attacks on Human Action Recognition Models</a></div> <div class="svelte-1cxbaue line"><a href=https://haekyu.com target=_self>Haekyu Park</a>, <a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://nilakshdas.com target=_self>Nilaksh Das</a>, <a href=https://www.linkedin.com/in/anindyasankar/ target=_self>Anindya S. Paul</a>, <a href=https://www.linkedin.com/in/pruthvi-perumalla/ target=_self>Pruthvi Perumalla</a>, <a href=https://www.linkedin.com/in/frank-zhou-b19515159/ target=_self>Zhiyan Zhou</a>, <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://aaai.org/Conferences/AAAI-21/aaai21demoscall/ target=_self>AAAI Conference on Artificial Intelligence</a> (AAAI Demo). Vancouver, Canada, 2021. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/skeleton-vis target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://poloclub.github.io/skeleton-vis/ target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#rocket-sharp></use></svg></div> <span class=svelte-1cxbaue>Demo</span> </a> <a href=https://youtu.be/xgK9maDqhi4 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#play-solid></use></svg></div> <span class=svelte-1cxbaue>Video</span> </a> <a href=https://arxiv.org/abs/2101.10586 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container"><a href=https://github.com/poloclub/skeleton-vis target=_self class="svelte-1cxbaue icon-container no-right-margin"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1cxbaue>Code</span></a> </div> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@article{park2021skeletonvis,
  title={SkeletonVis: Interactive Visualization for Understanding Adversarial Attacks on Human Action Recognition Models},
  author={Park, Haekyu and Wang, Zijie J. and Das, Nilaksh and Paul, Anindya S. and Perumalla, Pruthvi and Zhou, Zhiyan and Chau, Duen Horng},
  booktitle={AAAI, Demo},
  year={2021}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/cnn-explainer target=_self>CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization</a></div> <div class="svelte-1cxbaue line"><a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://www.linkedin.com/in/robert-turko/ target=_self>Robert Turko</a>, <a href=http://oshaikh.com/ target=_self>Omar Shaikh</a>, <a href=https://haekyu.com target=_self>Haekyu Park</a>, <a href=https://nilakshdas.com target=_self>Nilaksh Das</a>, <a href=https://fredhohman.com target=_self>Fred Hohman</a>, <a href=https://minsuk.com target=_self>Minsuk Kahng</a>, <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://www.computer.org/csdl/journal/tg target=_self>IEEE Transactions on Visualization and Computer Graphics</a> (TVCG). Salt Lake City, UT, USA, 2021. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/cnn-explainer target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://poloclub.github.io/cnn-explainer/ target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#rocket-sharp></use></svg></div> <span class=svelte-1cxbaue>Demo</span> </a> <a href=https://youtu.be/HnWIHWFbuUQ target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#play-solid></use></svg></div> <span class=svelte-1cxbaue>Video</span> </a> <a href=https://arxiv.org/abs/2004.15004 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container"><a href=https://github.com/poloclub/cnn-explainer target=_self class="svelte-1cxbaue icon-container no-right-margin"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1cxbaue>Code</span></a> <div class="svelte-1cxbaue star-container"><div style=display:flex>(<a href=https://github.com/poloclub/cnn-explainer/stargazers target=_self class="svelte-1cxbaue svg-icon" style=font-weight:500;margin-right:-3px> loading </a>)</div> </div> </div> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> <div class="svelte-1cxbaue icon-container award"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#award-solid></use></svg></div> <span class=svelte-1cxbaue><a href=https://web.archive.org/web/20200505121955/https://github.com/trending target=_self>Top of GitHub Trending</a></span> </div></div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@article{wangCNNExplainerLearning2021,
  title = {{{CNN Explainer}}: {{Learning Convolutional Neural Networks}} with {{Interactive Visualization}}},
  shorttitle = {{{CNN Explainer}}},
  author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},
  journal={IEEE Transactions on Visualization and Computer Graphics (TVCG)},
  publisher={IEEE},
  year={2020},
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/bluff target=_self>Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks</a></div> <div class="svelte-1cxbaue line"><a href=https://nilakshdas.com target=_self>Nilaksh Das</a>*, <a href=https://haekyu.com target=_self>Haekyu Park</a>*, <a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://fredhohman.com target=_self>Fred Hohman</a>, <a href=https://www.robfirstman.com/ target=_self>Robert Firstman</a>, <a href=https://www.linkedin.com/in/emily-rogers-1a828598 target=_self>Emily Rogers</a>, <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue line--italic"><a href=http://ieeevis.org/year/2020/welcome target=_self>IEEE Visualization Conference</a> (VIS). Salt Lake City, UT, USA, 2020. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/bluff target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://poloclub.github.io/bluff/ target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#rocket-sharp></use></svg></div> <span class=svelte-1cxbaue>Demo</span> </a> <a href=https://arxiv.org/abs/2009.02608 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container"><a href=https://github.com/poloclub/bluff target=_self class="svelte-1cxbaue icon-container no-right-margin"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1cxbaue>Code</span></a> </div> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> <div class="svelte-1cxbaue icon-container">( * Authors contributed equally )</div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@article{dasBluffInteractivelyDeciphering2020,
  title={Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks},
  author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng},
  booktitle={IEEE Visualization Conference (VIS)},
  publisher={IEEE},
  year={2020}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/ai-guideline target=_self>A Comparative Analysis of Industry Human-AI Interaction Guidelines</a></div> <div class="svelte-1cxbaue line"><a href=https://austinpwright.com/ target=_self>Austin P. Wright</a>, <a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://haekyu.com target=_self>Haekyu Park</a>, <a href=https://gracegsy.github.io/ target=_self>Grace Guo</a>, <a href=https://www.vis.uni-konstanz.de/mitglieder/sperrle/ target=_self>Fabian Sperrle</a>, <a href=https://el-assady.com/ target=_self>Mennatallah El-Assady</a>, <a href=https://va.gatech.edu/endert/ target=_self>Alex Endert</a>, <a href=https://www.vis.uni-konstanz.de/en/members/keim target=_self>Daniel Keim</a>, <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://trexvis.github.io/Workshop2020/ target=_self>IEEE Visualization Conference, Workshop on Trust and Expertise in Visual Analytics</a> (TREX). Salt Lake City, UT, USA, 2020. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/ai-guideline target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://ai-open-guidelines.readthedocs.io/en/latest/ target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#rocket-sharp></use></svg></div> <span class=svelte-1cxbaue>Demo</span> </a> <a href=https://arxiv.org/abs/2010.11761 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container"><a href=https://github.com/APWright/AI-Open-Guidelines target=_self class="svelte-1cxbaue icon-container no-right-margin"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1cxbaue>Code</span></a> </div> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@article{wrightComparativeAnalysisIndustry2020,
  title = {A {{Comparative Analysis}} of {{Industry Human}}-{{AI Interaction Guidelines}}},
  author = {Wright, Austin P. and Wang, Zijie J. and Park, Haekyu and Guo, Grace and Sperrle, Fabian and {El-Assady}, Mennatallah and Endert, Alex and Keim, Daniel and Chau, Duen Horng},
  year = {2020},
  month = oct,
  eprint = {2010.11761},
  journal = {arXiv:2010.11761}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/people-map target=_self>Mapping Researchers with PeopleMap</a></div> <div class="svelte-1cxbaue line"><a href=https://www.linkedin.com/in/jonsaadfalcon/ target=_self>Jon Saad-Falcon</a>, <a href=http://oshaikh.com/ target=_self>Omar Shaikh</a>, <a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://austinpwright.com/ target=_self>Austin P. Wright</a>, <a href=https://www.linkedin.com/in/sasha-richardson/ target=_self>Sasha Richardson</a>, <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue line--italic"><a href=http://ieeevis.org/year/2020/welcome target=_self>Poster, IEEE Visualization Conference</a> (VIS). Salt Lake City, UT, USA, 2020. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/people-map target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://poloclub.github.io/people-map/ideas/ target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#rocket-sharp></use></svg></div> <span class=svelte-1cxbaue>Demo</span> </a> <a href=https://arxiv.org/abs/2009.00091 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container"><a href=https://github.com/poloclub/people-map target=_self class="svelte-1cxbaue icon-container no-right-margin"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1cxbaue>Code</span></a> <div class="svelte-1cxbaue star-container"><div style=display:flex>(<a href=https://github.com/poloclub/people-map/stargazers target=_self class="svelte-1cxbaue svg-icon" style=font-weight:500;margin-right:-3px> loading </a>)</div> </div> </div> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> <div class="svelte-1cxbaue icon-container award"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#award-solid></use></svg></div> <span class=svelte-1cxbaue><a href=https://virtual.ieeevis.org/awards.html target=_self>Best Poster Research Award, Honorable Mention</a></span> </div></div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@article{saad-falconMappingResearchersPeopleMap2020,
  title = {Mapping {{Researchers}} with {{PeopleMap}}},
  author = {{Saad-Falcon}, Jon and Shaikh, Omar and Wang, Zijie J. and Wright, Austin P. and Richardson, Sasha and Chau, Duen Horng},
  year = {2020},
  journal = {Poster, IEEE Visualization Conference (VIS)}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/argo-lite target=_self>Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers</a></div> <div class="svelte-1cxbaue line"><a href=https://rsli.github.io/ target=_self>Siwei Li</a>, <a href=https://www.linkedin.com/in/frank-zhou-b19515159/ target=_self>Zhiyan Zhou</a>, <a href=https://github.com/aupadhayay3 target=_self>Anish Upadhayay</a>, <a href=http://oshaikh.com/ target=_self>Omar Shaikh</a>, <a href=https://www.scottfreitas.com/ target=_self>Scott Freitas</a>, <a href=https://haekyu.com target=_self>Haekyu Park</a>, <a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://www.linkedin.com/in/susantaroutray/ target=_self>Susanta Routray</a>, <a href=https://www.linkedin.com/in/mdhull/ target=_self>Matthew Hull</a>, <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://www.cikm2020.org/ target=_self>The Conference on Information and Knowledge Management</a> (CIKM). Galway, Ireland, 2020. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/argo-lite target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://poloclub.github.io/argo-graph-lite/ target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#rocket-sharp></use></svg></div> <span class=svelte-1cxbaue>Demo</span> </a> <a href=https://arxiv.org/abs/2008.11844 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container"><a href=https://github.com/poloclub/argo-graph-lite target=_self class="svelte-1cxbaue icon-container no-right-margin"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1cxbaue>Code</span></a> <div class="svelte-1cxbaue star-container"><div style=display:flex>(<a href=https://github.com/poloclub/argo-graph-lite/stargazers target=_self class="svelte-1cxbaue svg-icon" style=font-weight:500;margin-right:-3px> loading </a>)</div> </div> </div> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@article{liArgoLiteOpenSource2020,
  title={Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers},
  author={Li, Siwei and Zhou, Zhiyan and Upadhayay, Anish and Shaikh, Omar and Freitas, Scott and Park, Haekyu and Wang, Zijie J and Routray, Susanta and Hull, Matthew and Chau, Duen Horng},
  booktitle={Proceedings of the International Conference on Information and Knowledge Management},
  year={2020},
  organization={ACM}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/unmask target=_self>UnMask: Adversarial Detection and Defense Through Robust Feature Alignment</a></div> <div class="svelte-1cxbaue line"><a href=https://www.scottfreitas.com/ target=_self>Scott Freitas</a>, <a href=https://www.cc.gatech.edu/~schen351/ target=_self>Shang-Tse Chen</a>, <a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://bigdataieee.org/BigData2020/ target=_self>IEEE International Conference on Big Data</a> (BigData). Los Angeles, CA, USA, 2020. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/unmask target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://arxiv.org/abs/2002.09576 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container"><a href=https://github.com/unmaskd/unmask target=_self class="svelte-1cxbaue icon-container no-right-margin"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1cxbaue>Code</span></a> </div> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@article{freitasUnMaskAdversarialDetection2020,
  title = {{{UnMask}}: {{Adversarial Detection}} and {{Defense Through Robust Feature Alignment}}},
  shorttitle = {{{UnMask}}},
  author = {Freitas, Scott and Chen, Shang-Tse and Wang, Zijie J. and Chau, Duen Horng},
  year = {2020},
  archivePrefix = {arXiv},
  eprint = {2002.09576},
  eprinttype = {arxiv},
  journal = {arXiv:2002.09576}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/massif target=_self>Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning</a></div> <div class="svelte-1cxbaue line"><a href=https://nilakshdas.com target=_self>Nilaksh Das</a>*, <a href=https://haekyu.com target=_self>Haekyu Park</a>*, <a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://fredhohman.com target=_self>Fred Hohman</a>, <a href=https://www.robfirstman.com/ target=_self>Robert Firstman</a>, <a href=https://www.linkedin.com/in/emily-rogers-1a828598 target=_self>Emily Rogers</a>, <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://dl.acm.org/doi/abs/10.1145/3334480.3382977 target=_self>Extended Abstracts on ACM Human Factors in Computing Systems</a> (CHI). Honolulu, HI, USA, 2020. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/massif target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://arxiv.org/abs/2001.07769 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> <div class="svelte-1cxbaue icon-container">( * Authors contributed equally )</div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@inproceedings{das2020massif,
  title={Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning},
  author={Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},
  booktitle={Proceedings of the 2020 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
  publisher={ACM},
  year={2020}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/cnn-101 target=_self>CNN 101: Interactive Visual Learning for Convolutional Neural Networks</a></div> <div class="svelte-1cxbaue line"><a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://www.linkedin.com/in/robert-turko/ target=_self>Robert Turko</a>, <a href=http://oshaikh.com/ target=_self>Omar Shaikh</a>, <a href=https://haekyu.com target=_self>Haekyu Park</a>, <a href=https://nilakshdas.com target=_self>Nilaksh Das</a>, <a href=https://fredhohman.com target=_self>Fred Hohman</a>, <a href=https://minsuk.com target=_self>Minsuk Kahng</a>, <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://dl.acm.org/doi/abs/10.1145/3334480.3382899 target=_self>Extended Abstracts on ACM Human Factors in Computing Systems</a> (CHI). Honolulu, HI, USA, 2020. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/cnn-101 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://youtu.be/g082-zitM7s target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#play-solid></use></svg></div> <span class=svelte-1cxbaue>Video</span> </a> <a href=https://arxiv.org/abs/2001.02004 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@inproceedings{wangCNN101Interactive2020,
  title = {{{CNN}} 101: {{Interactive}} Visual Learning for Convolutional Neural Networks},
  booktitle = {Extended Abstracts of the 2020 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},
  year = {2020},
  publisher = {{ACM}},
  place = {{Honolulu, HI, USA}}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/t-cell target=_self>Classifying T cell activity in autofluorescence intensity images with convolutional neural networks</a></div> <div class="svelte-1cxbaue line"><a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://qoil.engr.tamu.edu target=_self>Alex J. Walsh</a>, <a href=https://morgridge.org/research/medical-engineering/optical-microscopy target=_self>Melissa C. Skala</a>, <a href=https://www.biostat.wisc.edu/~gitter target=_self>Anthony Gitter</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://onlinelibrary.wiley.com/journal/18640648 target=_self>Journal of Biophotonics</a> (J. Biophotonics). 2019. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/t-cell target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=https://onlinelibrary.wiley.com/doi/epdf/10.1002/jbio.201960050 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <a href=/slides/honor_thesis_symposium_2019.pdf target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#slides></use></svg></div> <span class=svelte-1cxbaue>Slides</span> </a> <div class="svelte-1cxbaue icon-container"><a href=https://github.com/gitter-lab/t-cell-classification target=_self class="svelte-1cxbaue icon-container no-right-margin"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1cxbaue>Code</span></a> </div> <a href=https://doi.org/10.5281/zenodo.2640835 target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#data></use></svg></div> <span class=svelte-1cxbaue>Data</span> </a> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@article{wang_classifying_2019,
  title = {Classifying {T} cell activity in autofluorescence intensity images with convolutional neural networks},
  issn = {1864-063X, 1864-0648},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jbio.201960050},
  doi = {10.1002/jbio.201960050},
  language = {en},
  urldate = {2020-01-12},
  journal = {Journal of Biophotonics},
  author = {Wang, Zijie J. and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},
  month = dec,
  year = {2019}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/t-cell-poster target=_self>Classifying T cell activity with convolutional neural networks</a></div> <div class="svelte-1cxbaue line"><a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://qoil.engr.tamu.edu target=_self>Alex J. Walsh</a>, <a href=https://morgridge.org/research/medical-engineering/optical-microscopy target=_self>Melissa C. Skala</a>, <a href=https://www.biostat.wisc.edu/~gitter target=_self>Anthony Gitter</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://www.iscb.org/glbio2019 target=_self>International Society for Computational Biology Great Lakes Bioinformatics Conference</a> (ISCB GLBIO). Madison, WI, USA, 2019. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/t-cell-poster target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=/pdf/19-tcell-glbio.pdf target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@inproceedings{wang_classifying_poster_2019,
  title = {Classifying {T} cell activity with convolutional neural networks},
  language = {en},
  conference = {International Society for Computational Biology Great Lakes Bioinformatics Conference},
  author = {Wang, Zijie J. and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},
  year = {2019}
}</pre> </div> </div><div class="svelte-1cxbaue row-tb"> <div class="svelte-1cxbaue line--strong"><a href=/papers/breast-poster target=_self>Using Transfer Learning to Classify Breast Cancer Cells with Fluorescence Imaging</a></div> <div class="svelte-1cxbaue line"><a href=https://zijie.wang target=_self style=font-weight:700>Zijie J. Wang</a>, <a href=https://morgridge.org/profile/tiffany-heaster/ target=_self>Tiffany M. Heaster</a>, <a href=https://www.linkedin.com/in/quan-yin/ target=_self>Quan Yin</a>, <a href=https://qoil.engr.tamu.edu target=_self>Alex J. Walsh</a>, <a href=https://morgridge.org/research/medical-engineering/optical-microscopy target=_self>Melissa C. Skala</a>, <a href=https://www.biostat.wisc.edu/~gitter target=_self>Anthony Gitter</a></div> <div class="svelte-1cxbaue line--italic"><a href=https://ugradsymposium.wisc.edu target=_self>University of Wisconsin–Madison Undergraduate Symposium</a>. 2018. </div> <div class="svelte-1cxbaue row--icons"><a href=/papers/breast-poster target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#home-sharp></use></svg></div> <span class=svelte-1cxbaue>Project</span> </a> <a href=/pdf/18-breast-symposium.pdf target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1cxbaue>PDF</span> </a> <div class="svelte-1cxbaue icon-container bibtex-button"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#quote-right-solid></use></svg></div> <span class=svelte-1cxbaue>BibTeX</span> </div> </div> <div class="svelte-1cxbaue bibtex hidden"><pre class=svelte-1cxbaue>@inproceedings{wang_using_poster_2018,
  title = {Using Transfer Learning to Classify Breast Cancer Cells with Fluorescence Imaging},
  language = {en},
  conference = {University of Wisconsin–Madison Undergraduate Symposium},
  author = {Wang, Zijie J. and Heaster, Tiffany M. and Yin, Quan and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},
  year = {2018}
}</pre> </div> </div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#talks id=talks><h2 class=svelte-1cxbaue>Invited Talks</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue talk-block"><div class="svelte-1cxbaue line--strong">CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization</div> <div class="svelte-1cxbaue row-grid small-margin"> <div class="svelte-1cxbaue row-grid--left-line"><div class="svelte-1cxbaue line--lr"><a href=http://ieeevis.org/year/2020/welcome target=_self class=svelte-1cxbaue>IEEE Visualization Conference</a> <a href="https://youtu.be/M-pUfWMjXhQ?t=3308" target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#video-solid></use></svg></div> </a> </div></div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time">Oct. 2020</div> </div><div class="svelte-1cxbaue row-grid small-margin"> <div class="svelte-1cxbaue row-grid--left-line"><div class="svelte-1cxbaue line--lr"><a href=https://deepkapha.ai/ target=_self class=svelte-1cxbaue>Deepkapha LiveAI</a> <a href="https://www.youtube.com/watch?v=56bkWcMfN7I" target=_self class="svelte-1cxbaue icon-container"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#video-solid></use></svg></div> </a> </div></div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time">Aug. 2020</div> </div> </div><div class="svelte-1cxbaue talk-block"><div class="svelte-1cxbaue line--strong">Classifying T Cell Activity with Convolutional Neural Networks</div> <div class="svelte-1cxbaue row-grid small-margin"> <div class="svelte-1cxbaue row-grid--left-line"><div class="svelte-1cxbaue line--lr"><a href=https://www.ostem.org/ target=_self class=svelte-1cxbaue>Out in Science, Technology, Engineering, and Mathematics (oSTEM) Conference</a> </div></div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time">Nov. 2019</div> </div><div class="svelte-1cxbaue row-grid small-margin"> <div class="svelte-1cxbaue row-grid--left-line"><div class="svelte-1cxbaue line--lr"><a href=https://honors.ls.wisc.edu/wp-content/uploads/sites/1038/2019/04/SymposiumSchedule2019email.pdf target=_self class=svelte-1cxbaue>UW–Madison Senior Honors Thesis Symposium</a> </div></div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time">April 2019</div> </div> </div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#press id=press><h2 class=svelte-1cxbaue>Press</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue talk-block"><div class="svelte-1cxbaue row-grid small-margin" id=press-row-grid> <div class="svelte-1cxbaue row-grid--left-line"><div class="svelte-1cxbaue line--lr press-title"><a href=https://www.cse.gatech.edu/news/640835/why-new-deep-learning-visualization-going-viral target=_self class=svelte-1cxbaue>Why is This New Deep Learning Visualization Going Viral?</a> </div></div> <div class="svelte-1cxbaue line--lr press-name">Georgia Tech CSE </div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time press-time">Oct. 2020</div> </div><div class="svelte-1cxbaue row-grid small-margin" id=press-row-grid> <div class="svelte-1cxbaue row-grid--left-line"><div class="svelte-1cxbaue line--lr press-title"><a href=https://towardsdatascience.com/learn-machine-learning-concepts-interactively-6c3f64518da2 target=_self class=svelte-1cxbaue>Learn Machine Learning Concepts Interactively</a> </div></div> <div class="svelte-1cxbaue line--lr press-name">Towards Data Science </div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time press-time">Oct. 2020</div> </div><div class="svelte-1cxbaue row-grid small-margin" id=press-row-grid> <div class="svelte-1cxbaue row-grid--left-line"><div class="svelte-1cxbaue line--lr press-title"><a href=https://gigazine.net/gsc_news/en/20200707-cnn-explainer/ target=_self class=svelte-1cxbaue>CNN Explainer that can Understand the Image Identification Process of Deep Learning</a> </div></div> <div class="svelte-1cxbaue line--lr press-name">Gigazine <a href=https://gigazine.net/news/20200707-cnn-explainer/ class=svelte-1cxbaue><div class="svelte-1cxbaue press-lang">Japanese</div> </a></div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time press-time">July 2020</div> </div><div class="svelte-1cxbaue row-grid small-margin" id=press-row-grid> <div class="svelte-1cxbaue row-grid--left-line"><div class="svelte-1cxbaue line--lr press-title"><a href="https://www.youtube.com/watch?v=N6wn8zMRlVE&feature=youtu.be" target=_self class=svelte-1cxbaue>How Do Neural Networks Learn?</a> </div></div> <div class="svelte-1cxbaue line--lr press-name">Two Minute Papers </div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time press-time">June 2020</div> </div><div class="svelte-1cxbaue row-grid small-margin" id=press-row-grid> <div class="svelte-1cxbaue row-grid--left-line"><div class="svelte-1cxbaue line--lr press-title"><a href=https://techcrunch.com/2020/04/09/intel-darpa-machine-learning/ target=_self class=svelte-1cxbaue>DARPA Snags Intel to Lead its Machine Learning Security Tech</a> </div></div> <div class="svelte-1cxbaue line--lr press-name">Tech Crunch </div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time press-time">April 2020</div> </div><div class="svelte-1cxbaue row-grid small-margin" id=press-row-grid> <div class="svelte-1cxbaue row-grid--left-line"><div class="svelte-1cxbaue line--lr press-title"><a href=https://newsroom.intel.com/news/intel-joins-georgia-tech-darpa-program-mitigate-machine-learning-deception-attacks target=_self class=svelte-1cxbaue>Intel Joins Georgia Tech in DARPA Program to Mitigate Machine Learning Deception Attacks</a> </div></div> <div class="svelte-1cxbaue line--lr press-name">Intel News Byte </div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time press-time">April 2020</div> </div></div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#awards id=awards><h2 class=svelte-1cxbaue>Grants and Awards</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://www.bosch.com/research/ target=_self>Bosch Research Gift Funding ($37k) </a></div> <div class="svelte-1cxbaue line--small row-grid--full-line">My visual analytics research during my internship results in $37,000 gift funding from Bosch.</div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-1" style=min-width:145px> Jan. 2021</div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://awards.advising.wisc.edu/campus-wide-award-recipients/2016-university-book-store-award-recipients/ target=_self>University Book Store Academic Excellence Award ($1k) </a></div> <div class="svelte-1cxbaue line--small row-grid--full-line">An award recognizing undergraduate students who have completed an outstanding independent project, such as a senior thesis.</div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-1" style=min-width:145px> May 2019</div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://honors.ls.wisc.edu/senior-thesis-summer-research-grants/ target=_self>Honors Senior Thesis Summer Research Grant ($3k) </a></div> <div class="svelte-1cxbaue line--small row-grid--full-line">A research grant funding students to undertake more demanding and extensive senior thesis research projects.</div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-1" style=min-width:145px> June 2018</div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://honors.ls.wisc.edu/welton-summer-sophomore-apprenticeships/ target=_self>Welton Summer Sophomore Apprenticeship ($2.5k) </a></div> <div class="svelte-1cxbaue line--small row-grid--full-line">A research grant awarded to talented students to participate in actual, cutting-edge research.</div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-1" style=min-width:145px> June 2017</div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://registrar.wisc.edu/deanslist/ target=_self>Dean's List </a></div> <div class="svelte-1cxbaue line--small row-grid--full-line">Achieved at least a 3.60 GPA as freshmen and sophomores, a 3.85 GPA as juniors and seniors.</div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-1" style=min-width:145px> Aug. 2015 – May 2019</div> </div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#teaching id=teaching><h2 class=svelte-1cxbaue>Teaching</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong">Graduate Teaching Assistant</div> <div class="svelte-1cxbaue row-grid--left-line line--italic"><a href=https://www.gatech.edu/ target=_self>Georgia Institute of Technology</a></div> <div class="svelte-1cxbaue row-grid--left-line line"><a href=https://poloclub.github.io/cse6242-2020fall-online/ target=_self>Data & Visual Analytics (CSE 6242)</a>, Instructor: <a href=https://www.cc.gatech.edu/~dchau target=_self>Duen Horng (Polo) Chau</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Atlanta, GA</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Aug. 2020 — Dec. 2020</div> <div class="svelte-1cxbaue line--small row-grid--full-line">Lead homework designs for data visualizations, hold weekly office hours, and answer student questions on Piazza. The course had 1277 graduate students enrolled. </div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong">Undergraduate Teaching Assistant</div> <div class="svelte-1cxbaue row-grid--left-line line--italic"><a href=https://www.wisc.edu/ target=_self>University of Wisconsin–Madison</a></div> <div class="svelte-1cxbaue row-grid--left-line line"><a href=https://graphics.cs.wisc.edu/WP/cs559-sp2019/overview/ target=_self>Computer Graphics (CS 559)</a>, Instructor: <a href=http://pages.cs.wisc.edu/~gleicher/ target=_self>Michael Gleicher</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Dec. 2018 — May 2019</div> <div class="svelte-1cxbaue line--small row-grid--full-line">Create course notes and weekly assignments, hold weekly office hours, and answer student questions on Piazza. The course had 180 undergraduates enrolled. </div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong">Notetaker</div> <div class="svelte-1cxbaue row-grid--left-line line--italic"><a href=https://www.wisc.edu/ target=_self>University of Wisconsin–Madison</a></div> <div class="svelte-1cxbaue row-grid--left-line line"><a href=https://mcburney.wisc.edu/ target=_self>McBurney Disability Resource Center</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Sep. 2016 — May 2019</div> <div class="svelte-1cxbaue line--small row-grid--full-line">Provide clearly-written math and statistics notes to students with disability, answer course-related questions. </div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong">Academic Coach</div> <div class="svelte-1cxbaue row-grid--left-line line--italic"><a href=https://www.wisc.edu/ target=_self>University of Wisconsin–Madison</a></div> <div class="svelte-1cxbaue row-grid--left-line line"><a href=https://diversity.wisc.edu/about/about-ddeea/ target=_self>Division of Diversity, Equity and Educational Achievement</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Nov. 2016 — May 2017</div> <div class="svelte-1cxbaue line--small row-grid--full-line">Mentor undergraduate students in DDEEA programs for Data Structure course, design two worksheets and provided detailed solutions every week. </div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong">Tutor</div> <div class="svelte-1cxbaue row-grid--left-line line--italic"><a href=https://www.wisc.edu/ target=_self>University of Wisconsin–Madison</a></div> <div class="svelte-1cxbaue row-grid--left-line line"><a href=https://guts.wisc.edu/ target=_self>Greater University Tutoring Service</a></div> <div class="svelte-1cxbaue row-grid--right-line-1 line--place">Madison, WI</div> <div class="svelte-1cxbaue line--time row-grid--right-line-2">Jan. 2016 — Jan. 2017</div> <div class="svelte-1cxbaue line--small row-grid--full-line">Instruct peers one-on-one in programming and math problems for three hours weekly, lead review sections to help students study for calculus exams. </div> </div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#mentoring id=mentoring><h2 class=svelte-1cxbaue>Mentoring</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://www.linkedin.com/in/jonsaadfalcon/ target=_self>Jon Saad-Falcon</a></div> <div class="svelte-1cxbaue row-grid--left-line line--italic">B.S. in Computer Science, Georgia Institute of Technology</div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-1 mentor-time-line">May 2020 — Present</div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=https://www.linkedin.com/in/robert-turko/ target=_self>Robert Turko</a></div> <div class="svelte-1cxbaue row-grid--left-line line--italic">B.S. in Computer Science, Georgia Institute of Technology</div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-1 mentor-time-line">Aug. 2019 — Present</div> <div class="svelte-1cxbaue icon-container line--small row-grid--full-line"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#award-solid></use></svg></div> <span class=svelte-1cxbaue>PURA Travel Award (2020)</span> </div> </div><div class="svelte-1cxbaue row-grid"> <div class="svelte-1cxbaue row-grid--left-line line--strong"><a href=http://oshaikh.com/ target=_self>Omar Shaikh</a></div> <div class="svelte-1cxbaue row-grid--left-line line--italic">B.S. in Computer Science, Georgia Institute of Technology</div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-1 mentor-time-line">Aug. 2019 — Present</div> <div class="svelte-1cxbaue icon-container line--small row-grid--full-line"><div class="svelte-1cxbaue svg-icon"><svg class=svelte-1cxbaue viewBox="0 0 100 100"><use xlink:href=/sprite.svg#award-solid></use></svg></div> <span class=svelte-1cxbaue>Outstanding Freshman Award (2020)</span> </div> </div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#service id=service><h2 class=svelte-1cxbaue>Service</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue service-group"><div class="svelte-1cxbaue line--strong">Program Committee</div> <div class="svelte-1cxbaue line service-line"><a href=https://dl.acm.org/conference/cikm target=_self>ACM Conference on Information and Knowledge Management (<span style=font-weight:500>CIKM</span>) </a> <a href=https://www.cikm2020.org/ target=_self class="svelte-1cxbaue service-year">2020 </a> </div><div class="svelte-1cxbaue line service-line"><a href=https://sigir.org/ target=_self>ACM Conference on Information Retrieval (<span style=font-weight:500>SIGIR</span>) </a> <a href=https://sigir.org/sigir2021/index.html target=_self class="svelte-1cxbaue service-year">2021 </a> </div><div class="svelte-1cxbaue line service-line"><a href=https://ecmlpkdd.org/ target=_self>European Conference on Machine Learning and Data Mining (<span style=font-weight:500>ECML PKDD</span>) </a> <a href=https://2021.ecmlpkdd.org/ target=_self class="svelte-1cxbaue service-year">2021 </a> </div></div> <div class="svelte-1cxbaue service-group"><div class="svelte-1cxbaue line--strong">Reviewer</div> <div class="svelte-1cxbaue line service-line"><a href=http://ieeevis.org target=_self>IEEE Visualization & Visual Analytics (<span style=font-weight:500>VIS</span>) </a> <a href=http://ieeevis.org/year/2020/welcome target=_self class="svelte-1cxbaue service-year">2020 </a> </div><div class="svelte-1cxbaue line service-line"><a href=https://ieeexplore.ieee.org/xpl/conhome/1001657/all-proceedings target=_self>IEEE Pacific Visualization Symposium (<span style=font-weight:500>PacificVis</span>) </a> <a href=http://vis.tju.edu.cn/pvis2021/ target=_self class="svelte-1cxbaue service-year">2021 </a> </div><div class="svelte-1cxbaue line service-line"><a href=https://www.eurovis.org/ target=_self>EG Conference on Visualization (<span style=font-weight:500>EuroVis</span>) </a> <a href=https://conferences.eg.org target=_self class="svelte-1cxbaue service-year">2021 </a> </div><div class="svelte-1cxbaue line service-line"><a href=https://joss.theoj.org/ target=_self>Journal of Open Source Software (<span style=font-weight:500>JOSS</span>) </a> <a href=https://joss.theoj.org target=_self class="svelte-1cxbaue service-year">2020 </a> </div><div class="svelte-1cxbaue line service-line"><a href=https://rethinkingmlpapers.github.io/ target=_self>Rethinking ML Papers Workshop at ICLR </a> <a href=https://rethinkingmlpapers.github.io/ target=_self class="svelte-1cxbaue service-year">2021 </a> </div></div> <div class="svelte-1cxbaue service-group"><div class="svelte-1cxbaue line--strong">Member</div> <div class="svelte-1cxbaue row-grid" style=margin-bottom:0><div class="svelte-1cxbaue row-grid--left-line line"><a href=https://www.ieee.org/ target=_self>Institute of Electrical and Electronics Engineers (<span style=font-weight:500>IEEE</span>) </a></div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time">July 2019 — Present</div> </div><div class="svelte-1cxbaue row-grid" style=""><div class="svelte-1cxbaue row-grid--left-line line"><a href=https://www.acm.org/ target=_self>Association for Computing Machinery (<span style=font-weight:500>ACM</span>) </a></div> <div class="svelte-1cxbaue line--time dark row-grid--right-line-talk-time">Dec. 2019 — Present</div> </div></div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#skills id=skills><h2 class=svelte-1cxbaue>Skills</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue row-lr" style=margin-bottom:.5rem><div class=row__left><div class="svelte-1cxbaue line--strong">Programming</div> <div class="svelte-1cxbaue line">Python, JavaScript, Swift, R, Julia, PyTorch, TensorFlow, Keras, HTML, CSS, LaTeX, SQL, C++, Git </div></div> </div><div class="svelte-1cxbaue row-lr" style=margin-bottom:.5rem><div class=row__left><div class="svelte-1cxbaue line--strong">Design</div> <div class="svelte-1cxbaue line">Affinity Designer, Affinity Photo, Final Cut Pro, Sketch, Keynote, Illustrator, Photoshop </div></div> </div><div class="svelte-1cxbaue row-lr" style=""><div class=row__left><div class="svelte-1cxbaue line--strong">HCI</div> <div class="svelte-1cxbaue line">Think-aloud protocol, User Personas, Rapid Paper Prototyping, Affinity Diagraming </div></div> </div> <div class="svelte-1cxbaue row-lr section-header"><div class=row__left><a href=/cv#references id=references><h2 class=svelte-1cxbaue>References</h2></a></div> <div class="svelte-1cxbaue row__right--line"></div></div> <div class="svelte-1cxbaue row"><div class="svelte-1cxbaue row-item"> <div class="svelte-1cxbaue line no-wrap"><a href=https://cc.gatech.edu/~dchau/ target=_self style=font-weight:700;font-size:1.2em>Polo Chau</a>, Associate Professor</div> <div class="svelte-1cxbaue line no-wrap"><a href=https://cse.gatech.edu/ target=_self>School of Computational Science and Engineering</a></div> <div class="svelte-1cxbaue line--italic no-wrap"><a href=https://www.gatech.edu target=_self>Georgia Institute of Technology</a></div> <div class="svelte-1cxbaue line--code"><a href=https://cc.gatech.edu/~dchau/ target=_self>https://cc.gatech.edu/~dchau/</a></div> </div><div class="svelte-1cxbaue row-item"> <div class="svelte-1cxbaue line no-wrap"><a href=https://www.linkedin.com/in/lianggou/ target=_self style=font-weight:700;font-size:1.2em>Liang Gou</a>, Principal Research Scientist</div> <div class="svelte-1cxbaue line no-wrap"><a href=https://www.bosch.us/our-company/bosch-in-the-usa/sunnyvale/ target=_self>Human–Machine Interaction</a></div> <div class="svelte-1cxbaue line--italic no-wrap"><a href=https://www.bosch.us/our-company/bosch-in-the-usa/sunnyvale/ target=_self>Bosch Research</a></div> <div class="svelte-1cxbaue line--code"><a href=https://www.linkedin.com/in/lianggou/ target=_self>https://www.linkedin.com/in/lianggou/</a></div> </div><div class="svelte-1cxbaue row-item"> <div class="svelte-1cxbaue line no-wrap"><a href=https://www.biostat.wisc.edu/~gitter/ target=_self style=font-weight:700;font-size:1.2em>Anghony Gitter</a>, Assistant Professor</div> <div class="svelte-1cxbaue line no-wrap"><a href=https://www.biostat.wisc.edu/ target=_self>Department of Biostatistics and Medical Informatics</a></div> <div class="svelte-1cxbaue line--italic no-wrap"><a href=https://www.wisc.edu target=_self>University of Wisconsin–Madison</a></div> <div class="svelte-1cxbaue line--code"><a href=https://www.biostat.wisc.edu/~gitter/ target=_self>https://www.biostat.wisc.edu/~gitter/</a></div> </div><div class="svelte-1cxbaue row-item"> <div class="svelte-1cxbaue line no-wrap"><a href=http://pages.cs.wisc.edu/~gleicher/ target=_self style=font-weight:700;font-size:1.2em>Michael Gleicher</a>, Professor</div> <div class="svelte-1cxbaue line no-wrap"><a href=https://www.cs.wisc.edu/ target=_self>Department of Computer Sciences</a></div> <div class="svelte-1cxbaue line--italic no-wrap"><a href=https://www.wisc.edu target=_self>University of Wisconsin–Madison</a></div> <div class="svelte-1cxbaue line--code"><a href=http://pages.cs.wisc.edu/~gleicher/ target=_self>http://pages.cs.wisc.edu/~gleicher/</a></div> </div></div></div> <div class="svelte-1cxbaue right-padding"></div></div></main> </div> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,(function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar,as,at,au,av){return {data:{people:{"Zijie J. Wang":{url:"https:\u002F\u002Fzijie.wang",isMe:b},"Anthony Gitter":{url:"https:\u002F\u002Fwww.biostat.wisc.edu\u002F~gitter"},"Melissa C. Skala":{url:"https:\u002F\u002Fmorgridge.org\u002Fresearch\u002Fmedical-engineering\u002Foptical-microscopy"},"Alex J. Walsh":{url:"https:\u002F\u002Fqoil.engr.tamu.edu"},"Duen Horng (Polo) Chau":{url:H},"Polo Chau":{url:H},"Fred Hohman":{url:"https:\u002F\u002Ffredhohman.com"},"Minsuk Kahng":{url:"https:\u002F\u002Fminsuk.com"},"Haekyu Park":{url:"https:\u002F\u002Fhaekyu.com"},"Nilaksh Das":{url:"https:\u002F\u002Fnilakshdas.com"},"Robert Turko":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Frobert-turko\u002F"},"Omar Shaikh":{url:"http:\u002F\u002Foshaikh.com\u002F"},"Michael Gleicher":{url:I},"Yu Hen Hu":{url:"http:\u002F\u002Fhomepages.cae.wisc.edu\u002F~hu\u002F"},"Tiffany M. Heaster":{url:"https:\u002F\u002Fmorgridge.org\u002Fprofile\u002Ftiffany-heaster\u002F"},"Quan Yin":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fquan-yin\u002F"},"Emily Rogers":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Femily-rogers-1a828598"},"Robert Firstman":{url:"https:\u002F\u002Fwww.robfirstman.com\u002F"},"Scott Freitas":{url:"https:\u002F\u002Fwww.scottfreitas.com\u002F"},"Shang-Tse Chen":{url:"https:\u002F\u002Fwww.cc.gatech.edu\u002F~schen351\u002F"},"Jon Saad-Falcon":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fjonsaadfalcon\u002F"},"Austin P. Wright":{url:"https:\u002F\u002Faustinpwright.com\u002F"},"Sasha Richardson":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fsasha-richardson\u002F"},"Siwei Li":{url:"https:\u002F\u002Frsli.github.io\u002F"},"Zhiyan Zhou":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Ffrank-zhou-b19515159\u002F"},"Anish Upadhayay":{url:"https:\u002F\u002Fgithub.com\u002Faupadhayay3"},"Susanta Routray":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fsusantaroutray\u002F"},"Matthew Hull":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fmdhull\u002F"},"Liang Gou":{url:J},"Grace Guo":{url:"https:\u002F\u002Fgracegsy.github.io\u002F"},"Fabian Sperrle":{url:"https:\u002F\u002Fwww.vis.uni-konstanz.de\u002Fmitglieder\u002Fsperrle\u002F"},"Mennatallah El-Assady":{url:"https:\u002F\u002Fel-assady.com\u002F"},"Alex Endert":{url:"https:\u002F\u002Fva.gatech.edu\u002Fendert\u002F"},"Daniel Keim":{url:"https:\u002F\u002Fwww.vis.uni-konstanz.de\u002Fen\u002Fmembers\u002Fkeim"},"Anindya S. Paul":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fanindyasankar\u002F"},"Pruthvi Perumalla":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fpruthvi-perumalla\u002F"},"Dongjin Choi":{url:"https:\u002F\u002Fwww.jinchoi.xyz"},"Shenyu Xu":{url:"https:\u002F\u002Fthomasxu2009.github.io"},"Diyi Yang":{url:"https:\u002F\u002Fwww.cc.gatech.edu\u002F~dyang888\u002F"}},education:[{school:p,schoolURL:y,place:z,timeStart:k,timeEnd:i,descriptions:["Ph.D. in Machine Learning"],advisors:[c]},{school:e,schoolURL:l,place:h,timeStart:"Sept. 2015",timeEnd:q,descriptions:["Bachelor of Science (B.S.), GPA: 3.95\u002F4.00","Majors: Computer Sciences (Honor), Statistics (Honor), Mathematics"],advisors:[m,r,K],thesis:{title:L,file:"pdf\u002Fundergrad-thesis.pdf"}}],experienceAcademic:[{institution:p,place:z,position:"Ph.D. Researcher",group:M,timeStart:k,timeEnd:i,mentors:[c],description:"Member of the Polo Club of Data Science where we innovate scalable, interactive, and interpretable tools that amplify human's ability to understand and interact with billion-scale data and machine learning models.\n",institutionURL:y,groupURL:"https:\u002F\u002Fcse.gatech.eduu"},{institution:"Morgridge Institute for Research",place:h,position:N,group:"John W. and Jeanne M. Rowe Center for Research in Virology",timeStart:O,timeEnd:k,mentors:[m],description:"Classify T-cell and breast cancer cell types using fluorescent images with machine learning classifiers with a gradient of complexity. Interpre feature representations of each classifiers. Analyze about 1 million 5-channel cell-painting images of bone tumor cells. Explore latent space between image space and chemical molecule space.\n",institutionURL:"https:\u002F\u002Fmorgridge.org",groupURL:"https:\u002F\u002Fmorgridge.org\u002Fresearch\u002Fvirology\u002F"},{institution:e,place:h,position:N,group:P,timeStart:Q,timeEnd:"June 2019",mentors:[r],description:"Design and develop a visual analytics tool for recommender system resaerchers. Interactively visualized user-item rating matrix with statistics-conditioned sub-sampling to spot abnormal ratings and predictions.\n",institutionURL:l,groupURL:"https:\u002F\u002Fwww.cs.wisc.edu"},{institution:e,place:h,position:"Research Assistant",group:"Electrical & Computer Engineering",timeStart:"Feb. 2017",timeEnd:O,mentors:[K],description:"Study how to track car driver’s head position and orientation from low-qualitytraffic video. Develop semi-automatic video annotation software with Viola-Jones frontal facedetector for training object tracking algorithms. Implement real-time face tracking algorithms on iOS devices. Train a facial reenactment model using GANs and port it to iOS device.\n",institutionURL:l,groupURL:"https:\u002F\u002Fwww.engr.wisc.edu\u002Fdepartment\u002Felectrical-computer-engineering\u002F"}],experienceIndustry:[{institution:R,place:"Sunnyvale, CA",position:"Research Intern",group:S,timeStart:T,timeEnd:A,mentors:[U],description:"Research and develop explainable machine learning models and visual analytics solutions to help autonomous driving domain experts understand and control adversarial case generation for object recognition.\n",institutionURL:s,groupURL:s}],publication:[{id:V,title:"Dodrio: Exploring Transformer Models with Interactive Visualization",authors:[a,t,c],venue:"arXiv:2103.14625",venueURL:W,venueShort:"arXiv",year:f,url:"\u002Fpapers\u002Fdodrio",pdf:W,repo:"poloclub\u002Fdodrio",showStar:b,video:X,demo:"https:\u002F\u002Fpoloclub.github.io\u002Fdodrio\u002F",abstract:"Why do large pre-trained transformer-based models perform so well across a\nwide variety of NLP tasks? Recent research suggests the key may lie in\nmulti-headed attention mechanism's ability to learn and represent linguistic\ninformation. Understanding how these models represent both syntactic and\nsemantic knowledge is vital to investigate why they succeed and fail, what\nthey have learned, and how they can improve. We present Dodrio, an\nopen-source interactive visualization tool to help NLP researchers and\npractitioners analyze attention mechanisms in transformer-based models with\nlinguistic knowledge. Dodrio tightly integrates an overview that summarizes\nthe roles of different attention heads, and detailed views that help users\ncompare attention weights with the syntactic structure and semantic\ninformation in the input text. To facilitate the visual comparison of\nattention weights and linguistic knowledge, Dodrio applies different graph\nvisualization techniques to represent attention weights with longer input\ntext. Case studies highlight how Dodrio provides insights into understanding\nthe attention mechanism in transformer-based models. Dodrio is available at\n\u003Ca href='https:\u002F\u002Fpoloclub.github.io\u002Fdodrio\u002F'\u003Ehttps:\u002F\u002Fpoloclub.github.io\u002Fdodrio\u002F\u003C\u002Fa\u003E. ",crownCaption:"The Dodrio user interface showing user exploration of connections between\nattention weights from a fine-tuned BERT model and syntactic dependencies as\nwell as semantic saliency scores on the SST2 dataset. (A) In the Dependency\nView, a user hovers over a word from the input sentence, highlighting its\nassociated dependency directed links as orange arcs (lighter is source;\ndarker is target). (B) Semantic Attention Graph highlights the word’s related\ntokens and their attentions; nodes are tokens (darker means more salient), a\ndirected edge encodes attention weight between two tokens.(C) The Attention\nHead Overview shows all attention heads in a multi-layer and multi-head model\nas a grid of circles, each head is (D) colored based on its linguistic\nknowledge in the model (more red → more semantic-aligned, more blue → more\nsyntactic-aligned; darker → more aligned), and sized based on its importance\nscore in the model (larger → more important)",bibtex:"@article{wangDodrioExploringTransformer2021,\n  title = {Dodrio: {{Exploring Transformer Models}} with {{Interactive Visualization}}},\n  shorttitle = {Dodrio},\n  author = {Wang, Zijie J. and Turko, Robert and Chau, Duen Horng},\n  year = {2021},\n  month = mar,\n  url = {http:\u002F\u002Farxiv.org\u002Fabs\u002F2103.14625},\n  archiveprefix = {arXiv},\n  eprint = {2103.14625},\n  journal = {arXiv:2103.14625}\n}"},{id:"human-in-the-loop-nlp",title:"Putting Humans in the Natural Language Processing Loop: A Survey",authors:[a,Y,Z,"Diyi Yang"],equals:[a,Y,Z],venue:"EACL Workshop on Bridging Human–Computer Interaction and Natural Language Processing",venueURL:"https:\u002F\u002Fsites.google.com\u002Fview\u002Fhciandnlp\u002Fhome",venueShort:"HCI+NLP",location:"Kyiv, Ukraine",year:f,url:"\u002Fpapers\u002Fhuman-in-the-loop-nlp",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2103.04044",abstract:"How can we design Natural Language Processing (NLP) systems that learn from\nhuman feedback? There is a growing research body of Human-in-the-loop (HITL)\nNLP frameworks that continuously integrate human feedback to improve the\nmodel itself. HITL NLP research is nascent but multifarious---solving\nvarious NLP problems, collecting diverse feedback from different people, and\napplying different methods to learn from collected feedback. We present a\nsurvey of HITL NLP work from both Machine Learning (ML) and Human-Computer\nInteraction (HCI) communities that highlights its short yet inspiring\nhistory, and thoroughly summarize recent frameworks focusing on their tasks,\ngoals, human interactions, and feedback learning methods. Finally, we\ndiscuss future directions for integrating human feedback in the NLP\ndevelopment loop.",crownCaption:"Overview of representative works in HITL NLP. Each row represents one work.\nWorks are sorted by their task types. Each column corresponds to a dimension\nfrom the four subsections (task, goal, human interaction, and feedback\nlearning method).",crownShowBorder:b,bibtex:"@inproceedings{wangPuttingHumansNatural2021,\n  title = {Putting {{Humans}} in the {{Natural Language Processing Loop}}: {{A Survey}}},\n  shorttitle = {Putting {{Humans}} in the {{Natural Language Processing Loop}}},\n  author = {Wang, Zijie J. and Choi, Dongjin and Xu, Shenyu and Yang, Diyi},\n  year = {2021},\n  month = mar,\n  booktitle = \"Proceedings of the First Workshop on Bridging Human–Computer Interaction and Natural Language Processing\",\n  publisher = \"Association for Computational Linguistics\",\n}"},{id:_,title:"SkeletonVis: Interactive Visualization for Understanding Adversarial Attacks on Human Action Recognition Models",authors:[g,a,j,"Anindya S. Paul","Pruthvi Perumalla",$,c],venue:"AAAI Conference on Artificial Intelligence",venueURL:"https:\u002F\u002Faaai.org\u002FConferences\u002FAAAI-21\u002Faaai21demoscall\u002F",venueShort:"AAAI Demo",location:"Vancouver, Canada",year:f,url:"\u002Fpapers\u002Fskeleton-vis",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2101.10586",repo:"poloclub\u002Fskeleton-vis",showStar:B,video:"https:\u002F\u002Fyoutu.be\u002FxgK9maDqhi4",demo:"https:\u002F\u002Fpoloclub.github.io\u002Fskeleton-vis\u002F",abstract:"Skeleton-based human action recognition technologies are increasingly used\nin video based applications, such as home robotics, healthcare on aging\npopulation, and surveillance. However, such models are vulnerable to\nadversarial attacks, raising serious concerns for their use in\nsafety-critical applications. To develop an effective defense against\nattacks, it is essential to understand how such attacks mislead the pose\ndetection models into making incorrect predictions. We present SkeletonVis,\nthe first interactive system that visualizes how the attacks work on the\nmodels to enhance human understanding of attacks. ",crownShowBorder:b,crownCaption:"The interface of SkeletonVis, visualizing how the Fast Gradient Method\nmanipulates the left foot joints detected by the Detectron2 Keypoint R-CNN\nmodel. (A) The Skeleton Views hows the joints perturbed to unexpected\nlocations. (B) Timeline View reveals the attacked joints spuriously jumping\naround from one frame to the next, leading to a “spike” in the average joint\ndisplacement across attacked frames. These manipulations finally sway the\nST-GCN action detection model into misclassifying the attacked frames as\n“exercising with exercise ball,” instead of the correct “lunge”\nclassification.   ",bibtex:"@article{park2021skeletonvis,\n  title={SkeletonVis: Interactive Visualization for Understanding Adversarial Attacks on Human Action Recognition Models},\n  author={Park, Haekyu and Wang, Zijie J. and Das, Nilaksh and Paul, Anindya S. and Perumalla, Pruthvi and Zhou, Zhiyan and Chau, Duen Horng},\n  booktitle={AAAI, Demo},\n  year={2021}\n}"},{id:aa,title:ab,authors:[a,t,n,g,j,u,ac,c],venue:"IEEE Transactions on Visualization and Computer Graphics",venueURL:"https:\u002F\u002Fwww.computer.org\u002Fcsdl\u002Fjournal\u002Ftg",venueShort:"TVCG",location:v,year:f,url:"\u002Fpapers\u002Fcnn-explainer",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.15004",repo:"poloclub\u002Fcnn-explainer",showStar:b,awards:[{name:"Top of GitHub Trending",url:"https:\u002F\u002Fweb.archive.org\u002Fweb\u002F20200505121955\u002Fhttps:\u002F\u002Fgithub.com\u002Ftrending"}],video:"https:\u002F\u002Fyoutu.be\u002FHnWIHWFbuUQ",demo:"https:\u002F\u002Fpoloclub.github.io\u002Fcnn-explainer\u002F",abstract:"Deep learning's great success motivates many practitioners and students to\nlearn about this exciting technology. However, it is often challenging for\nbeginners to take their first step due to the complexity of understanding\nand applying deep learning. We present CNN Explainer, an interactive\nvisualization tool designed for non-experts to learn and examine\nconvolutional neural networks (CNNs), a foundational deep learning model\narchitecture. Our tool addresses key challenges that novices face while\nlearning about CNNs, which we identify from interviews with instructors and\na survey with past students. CNN Explainer tightly integrates a model\noverview that summarizes a CNN's structure, and on-demand, dynamic visual\nexplanation views that help users understand the underlying components of\nCNNs. Through smooth transitions across levels of abstraction, our tool\nenables users to inspect the interplay between low-level mathematical\noperations and high-level model structures. A qualitative user study shows\nthat CNN Explainer helps users more easily understand the inner workings of\nCNNs, and is engaging and enjoyable to use. We also derive design lessons\nfrom our study. Developed using modern web technologies, CNN Explainer runs\nlocally in users' web browsers without the need for installation or\nspecialized hardware, broadening the public's education access to modern\ndeep learning techniques.",crownCaption:"With CNN Explainer, learners can visually examine how Convolutional Neural\nNetworks (CNNs) transform input images into classification predictions\n(e.g., predicting espresso for an image of a coffee cup), and interactively\nlearn about their underlying mathematical operations. In this example, a\nlearner uses CNN Explainer to understand how convolutional layers work\nthrough three tightly integrated views, each explaining the convolutional\nprocess in increasing levels of detail. (A) The Overview visualizes a CNN\narchitecture where each neuron is encoded as a square with a heatmap\nrepresenting the neuron’s output, and each edge connects the neuron with its\ncorresponding inputs and outputs. (B) Clicking a neuron reveals how its\nactivations are computed by the previous layer’s neurons, displaying the\noften-overlooked intermediate computation through animations of sliding\nkernels. (C) The Convolutional Interactive Formula View allows users to\ninteractively inspect the underlying mathematics of the dot-product\noperation core to convolution, through hovering the 3×3 kernel over the\ninput, and interactively studying the corresponding output. For clarity,\nvisibility of Overview and annotation text is improved, and the overlay is\nre-positioned.",bibtex:"@article{wangCNNExplainerLearning2021,\n  title = {{{CNN Explainer}}: {{Learning Convolutional Neural Networks}} with {{Interactive Visualization}}},\n  shorttitle = {{{CNN Explainer}}},\n  author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},\n  journal={IEEE Transactions on Visualization and Computer Graphics (TVCG)},\n  publisher={IEEE},\n  year={2020},\n}"},{id:ad,title:"Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks",authors:[j,g,a,u,ae,af,c],equals:[j,g],venue:ag,venueURL:w,venueShort:C,location:v,year:d,url:"\u002Fpapers\u002Fbluff",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2009.02608",repo:"poloclub\u002Fbluff",showStar:B,demo:"https:\u002F\u002Fpoloclub.github.io\u002Fbluff\u002F",abstract:"Deep neural networks (DNNs) are now commonly used in many domains. However,\nthey are vulnerable to adversarial attacks: carefully crafted perturbations\non data inputs that can fool a model into making incorrect predictions.\nDespite significant research on developing DNN attack and defense\ntechniques, people still lack an understanding of how such attacks penetrate\na model's internals. We present Bluff, an interactive system for\nvisualizing, characterizing, and deciphering adversarial attacks on\nvision-based neural networks. Bluff allows people to flexibly visualize and\ncompare the activation pathways for benign and attacked images, revealing\nmechanisms that adversarial attacks employ to inflict harm on a model. Bluff\nis open-sourced and runs in modern web browsers. ",crownCaption:"With Bluff, users interactively visualize how adversarial attacks penetrate\na deep neural network to induce incorrect outcomes. Here, a user inspects\nwhy Inception V1 misclassifies adversarial giant panda images, crafted by\nthe Projected Gradient Descent (PGD) attack, as armadillo. PGD successfully\nperturbed pixels to induce the “brown bird” feature, an appearance more\nlikely shared by an armadillo (small, roundish, brown body) than a panda,\nactivating more features that contribute to the armadillo (mis)classification\n(e.g., “scales,” “bumps,” “mesh”). The adversarial pathways, formed by these\nneurons and their connections, overwhelm the benign panda pathways and lead\nto the ultimate misclassification. (A) Control Side bar allows users to\nspecify what data is to be included and highlighted. (B) Graph Summary View\nvisualizes pathways most activated or changed by an attack as a network\ngraph of neurons (each labeled by the channel ID in its layer) and their\nconnections. When hovering over a neuron, (C) Detail View displays its\nfeature visualization, representative dataset examples, and activation\npatterns over attack strengths.",bibtex:"@article{dasBluffInteractivelyDeciphering2020,\n  title={Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks},\n  author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng},\n  booktitle={IEEE Visualization Conference (VIS)},\n  publisher={IEEE},\n  year={2020}\n}"},{id:ah,title:"A Comparative Analysis of Industry Human-AI Interaction Guidelines",authors:[ai,a,g,"Grace Guo","Fabian Sperrle","Mennatallah El-Assady","Alex Endert","Daniel Keim",c],venue:"IEEE Visualization Conference, Workshop on Trust and Expertise in Visual Analytics",venueURL:"https:\u002F\u002Ftrexvis.github.io\u002FWorkshop2020\u002F",venueShort:"TREX",location:v,year:d,url:"\u002Fpapers\u002Fai-guideline",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2010.11761",repo:"APWright\u002FAI-Open-Guidelines",showStar:B,demo:"https:\u002F\u002Fai-open-guidelines.readthedocs.io\u002Fen\u002Flatest\u002F",crownMaxHeight:"750px",crownShowBorder:b,abstract:"With the recent release of AI interaction guidelines from Apple, Google, and\nMicrosoft, there is clearly interest in understanding the best practices in\nhuman-AI interaction. However, industry standards are not determined by a\nsingle company, but rather by the synthesis of knowledge from the whole\ncommunity. We have surveyed all of the design guidelines from each of these\nmajor companies and developed a single, unified structure of guidelines,\ngiving developers a centralized reference. We have then used this framework\nto compare each of the surveyed companies to find differences in areas of\nemphasis. Finally, we encourage people to contribute additional guidelines\nfrom other companies, academia, or individuals, to provide an open and\nextensible reference of AI design guidelines at \u003Ca\nhref='https:\u002F\u002Fai-open-guidelines.readthedocs.io'\u003Ehttps:\u002F\u002Fai-open-guidelines.readthedocs.io\u003C\u002Fa\u003E.    ",crownCaption:"Unified Guideline Structure. The inner ring consists of the higher level\ncategorizations, and further sub-categorizations developed during the\naffinity diagram process are shown concentrically. The outermost rays\nconsist of the specific guidelines colored based on their\ncategorizations. Further references on each guideline and its corresponding\ncategorization and source document can be found in the appendix.",bibtex:"@article{wrightComparativeAnalysisIndustry2020,\n  title = {A {{Comparative Analysis}} of {{Industry Human}}-{{AI Interaction Guidelines}}},\n  author = {Wright, Austin P. and Wang, Zijie J. and Park, Haekyu and Guo, Grace and Sperrle, Fabian and {El-Assady}, Mennatallah and Endert, Alex and Keim, Daniel and Chau, Duen Horng},\n  year = {2020},\n  month = oct,\n  eprint = {2010.11761},\n  journal = {arXiv:2010.11761}\n}"},{id:"people-map",title:"Mapping Researchers with PeopleMap",authors:[aj,n,a,ai,"Sasha Richardson",c],venue:"Poster, IEEE Visualization Conference",venueURL:w,venueShort:C,year:d,location:v,url:"\u002Fpapers\u002Fpeople-map",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2009.00091",repo:"poloclub\u002Fpeople-map",type:o,demo:"https:\u002F\u002Fpoloclub.github.io\u002Fpeople-map\u002Fideas\u002F",showStar:b,awards:[{name:"Best Poster Research Award, Honorable Mention",url:"https:\u002F\u002Fvirtual.ieeevis.org\u002Fawards.html"}],abstract:"Discovering research expertise at institutions can be a difficult task.\nManually curated university directories easily become out of date and they\noften lack the information necessary for understanding a researcher's\ninterests and past work, making it harder to explore the diversity of\nresearch at an institution and identify research talents. This results in\nlost opportunities for both internal and external entities to discover new\nconnections and nurture research collaboration. To solve this problem, we\nhave developed PeopleMap, the first interactive, open-source, web-based tool\nthat visually \"maps out\" researchers based on their research interests and\npublications by leveraging embeddings generated by natural language\nprocessing (NLP) techniques. PeopleMap provides a new engaging way for\ninstitutions to summarize their research talents and for people to discover\nnew connections. The platform is developed with ease-of-use and\nsustainability in mind. Using only researchers' Google Scholar profiles as\ninput, PeopleMap can be readily adopted by any institution using its\npublicly-accessible repository and detailed documentation.",crownCaption:"PeopleMap visually maps out researchers based on their research interests\nand publications. Here, a PeopleMap user is exploring the research topics of\nthe faculty members at the Institute of Data Engineering and Science (IDEaS)\nat Georgia Tech (https:\u002F\u002Fpoloclub.github.io\u002Fpeople-map\u002Fideas\u002F) A. Map View\nvisualizes the embedding of researchers generated using their research\ntopics and publication data, with each dot representing a researcher. B.\nResearch Query allows users to search for researchers and query areas of\nstudy, allowing the user to both locate specific individuals and see the\nresearchers most associated with a queried field in the Map View. C.\nResearcher View shows the detailed information (e.g., affiliation,\ncitations, interests) of a researcher highlighted in Map View. D. Control\nPanel allows users to adjust the hyperparameters of the Map View\nvisualization (e.g., show research names and cluster information).",bibtex:"@article{saad-falconMappingResearchersPeopleMap2020,\n  title = {Mapping {{Researchers}} with {{PeopleMap}}},\n  author = {{Saad-Falcon}, Jon and Shaikh, Omar and Wang, Zijie J. and Wright, Austin P. and Richardson, Sasha and Chau, Duen Horng},\n  year = {2020},\n  journal = {Poster, IEEE Visualization Conference (VIS)}\n}"},{id:"argo-lite",title:"Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers",authors:["Siwei Li",$,"Anish Upadhayay",n,ak,g,a,"Susanta Routray","Matthew Hull",c],venue:"The Conference on Information and Knowledge Management",venueShort:al,venueURL:am,year:d,location:"Galway, Ireland",url:"\u002Fpapers\u002Fargo-lite",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2008.11844",repo:"poloclub\u002Fargo-graph-lite",showStar:b,type:o,demo:"https:\u002F\u002Fpoloclub.github.io\u002Fargo-graph-lite\u002F",abstract:"Graph data have become increasingly common. Visualizing them helps people\nbetter understand relations among entities. Unfortunately, existing graph\nvisualization tools are primarily designed for single-person desktop use,\noffering limited support for interactive web-based exploration and online\ncollaborative analysis. To address these issues, we have developed Argo\nLite, a new in-browser interactive graph exploration and visualization tool.\nArgo Lite enables users to publish and share interactive graph\nvisualizations as URLs and embedded web widgets. Users can explore graphs\nincrementally by adding more related nodes, such as highly cited papers\ncited by or citing a paper of interest in a citation network. Argo Lite\nworks across devices and platforms, leveraging WebGL for high-performance\nrendering. Argo Lite has been used by over 1,000 students at Georgia Tech's\nData and Visual Analytics class. Argo Lite may serve as a valuable\nopen-source tool for advancing multiple CIKM research areas, from data\npresentation, to interfaces for information systems and more.",crownCaption:"Argo Lite visualizing a citation network of recent COVID-19 publications.\nArgo Lite users can explore graphs incrementally by adding more\nrelated papers (e.g., highly cited papers cited by or citing a paper of\ninterest) to the visualization. Using WebGL for high-performance\ncross-platform graph rendering, Argo Lite runs in all modern web\nbrowsers without requiring any installation.",bibtex:"@article{liArgoLiteOpenSource2020,\n  title={Argo Lite: Open-Source Interactive Graph Exploration and Visualization in Browsers},\n  author={Li, Siwei and Zhou, Zhiyan and Upadhayay, Anish and Shaikh, Omar and Freitas, Scott and Park, Haekyu and Wang, Zijie J and Routray, Susanta and Hull, Matthew and Chau, Duen Horng},\n  booktitle={Proceedings of the International Conference on Information and Knowledge Management},\n  year={2020},\n  organization={ACM}\n}"},{id:an,title:"UnMask: Adversarial Detection and Defense Through Robust Feature Alignment",authors:[ak,"Shang-Tse Chen",a,c],venue:"IEEE International Conference on Big Data",venueShort:"BigData",venueURL:"https:\u002F\u002Fbigdataieee.org\u002FBigData2020\u002F",year:d,location:"Los Angeles, CA, USA",url:"\u002Fpapers\u002Funmask",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2002.09576",repo:"unmaskd\u002Funmask",type:o,abstract:"Deep learning models are being integrated into a wide range of high-impact,\nsecurity-critical systems, from self-driving cars to medical diagnosis.\nHowever, recent research has demonstrated that many of these deep learning\narchitectures are vulnerable to adversarial attacks--highlighting the vital\nneed for defensive techniques to detect and mitigate these attacks before\nthey occur. To combat these adversarial attacks, we developed UnMask, an\nadversarial detection and defense framework based on robust feature\nalignment. The core idea behind UnMask is to protect these models by\nverifying that an image's predicted class (\"bird\") contains the expected\nrobust features (e.g., beak, wings, eyes). For example, if an image is\nclassified as \"bird\", but the extracted features are wheel, saddle and\nframe, the model may be under attack. UnMask detects such attacks and\ndefends the model by rectifying the misclassification, re-classifying the\nimage based on its robust features. Our extensive evaluation shows that\nUnMask (1) detects up to 96.75% of attacks, with a false positive rate of\n9.66% and (2) defends the model by correctly classifying up to 93% of\nadversarial images produced by the current strongest attack, Projected\nGradient Descent, in the gray-box setting. UnMask provides significantly\nbetter protection than adversarial training across 8 attack vectors,\naveraging 31.18% higher accuracy. Our proposed method is architecture\nagnostic and fast. We open source the code repository and data with this\npaper: https:\u002F\u002Fgithub.com\u002Funmaskd\u002Funmask. ",crownShowBorder:b,crownCaption:"UnMask Framework Overview. UnMask combats adversarial attacks (in\nred) through extracting robust features from an image (“Bicycle” at top), and\ncomparing them to expected features of the classification (“Bird” at bottom)\nfrom the unprotected model. Low feature overlap signals an\nattack. UnMask rectifies misclassification using the image’s extracted\nfeatures. Our approach detects 96.75% of gray-box attacks (at 9.66% false\npositive rate) and defends the model by correctly classifying up to 93%\nof adversarial images crafted by Projected Gradient Descent (PGD).",bibtex:"@article{freitasUnMaskAdversarialDetection2020,\n  title = {{{UnMask}}: {{Adversarial Detection}} and {{Defense Through Robust Feature Alignment}}},\n  shorttitle = {{{UnMask}}},\n  author = {Freitas, Scott and Chen, Shang-Tse and Wang, Zijie J. and Chau, Duen Horng},\n  year = {2020},\n  archivePrefix = {arXiv},\n  eprint = {2002.09576},\n  eprinttype = {arxiv},\n  journal = {arXiv:2002.09576}\n}"},{id:"massif",title:"Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning",authors:[j,g,a,u,ae,af,c],equals:[j,g],venue:ao,venueURL:"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fabs\u002F10.1145\u002F3334480.3382977",venueShort:ap,location:aq,year:d,url:"\u002Fpapers\u002Fmassif",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2001.07769",type:o,abstract:"Deep neural networks (DNNs) are increasingly powering high-stakes\napplications such as autonomous cars and healthcare; however, DNNs are often\ntreated as \"black boxes\" in such applications. Recent research has also\nrevealed that DNNs are highly vulnerable to adversarial attacks, raising\nserious concerns over deploying DNNs in the real world. To overcome these\ndeficiencies, we are developing Massif, an interactive tool for deciphering\nadversarial attacks. Massif identifies and interactively visualizes neurons\nand their connections inside a DNN that are strongly activated or suppressed\nby an adversarial attack. Massif provides both a high-level, interpretable\noverview of the effect of an attack on a DNN, and a low-level, detailed\ndescription of the affected neurons. Massif's tightly coupled views help\npeople better understand which input features are most vulnerable and\nimportant for correct predictions.",crownCaption:"The MASSIF interface. A user Hailey is studying the targeted Fast Gradient\nMethod (FGM) attack performed on the InceptionV1 model. Using the control\npanel (A), she selects “giant panda” as the benign class and “armadillo” as\nthe attack target class. MASSIF generates an attribution graph (B), which\nshows Hailey the neurons within the network that are suppressed in the\nattacked images (B1, blue), shared by both benign and attacked images (B2,\npurple), and emphasized only in the attacked images (B3, orange). Each\nneuron is represented by a node and its feature visualization (C). Hovering\nover any neuron displays example dataset patches that maximally activate\nthe neuron, providing stronger evidence for what a neuron has learned to\ndetect. Hovering over a neuron also highlights its most influential\nconnections from the previous layer (D), allowing Hailey to determine where\nin the network the prediction diverges from the benign class to the attacked\nclass.",bibtex:"@inproceedings{das2020massif,\n  title={Massif: Interactive Interpretation of Adversarial Attacks on Deep Learning},\n  author={Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},\n  booktitle={Proceedings of the 2020 CHI Conference Extended Abstracts on Human Factors in Computing Systems},\n  publisher={ACM},\n  year={2020}\n}"},{id:"cnn-101",title:"CNN 101: Interactive Visual Learning for Convolutional Neural Networks",authors:[a,t,n,g,j,u,ac,c],venue:ao,venueShort:ap,location:aq,venueURL:"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fabs\u002F10.1145\u002F3334480.3382899",year:d,url:"\u002Fpapers\u002Fcnn-101",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2001.02004",type:o,video:"https:\u002F\u002Fyoutu.be\u002Fg082-zitM7s",crownCaption:"The Overview (A) visualizes activation maps of all neurons as heatmaps\nconnected with edges. When user clicks a convolutional neuron in (A), the\nview transitions to the Convolutional Intermediate View (A=\u003EB).The Flatten\nIntermediate View appears when an output neuron is selected instead\n(A=\u003EC). (B) demonstrates the relationship between selected convolutional\nneuron and its previous layer. (B) transitions to the Detail View which illustrates\nthe convolution operation on selected input neuron (B=\u003ED). (C) explains\nthe flatten layer between the second last layer and output layer.",abstract:"The success of deep learning solving previously-thought hard problems has\ninspired many non-experts to learn and understand this exciting technology.\nHowever, it is often challenging for learners to take the first steps due to\nthe complexity of deep learning models. We present our ongoing work, CNN\n101, an interactive visualization system for explaining and teaching\nconvolutional neural networks. Through tightly integrated interactive views,\nCNN 101 offers both overview and detailed descriptions of how a model works.\nBuilt using modern web technologies, CNN 101 runs locally in users' web\nbrowsers without requiring specialized hardware, broadening the public's\neducation access to modern deep learning techniques. ",bibtex:"@inproceedings{wangCNN101Interactive2020,\n  title = {{{CNN}} 101: {{Interactive}} Visual Learning for Convolutional Neural Networks},\n  booktitle = {Extended Abstracts of the 2020 {{CHI}} Conference on Human Factors in Computing Systems},\n  author = {Wang, Zijie J. and Turko, Robert and Shaikh, Omar and Park, Haekyu and Das, Nilaksh and Hohman, Fred and Kahng, Minsuk and Chau, Duen Horng},\n  year = {2020},\n  publisher = {{ACM}},\n  place = {{Honolulu, HI, USA}}\n}"},{id:"t-cell",title:"Classifying T cell activity in autofluorescence intensity images with convolutional neural networks",authors:[a,D,E,m],venue:"Journal of Biophotonics",venueShort:"J. Biophotonics",venueURL:"https:\u002F\u002Fonlinelibrary.wiley.com\u002Fjournal\u002F18640648",year:ar,url:"\u002Fpapers\u002Ft-cell",pdf:"https:\u002F\u002Fonlinelibrary.wiley.com\u002Fdoi\u002Fepdf\u002F10.1002\u002Fjbio.201960050",slides:"\u002Fslides\u002Fhonor_thesis_symposium_2019.pdf",repo:"gitter-lab\u002Ft-cell-classification",showStar:"flase",data:"https:\u002F\u002Fdoi.org\u002F10.5281\u002Fzenodo.2640835",type:"journal",crownShowBorder:b,crownCaption:"Our T cell image data processing workflow.",abstract:"The importance of T cells in immunotherapy has motivated developing\ntechnologies to better characterize T cells and improve therapeutic\nefficacy. One specific objective is assessing antigen-induced T cell\nactivation because only functionally active T cells are capable of killing\nthe desired targets. Autofluorescence imaging can distinguish T cell\nactivity states of individual cells in a non-destructive manner by detecting\nendogenous changes in metabolic co-enzymes such as NAD(P)H. However,\nrecognizing robust patterns of T cell activity is computationally\nchallenging in the absence of exogenous labels or information-rich\nautofluorescence lifetime measurements. We demonstrate that advanced machine\nlearning can accurately classify T cell activity from NAD(P)H intensity\nimages and that those image-based signatures transfer across human donors.\nUsing a dataset of 8,260 cropped single-cell images from six donors, we\nmeticulously evaluate multiple machine learning models. These range from\ntraditional models that represent images using summary statistics or extract\nimage features with CellProfiler to deep convolutional neural networks\n(CNNs) pre-trained on general non-biological images. Adapting pre-trained\nCNNs for the T cell activity classification task provides substantially\nbetter performance than traditional models or a simple CNN trained with the\nautofluorescence images alone. Visualizing the images with dimension\nreduction provides intuition into why the CNNs achieve higher accuracy than\nother approaches. However, we observe that fine-tuning all layers of the\npre-trained CNN does not provide a classification performance boost\ncommensurate with the additional computational cost. Our software detailing\nour image processing and model training pipeline is available as Jupyter\nnotebooks at https:\u002F\u002Fgithub.com\u002Fgitter-lab\u002Ft-cell-classification.",bibtex:"@article{wang_classifying_2019,\n  title = {Classifying {T} cell activity in autofluorescence intensity images with convolutional neural networks},\n  issn = {1864-063X, 1864-0648},\n  url = {https:\u002F\u002Fonlinelibrary.wiley.com\u002Fdoi\u002Fabs\u002F10.1002\u002Fjbio.201960050},\n  doi = {10.1002\u002Fjbio.201960050},\n  language = {en},\n  urldate = {2020-01-12},\n  journal = {Journal of Biophotonics},\n  author = {Wang, Zijie J. and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},\n  month = dec,\n  year = {2019}\n}"},{id:"t-cell-poster",title:"Classifying T cell activity with convolutional neural networks",authors:[a,D,E,m],venue:"International Society for Computational Biology Great Lakes Bioinformatics Conference",venueShort:"ISCB GLBIO",venueURL:"https:\u002F\u002Fwww.iscb.org\u002Fglbio2019",location:"Madison, WI, USA",year:ar,url:"\u002Fpapers\u002Ft-cell-poster",pdf:"\u002Fpdf\u002F19-tcell-glbio.pdf",code:"https:\u002F\u002Fgithub.com\u002Fgitter-lab\u002Ft-cell-classification",type:as,crownShowBorder:b,crownCaption:"Poster presented at the International Society for Computational Biology\nGreat Lakes Bioinformatics Conference (ISCB GLBIO).",abstract:"T cell activity state is an important component of immunotherapy efficacy in\nclinical cancer treatment. However, current image-based activity profiling\nmethods destroy cells and require exogenous contrast agents, making them\nunsuitable for clinical applications. In this study, we use non-destructive,\nT cell autofluorescence microscopy images to measure NAD(P)H intensity and\nclassify individual T cells as activated or quiescent. We assess five\nmachine learning methods of increasing complexity, ranging from linear\nclassifiers to deep convolutional neural networks pre-trained on generic\nimages. To evaluate these models and determine whether they are accurate\nacross different human T cell donors, we designed a meticulous nested\ncross-validation scheme to tune and test each model. A retrained\nconvolutional neural network, the most advanced model, achieved an average\naccuracy of 91.4% when classifying quiescent and activated T cells.\nImportantly, it gave 98% accuracy on an independent donor that was held out\nuntil all aspects of the training and tuning procedures were finalized. This\nshows that autofluorescence microscopy with a state-of-the-art image\nclassification algorithm is a powerful tool for label-free and\nnon-destructive assessment of T cell activity state, even when only NAD(P)H\nintensity is provided as the input feature. In addition, our high-throughput\nhyperparameter selection results give empirical insights on practical deep\nlearning deployment with microscopy image data. Similarly, the model\ncomparisons examined the tradeoff between performance and model complexity,\nwhich provides alternative methods that are suitable when computing resource\nare limited. We observe that retraining more layers in a pre-trained\nconvolutional neural network does not bring performance improvements that\njustify the high computational costs. Finally, we are preparing all of our\ncode in Jupyter notebooks with reproducible examples of image processing and\nclassification. These comprehensive notebooks serve as an instructional tool\nfor readers who are not familiar with machine learning application on\nmicroscopy images.",bibtex:"@inproceedings{wang_classifying_poster_2019,\n  title = {Classifying {T} cell activity with convolutional neural networks},\n  language = {en},\n  conference = {International Society for Computational Biology Great Lakes Bioinformatics Conference},\n  author = {Wang, Zijie J. and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},\n  year = {2019}\n}"},{id:"breast-poster",title:"Using Transfer Learning to Classify Breast Cancer Cells with Fluorescence Imaging",authors:[a,"Tiffany M. Heaster","Quan Yin",D,E,m],venue:"University of Wisconsin–Madison Undergraduate Symposium","venue-short":"",venueURL:"https:\u002F\u002Fugradsymposium.wisc.edu",year:2018,url:"\u002Fpapers\u002Fbreast-poster",pdf:"\u002Fpdf\u002F18-breast-symposium.pdf",type:as,abstract:"Studying tumor heterogeneity by analyzing protein or gene expression levels\nover thousands of cells is very challenging. In this project, we instead use\na transfer learning approach to classify cancer cell types solely based on\nfluorescence imaging. We used images of two types of breast cancer cell\nlines – MDA-MB-231 and SKBr3 – to partially retrain a deep convolutional\nneural network Inception v3, which was pre-trained on 10 million natural\nimages with over 400 categories. We hypothesize features extracted from\ngeneral pictures by a deep neural network are portable to classify breast\ncancer cell types. The ability to recognize distinct cell types within\ntumors would provide a powerful tool for analyzing clinical samples.",crownCaption:"Poster presented at the University of Wisconsin–Madison Undergraduate Symposium.",crownShowBorder:b,bibtex:"@inproceedings{wang_using_poster_2018,\n  title = {Using Transfer Learning to Classify Breast Cancer Cells with Fluorescence Imaging},\n  language = {en},\n  conference = {University of Wisconsin–Madison Undergraduate Symposium},\n  author = {Wang, Zijie J. and Heaster, Tiffany M. and Yin, Quan and Walsh, Alex J. and Skala, Melissa C. and Gitter, Anthony},\n  year = {2018}\n}"}],talk:[{name:ab,events:[{time:F,place:ag,url:w,video:"https:\u002F\u002Fyoutu.be\u002FM-pUfWMjXhQ?t=3308"},{time:A,place:"Deepkapha LiveAI",url:"https:\u002F\u002Fdeepkapha.ai\u002F",video:"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=56bkWcMfN7I"}]},{name:L,events:[{time:"Nov. 2019",place:"Out in Science, Technology, Engineering, and Mathematics (oSTEM) Conference",url:"https:\u002F\u002Fwww.ostem.org\u002F"},{time:"April 2019",place:"UW–Madison Senior Honors Thesis Symposium",url:"https:\u002F\u002Fhonors.ls.wisc.edu\u002Fwp-content\u002Fuploads\u002Fsites\u002F1038\u002F2019\u002F04\u002FSymposiumSchedule2019email.pdf"}]}],award:[{name:"Bosch Research Gift Funding ($37k)",description:"My visual analytics research during my internship results in $37,000 gift funding from Bosch.",url:"https:\u002F\u002Fwww.bosch.com\u002Fresearch\u002F",time:"Jan. 2021"},{name:"University Book Store Academic Excellence Award ($1k)",description:"An award recognizing undergraduate students who have completed an\noutstanding independent project, such as a senior thesis.",url:"https:\u002F\u002Fawards.advising.wisc.edu\u002Fcampus-wide-award-recipients\u002F2016-university-book-store-award-recipients\u002F",time:q},{name:"Honors Senior Thesis Summer Research Grant ($3k)",description:"A research grant funding students to undertake more demanding and extensive\nsenior thesis research projects.",url:"https:\u002F\u002Fhonors.ls.wisc.edu\u002Fsenior-thesis-summer-research-grants\u002F",time:"June 2018"},{name:"Welton Summer Sophomore Apprenticeship ($2.5k)",description:"A research grant awarded to talented students to participate in actual,\ncutting-edge research.",url:"https:\u002F\u002Fhonors.ls.wisc.edu\u002Fwelton-summer-sophomore-apprenticeships\u002F",time:"June 2017"},{name:"Dean's List",description:"Achieved at least a 3.60 GPA as freshmen and sophomores, a 3.85 GPA as\njuniors and seniors.",url:"https:\u002F\u002Fregistrar.wisc.edu\u002Fdeanslist\u002F",time:"Aug. 2015 – May 2019"}],teaching:[{title:"Graduate Teaching Assistant",school:p,schoolURL:"https:\u002F\u002Fwww.gatech.edu\u002F",course:"Data & Visual Analytics (CSE 6242)",courseURL:"https:\u002F\u002Fpoloclub.github.io\u002Fcse6242-2020fall-online\u002F",instructor:c,timeStart:A,timeEnd:"Dec. 2020",place:z,description:"Lead homework designs for data visualizations, hold weekly office hours, and answer student questions on Piazza. The course had 1277 graduate students enrolled.\n"},{title:"Undergraduate Teaching Assistant",school:e,schoolURL:x,course:"Computer Graphics (CS 559)",courseURL:"https:\u002F\u002Fgraphics.cs.wisc.edu\u002FWP\u002Fcs559-sp2019\u002Foverview\u002F",instructor:r,timeStart:Q,timeEnd:q,place:h,description:"Create course notes and weekly assignments, hold weekly office hours, and answer student questions on Piazza. The course had 180 undergraduates enrolled.\n"},{title:"Notetaker",school:e,schoolURL:x,course:"McBurney Disability Resource Center",courseURL:"https:\u002F\u002Fmcburney.wisc.edu\u002F",timeStart:"Sep. 2016",timeEnd:q,place:h,description:"Provide clearly-written math and statistics notes to students with disability, answer course-related questions.\n"},{title:"Academic Coach",school:e,schoolURL:x,course:"Division of Diversity, Equity and Educational Achievement",courseURL:"https:\u002F\u002Fdiversity.wisc.edu\u002Fabout\u002Fabout-ddeea\u002F",timeStart:"Nov. 2016",timeEnd:"May 2017",place:h,description:"Mentor undergraduate students in DDEEA programs for Data Structure course, design two worksheets and provided detailed solutions every week.\n"},{title:"Tutor",school:e,schoolURL:x,course:"Greater University Tutoring Service",courseURL:"https:\u002F\u002Fguts.wisc.edu\u002F",timeStart:"Jan. 2016",timeEnd:"Jan. 2017",place:h,description:"Instruct peers one-on-one in programming and math problems for three hours weekly, lead review sections to help students study for calculus exams.\n"}],mentoring:[{name:aj,timeStart:"May 2020",timeEnd:i,degree:G},{name:t,timeStart:k,timeEnd:i,degree:G,description:"Machine learning and visualization",awards:["PURA Travel Award (2020)"]},{name:n,timeStart:k,timeEnd:i,degree:G,awards:["Outstanding Freshman Award (2020)"]}],service:{review:[{venue:"IEEE Visualization & Visual Analytics",venueShort:C,url:"http:\u002F\u002Fieeevis.org",years:[{year:d,yearURL:w}]},{venue:"IEEE Pacific Visualization Symposium",venueShort:"PacificVis",url:"https:\u002F\u002Fieeexplore.ieee.org\u002Fxpl\u002Fconhome\u002F1001657\u002Fall-proceedings",years:[{year:f,yearURL:"http:\u002F\u002Fvis.tju.edu.cn\u002Fpvis2021\u002F"}]},{venue:"EG Conference on Visualization",venueShort:"EuroVis",url:"https:\u002F\u002Fwww.eurovis.org\u002F",years:[{year:f,yearURL:"https:\u002F\u002Fconferences.eg.org"}]},{venue:"Journal of Open Source Software",venueShort:"JOSS",url:"https:\u002F\u002Fjoss.theoj.org\u002F",years:[{year:d,yearURL:"https:\u002F\u002Fjoss.theoj.org"}]},{venue:"Rethinking ML Papers Workshop at ICLR",url:at,years:[{year:f,yearURL:at}]}],pc:[{venue:"ACM Conference on Information and Knowledge Management",venueShort:al,url:"https:\u002F\u002Fdl.acm.org\u002Fconference\u002Fcikm",years:[{year:d,yearURL:am}]},{venue:"ACM Conference on Information Retrieval",venueShort:"SIGIR",url:"https:\u002F\u002Fsigir.org\u002F",years:[{year:f,yearURL:"https:\u002F\u002Fsigir.org\u002Fsigir2021\u002Findex.html"}]},{venue:"European Conference on Machine Learning and Data Mining",venueShort:"ECML PKDD",url:"https:\u002F\u002Fecmlpkdd.org\u002F",years:[{year:f,yearURL:"https:\u002F\u002F2021.ecmlpkdd.org\u002F"}]}],membership:[{org:"Institute of Electrical and Electronics Engineers",orgShort:"IEEE",orgURL:"https:\u002F\u002Fwww.ieee.org\u002F",timeStart:"July 2019",timeEnd:i},{org:"Association for Computing Machinery",orgShort:"ACM",orgURL:"https:\u002F\u002Fwww.acm.org\u002F",timeStart:"Dec. 2019",timeEnd:i}]},reference:[{name:"Polo Chau",position:"Associate Professor",department:M,departmentURL:"https:\u002F\u002Fcse.gatech.edu\u002F",institution:p,institutionURL:y,url:"https:\u002F\u002Fcc.gatech.edu\u002F~dchau\u002F"},{name:U,position:"Principal Research Scientist",department:S,departmentURL:s,institution:R,institutionURL:s,url:J},{name:"Anghony Gitter",position:"Assistant Professor",department:"Department of Biostatistics and Medical Informatics",departmentURL:"https:\u002F\u002Fwww.biostat.wisc.edu\u002F",institution:e,institutionURL:l,url:"https:\u002F\u002Fwww.biostat.wisc.edu\u002F~gitter\u002F"},{name:r,position:"Professor",department:P,departmentURL:"https:\u002F\u002Fwww.cs.wisc.edu\u002F",institution:e,institutionURL:l,url:I}],skill:[{group:"Programming",items:["Python","JavaScript","Swift","R","Julia","PyTorch","TensorFlow","Keras","HTML","CSS","LaTeX","SQL","C++","Git"]},{group:"Design",items:["Affinity Designer","Affinity Photo","Final Cut Pro","Sketch","Keynote","Illustrator","Photoshop"]},{group:"HCI",items:["Think-aloud protocol","User Personas","Rapid Paper Prototyping","Affinity Diagraming"]}],news:[{date:"March 29, 2021",news:"Posted our \u003Ca href='https:\u002F\u002Farxiv.org\u002Fabs\u002F2103.14625' target='_self'\u003EDodrio paper\u003C\u002Fa\u003E on arXiv! Dodrio is an \u003Ca href='https:\u002F\u002Fpoloclub.github.io\u002Fdodrio\u002F' target='_self'\u003Einteractive visualization tool\u003C\u002Fa\u003E that helps researchers explore attention weights with linguistic knowledge.\n"},{date:"March 16, 2021",news:"New survey paper on\n\u003Ca href='papers\u002Fhuman-in-the-loop-nlp'\u003Ehuman-in-the-loop systems in NLP\u003C\u002Fa\u003E\nis accepted to the \n\u003Ca href='https:\u002F\u002Fsites.google.com\u002Fview\u002Fhciandnlp\u002Fhome'\u003EHCI + NLP workshop\u003C\u002Fa\u003E\nat EACL2021!"},{date:"Aug. 29, 2020",news:"Two papers,\n\u003Ca href='papers\u002Fcnn-explainer'\u003ECNN Explainer\u003C\u002Fa\u003E\nand\n\u003Ca href='papers\u002Fbluff'\u003EBluff\u003C\u002Fa\u003E,\nare accepted for IEEE VIS 2020!"},{date:"June 18, 2020",news:"Started my first internship at \u003Ca href='https:\u002F\u002Fwww.bosch.us\u002Four-company\u002Fbosch-in-the-usa\u002Fsunnyvale\u002F' target='_self'\u003EBosch (Sunnyvale)\u003C\u002Fa\u003E , working with \u003Ca href='https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Flianggou\u002F' target='_self'\u003ELiang Gou\u003C\u002Fa\u003E on visual analytics for autonomous driving.\n"},{date:"April 30, 2020",news:"Posted \u003Ca href='https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.15004' target='_self'\u003ECNN Explainer paper\u003C\u002Fa\u003E on arXiv. CNN Explainer an \u003Ca href='http:\u002F\u002Fpoloclub.github.io\u002Fcnn-explainer\u002F' target='_self'\u003Einteractive tool\u003C\u002Fa\u003E that helps beginners learn CNNs. It is also \u003Ca href='https:\u002F\u002Fgithub.com\u002Fpoloclub\u002Fcnn-explainer' target='_self'\u003Eopen-sourced\u003C\u002Fa\u003E on GitHub.\n"},{date:"Jan 15, 2020",news:"Two papers, \u003Ca href='papers\u002Fcnn-101' target='_self'\u003ECNN 101\u003C\u002Fa\u003E and \u003Ca href='papers\u002Fmassif' target='_self'\u003EMassif\u003C\u002Fa\u003E, are accepted for CHI 2020 Late-Breaking Works!\n"},{date:"Nov. 15, 2019",news:"I will present my T Cell Classification \u003Ca href='\u002Fpdf\u002Fglbio_2019.pdf' target='_self'\u003Eposter\u003C\u002Fa\u003E at \u003Ca href='https:\u002F\u002Fostem.org\u002Fpage\u002Fconference-2019' target='_self'\u003EoSTEM'19\u003C\u002Fa\u003E. See you in Detroit (really miss the Midwest winter!). \n"},{date:"Oct. 1, 2019",news:"I will attend \u003Ca href='http:\u002F\u002Fieeevis.org\u002Fyear\u002F2019\u002Fwelcome' target='_self'\u003EVIS'19\u003C\u002Fa\u003E in Vancouver. Come to talk to me :) \n"},{date:"Aug. 15, 2019",news:"Submitted my first \u003Ca href='https:\u002F\u002Fwww.biorxiv.org\u002Fcontent\u002F10.1101\u002F737346v1' target='_self'\u003Epaper\u003C\u002Fa\u003E on bioRxiv. Check it out!\n"},{date:"May. 11, 2019",news:"\u003Ca href='https:\u002F\u002Fweb.archive.org\u002Fweb\u002F20200928184759\u002Fhttps:\u002F\u002Fcommencement.wisc.edu\u002Fcontent\u002Fuploads\u002F2019\u002F05\u002FSaturday-May-11th-2019-Spring-Commencement-Ceremony-1.pdf' target='_self'\u003EI graduated!\u003C\u002Fa\u003E Will always be a proud badger!! 🦡\n"},{date:"April 20, 2019",news:"Honored to receive the 2019 \u003Ca href='https:\u002F\u002Fawards.advising.wisc.edu\u002Fcampus-wide-award-recipients\u002F2016-university-book-store-award-recipients\u002F' target='_self'\u003E University Book Store Academic Excellence Award\u003C\u002Fa\u003E.\n"},{date:"April 10, 2019",news:"Excited to present my T-cell classification project as a poster in     \u003Ca href='https:\u002F\u002Fwww.iscb.org\u002Fglbio2019' target='_self'\u003EGLBIO'19\u003C\u002Fa\u003E.\n"}],featured:[{id:V,featureImg:"\u002Fimages\u002Fteasers\u002Fdodrio.png"},{id:aa,featureImg:"\u002Fimages\u002Fteasers\u002Fcnn-explainer.png"},{id:ad,featureImg:"\u002Fimages\u002Fteasers\u002Fbluff.png"},{id:_,featureImg:"\u002Fimages\u002Fteasers\u002Fskeleton-vis.png"},{id:an,featureImg:"\u002Fimages\u002Fteasers\u002Funmask.png"},{id:ah,featureImg:"\u002Fimages\u002Fteasers\u002Fai-guideline.png"}],project:[{name:"Clip2imgur",repo:"xiaohk\u002Fclip2imgur",teaser:"\u002Fimages\u002Fteasers\u002Fproject-clip2imgur.png",award:{name:"Featured on Imgur",url:"https:\u002F\u002Fhelp.imgur.com\u002Fhc\u002Fen-us\u002Farticles\u002F209592766-Tools-for-Imgur"},description:"Convenient macOS command line tool for uploading screen-shots from the clipboard to Imgur. \n"},{name:"FaceData",repo:"xiaohk\u002FFaceData",showStar:b,teaser:"\u002Fimages\u002Fteasers\u002Fproject-face.jpg",description:"MacOS GUI to auto-annotate facial landmarks from a video. Landmarks can be used to train GANs.\n"},{name:"Graphics on the Web",repo:au,demo:"http:\u002F\u002Fjayw-www.cs.wisc.edu\u002Fcs559\u002Fp10\u002F",teaser:"\u002Fimages\u002Fteasers\u002Fproject-graphics.png",description:"Interactive 2D, 2.5D and 3D computational graphics with shaders and textures, created with HTML canvas and webGL.\n"},{name:"Group Assignment Problem",repo:au,demo:"https:\u002F\u002Fnbviewer.jupyter.org\u002Fgithub\u002Fxiaohk\u002FCS524-Group-Assignment-Optimization\u002Fblob\u002Fmaster\u002FWang.ipynb",teaser:"\u002Fimages\u002Fteasers\u002Fproject-optim.png",award:{name:"Best project",url:"https:\u002F\u002Fweb.archive.org\u002Fweb\u002F20200917025916\u002Fhttps:\u002F\u002Flaurentlessard.com\u002Fteaching\u002F524-intro-to-optimization\u002F"},description:"Flexible and robust Mixed Integer Quadratic Programming model written in Julia to solve a real-life optimization problem.\n"},{name:"Dean's list Vis",demo:"http:\u002F\u002Fjayw-www.cs.wisc.edu\u002Fd3-china-map\u002F",repo:"xiaohk\u002Fd3-china-map",teaser:"\u002Fimages\u002Fteasers\u002Fproject-map.png",description:"Interactive geo-visualization to explore where UW–Madison Chinese students are from.\n"},{name:"Yelp Sentiment",repo:"xiaohk\u002Fstat333_project_2",teaser:"\u002Fimages\u002Fteasers\u002Fproject-review.png",award:{name:"Kaggle winner",url:"https:\u002F\u002Fwww.kaggle.com\u002Fc\u002Fuw-madison-sp17-stat333"},description:"Predicting Yelp ratings based on text comments of restaurants at Madison Wisconsin.\n"}],press:[{title:"Why is This New Deep Learning Visualization Going Viral?",url:"https:\u002F\u002Fwww.cse.gatech.edu\u002Fnews\u002F640835\u002Fwhy-new-deep-learning-visualization-going-viral",press:"Georgia Tech CSE",date:F},{title:"Learn Machine Learning Concepts Interactively",url:"https:\u002F\u002Ftowardsdatascience.com\u002Flearn-machine-learning-concepts-interactively-6c3f64518da2",press:"Towards Data Science",date:F},{title:"CNN Explainer that can Understand the Image Identification Process of Deep Learning",url:"https:\u002F\u002Fgigazine.net\u002Fgsc_news\u002Fen\u002F20200707-cnn-explainer\u002F",press:"Gigazine",date:"July 2020",languages:[{lang:"Japanese",title:"ディープラーニングの手法「CNN」の画像識別処理がアニメーションで理解できる「CNN Explainer」",url:"https:\u002F\u002Fgigazine.net\u002Fnews\u002F20200707-cnn-explainer\u002F"}]},{title:"How Do Neural Networks Learn?",url:"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=N6wn8zMRlVE&feature=youtu.be",press:"Two Minute Papers",date:T},{title:"DARPA Snags Intel to Lead its Machine Learning Security Tech",url:"https:\u002F\u002Ftechcrunch.com\u002F2020\u002F04\u002F09\u002Fintel-darpa-machine-learning\u002F",press:"Tech Crunch",date:av},{title:"Intel Joins Georgia Tech in DARPA Program to Mitigate Machine Learning Deception Attacks",url:"https:\u002F\u002Fnewsroom.intel.com\u002Fnews\u002Fintel-joins-georgia-tech-darpa-program-mitigate-machine-learning-deception-attacks",press:"Intel News Byte",date:av}],redirect:{"dodrio-video":X}}}}("Zijie J. Wang",true,"Duen Horng (Polo) Chau",2020,"University of Wisconsin–Madison",2021,"Haekyu Park","Madison, WI","Present","Nilaksh Das","Aug. 2019","https:\u002F\u002Fwww.wisc.edu","Anthony Gitter","Omar Shaikh","arxiv","Georgia Institute of Technology","May 2019","Michael Gleicher","https:\u002F\u002Fwww.bosch.us\u002Four-company\u002Fbosch-in-the-usa\u002Fsunnyvale\u002F","Robert Turko","Fred Hohman","Salt Lake City, UT, USA","http:\u002F\u002Fieeevis.org\u002Fyear\u002F2020\u002Fwelcome","https:\u002F\u002Fwww.wisc.edu\u002F","https:\u002F\u002Fwww.gatech.edu","Atlanta, GA","Aug. 2020",false,"VIS","Alex J. Walsh","Melissa C. Skala","Oct. 2020","B.S. in Computer Science, Georgia Institute of Technology","https:\u002F\u002Fwww.cc.gatech.edu\u002F~dchau","http:\u002F\u002Fpages.cs.wisc.edu\u002F~gleicher\u002F","https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Flianggou\u002F","Yu Hen Hu","Classifying T Cell Activity with Convolutional Neural Networks","School of Computational Science and Engineering","Undergraduate Researcher","Dec. 2017","Department of Computer Sciences","Dec. 2018","Bosch Research","Human–Machine Interaction","June 2020","Liang Gou","dodrio","https:\u002F\u002Farxiv.org\u002Fabs\u002F2103.14625","https:\u002F\u002Fyoutu.be\u002FqB-T9j7UTgE","Dongjin Choi","Shenyu Xu","skeleton-vis","Zhiyan Zhou","cnn-explainer","CNN Explainer: Learning Convolutional Neural Networks with Interactive Visualization","Minsuk Kahng","bluff","Robert Firstman","Emily Rogers","IEEE Visualization Conference","ai-guideline","Austin P. Wright","Jon Saad-Falcon","Scott Freitas","CIKM","https:\u002F\u002Fwww.cikm2020.org\u002F","unmask","Extended Abstracts on ACM Human Factors in Computing Systems","CHI","Honolulu, HI, USA",2019,"poster","https:\u002F\u002Frethinkingmlpapers.github.io\u002F","xiaohk\u002FCS559-computational-graphics","April 2020"))]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');(function(){try{eval("async function x(){}");var main="/client/client.65134f1f.js"}catch(e){main="/client/legacy/client.117ca033.js"};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src=main;s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@1.0.1.js";s.setAttribute("data-main",main);}document.head.appendChild(s);}());</script> 