<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#333333 name=theme-color> <base href=/ > <link href=global.css rel=stylesheet> <link href=manifest.json rel=manifest> <link href=favicon.ico rel=icon type=image/png> <link href="https://fonts.googleapis.com/css2?family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Roboto+Mono:ital,wght@0,100;0,300;0,400;0,500;0,700;1,100;1,300;1,400;1,500;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet> <link href=client/main.3754935911.css rel=stylesheet><link href=client/[slug].c1740130.css rel=stylesheet><link href=client/client.53600047.css rel=stylesheet> <noscript id=sapper-head-start></noscript><title>Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks — Jay Wang</title><meta content="Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks — Jay Wang" name=title><meta content="Deep neural networks (DNNs) are now commonly used in many domains. However,
they are vulnerable to adversarial attacks: carefully crafted perturbation..." name=description><meta content=website property=og:type><meta content=https://zijie.wang property=og:url><meta content="Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks — Jay Wang" property=og:title><meta content="Deep neural networks (DNNs) are now commonly used in many domains. However,
they are vulnerable to adversarial attacks: carefully crafted perturbation..." property=og:description><meta content=https://zijie.wang/images/crowns/bluff.png property=og:image><meta content=summary_large_image property=twitter:card><meta content=https://zijie.wang property=twitter:url><meta content="Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks — Jay Wang" property=twitter:title><meta content="Deep neural networks (DNNs) are now commonly used in many domains. However,
they are vulnerable to adversarial attacks: carefully crafted perturbation..." property=twitter:description><meta content=https://zijie.wang/images/crowns/bluff.png property=twitter:image><meta content=@jay4w property=twitter:site><meta content=@jay4w property=twitter:creator><script async src="https://www.googletagmanager.com/gtag/js?id=UA-130177683-1"></script><script>window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-130177683-1'); </script><noscript id=sapper-head-end></noscript> </head> <body> <div id=sapper> <nav class=svelte-1w9yw1c><div class=left-padding></div> <div class="svelte-1w9yw1c header-main"><div class="svelte-1w9yw1c header"><a class=svelte-1w9yw1c href=.><div class="svelte-1w9yw1c header-item header-item-name">Jay Wang</div></a> <div class="svelte-1w9yw1c header-other"><a class=svelte-1w9yw1c href=/cv><div class="svelte-1w9yw1c header-item header-other-item">CV</div></a> <a class=svelte-1w9yw1c href=/cv#publications><div class="svelte-1w9yw1c header-item header-other-item">Publications</div></a></div></div></div> <div class=right-padding></div></nav> <main class=svelte-1jybnva> <div class="svelte-1a8t81v page"><div class=left-padding></div> <div class="svelte-1a8t81v papers-content"><h1 class=svelte-1a8t81v>Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks</h1> <div class="svelte-1a8t81v author-list"><a class=svelte-1a8t81v href=https://nilakshdas.com target=_self><div class="svelte-1a8t81v author"><img alt="Nilaksh Das picture" class=svelte-1a8t81v src="images/people/Nilaksh Das.jpg"> <div class="svelte-1a8t81v author-name">Nilaksh Das*</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://haekyu.com target=_self><div class="svelte-1a8t81v author"><img alt="Haekyu Park picture" class=svelte-1a8t81v src="images/people/Haekyu Park.jpg"> <div class="svelte-1a8t81v author-name">Haekyu Park*</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://zijie.wang target=_self><div class="svelte-1a8t81v author"><img alt="Zijie J. Wang picture" class=svelte-1a8t81v src="images/people/Zijie J. Wang.jpg"> <div class="svelte-1a8t81v author-name">Zijie J. Wang</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://fredhohman.com target=_self><div class="svelte-1a8t81v author"><img alt="Fred Hohman picture" class=svelte-1a8t81v src="images/people/Fred Hohman.jpg"> <div class="svelte-1a8t81v author-name">Fred Hohman</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://www.robfirstman.com/ target=_self><div class="svelte-1a8t81v author"><img alt="Robert Firstman picture" class=svelte-1a8t81v src="images/people/Robert Firstman.jpg"> <div class="svelte-1a8t81v author-name">Robert Firstman</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://www.linkedin.com/in/emily-rogers-1a828598 target=_self><div class="svelte-1a8t81v author"><img alt="Emily Rogers picture" class=svelte-1a8t81v src="images/people/Emily Rogers.jpg"> <div class="svelte-1a8t81v author-name">Emily Rogers</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://www.cc.gatech.edu/~dchau target=_self><div class="svelte-1a8t81v author"><img alt="Duen Horng (Polo) Chau picture" class=svelte-1a8t81v src="images/people/Duen Horng (Polo) Chau.jpg"> <div class="svelte-1a8t81v author-name">Duen Horng (Polo) Chau</div> <div class=author-comma></div></div> </a></div> <div class="svelte-1a8t81v icon-container italic">( * Authors contributed equally )</div> <div class="svelte-1a8t81v venue"><a class=svelte-1a8t81v href=http://ieeevis.org/year/2020/welcome target=_self>IEEE Visualization Conference (VIS), 2020</a></div> <figure class="svelte-1a8t81v crown-img"><img alt="crown jewel figure" class=svelte-1a8t81v src=images/crowns/bluff.png style=""> <figcaption class="svelte-1a8t81v crown-caption">With Bluff, users interactively visualize how adversarial attacks penetrate a deep neural network to induce incorrect outcomes. Here, a user inspects why Inception V1 misclassifies adversarial giant panda images, crafted by the Projected Gradient Descent (PGD) attack, as armadillo. PGD successfully perturbed pixels to induce the “brown bird” feature, an appearance more likely shared by an armadillo (small, roundish, brown body) than a panda, activating more features that contribute to the armadillo (mis)classification (e.g., “scales,” “bumps,” “mesh”). The adversarial pathways, formed by these neurons and their connections, overwhelm the benign panda pathways and lead to the ultimate misclassification. (A) Control Side bar allows users to specify what data is to be included and highlighted. (B) Graph Summary View visualizes pathways most activated or changed by an attack as a network graph of neurons (each labeled by the channel ID in its layer) and their connections. When hovering over a neuron, (C) Detail View displays its feature visualization, representative dataset examples, and activation patterns over attack strengths.</figcaption></figure> <div class=block-container> <div class="svelte-1a8t81v block"><div class="svelte-1a8t81v block-name">Abstract</div> <div class=block-abstract-text>Deep neural networks (DNNs) are now commonly used in many domains. However, they are vulnerable to adversarial attacks: carefully crafted perturbations on data inputs that can fool a model into making incorrect predictions. Despite significant research on developing DNN attack and defense techniques, people still lack an understanding of how such attacks penetrate a model's internals. We present Bluff, an interactive system for visualizing, characterizing, and deciphering adversarial attacks on vision-based neural networks. Bluff allows people to flexibly visualize and compare the activation pathways for benign and attacked images, revealing mechanisms that adversarial attacks employ to inflict harm on a model. Bluff is open-sourced and runs in modern web browsers. </div></div> <div class="svelte-1a8t81v block citation-block"><div class="svelte-1a8t81v block-name">Citation</div> <div class="svelte-1a8t81v pub-title">Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks</div> <div class="svelte-1a8t81v pub-author"><a class=svelte-1a8t81v href=https://nilakshdas.com target=_self><div class="svelte-1a8t81v author citation"><div class="svelte-1a8t81v author-name citation">Nilaksh Das*</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://haekyu.com target=_self><div class="svelte-1a8t81v author citation"><div class="svelte-1a8t81v author-name citation">Haekyu Park*</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://zijie.wang target=_self><div class="svelte-1a8t81v author citation"><div class="svelte-1a8t81v author-name citation">Zijie J. Wang</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://fredhohman.com target=_self><div class="svelte-1a8t81v author citation"><div class="svelte-1a8t81v author-name citation">Fred Hohman</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://www.robfirstman.com/ target=_self><div class="svelte-1a8t81v author citation"><div class="svelte-1a8t81v author-name citation">Robert Firstman</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://www.linkedin.com/in/emily-rogers-1a828598 target=_self><div class="svelte-1a8t81v author citation"><div class="svelte-1a8t81v author-name citation">Emily Rogers</div> <div class=author-comma>,</div></div> </a><a class=svelte-1a8t81v href=https://www.cc.gatech.edu/~dchau target=_self><div class="svelte-1a8t81v author citation"><div class="svelte-1a8t81v author-name citation">Duen Horng (Polo) Chau</div> <div class=author-comma></div></div> </a></div> <div class="svelte-1a8t81v pub-venue"><a class=svelte-1a8t81v href=http://ieeevis.org/year/2020/welcome target=_self>IEEE Visualization Conference (VIS), 2020</a></div> <div class="svelte-1a8t81v pub-icons"><a class="svelte-1a8t81v icon-container" href=https://poloclub.github.io/bluff/ target=_self><div class="svelte-1a8t81v svg-icon"><svg class=svelte-1a8t81v viewBox="0 0 100 100"><use xlink:href=/sprite.svg#rocket-sharp></use></svg></div> <span class=svelte-1a8t81v>Demo</span></a> <a class="svelte-1a8t81v icon-container" href=https://arxiv.org/abs/2009.02608 target=_self><div class="svelte-1a8t81v svg-icon"><svg class=svelte-1a8t81v viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1a8t81v>PDF</span></a> <div class="svelte-1a8t81v icon-container"><a class="svelte-1a8t81v icon-container no-right-margin" href=https://github.com/poloclub/bluff target=_self><div class="svelte-1a8t81v svg-icon"><svg class=svelte-1a8t81v viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1a8t81v>Code</span></a> </div> <div class="svelte-1a8t81v icon-container comment">(*Authors contributed equally)</div></div> <div class="svelte-1a8t81v bibtex"><pre class=svelte-1a8t81v>@article{dasBluffInteractivelyDeciphering2020,
  title={Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks},
  author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng},
  booktitle={IEEE Visualization Conference (VIS)},
  publisher={IEEE},
  year={2020}
}</pre></div></div></div> </div> <div class=right-padding></div></div></main> <footer class=svelte-1pltrfa><div class=left-padding></div> <div class="svelte-1pltrfa footer-main"><div class="svelte-1pltrfa footer"><div class="svelte-1pltrfa footer-item"><span>Designed and built by <a class="svelte-1pltrfa raleway" href=.>Jay Wang</a> with</span> <div class="svelte-1pltrfa svg-icon"><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#t-heart></use></svg></div> <span>using <a class=svelte-1pltrfa href=https://svelte.dev/ target=_self>Svelte</a> and <a class=svelte-1pltrfa href=https://sapper.svelte.dev/ target=_self>Sapper</a>.</span></div> <div class="svelte-1pltrfa footer-other"><div class=footer-icons><a class="svelte-1pltrfa svg-icon" href=cv target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-alt-regular></use></svg></a> <a class="svelte-1pltrfa svg-icon" href=https://github.com/xiaohk target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></a> <a class="svelte-1pltrfa svg-icon" href="https://scholar.google.com/citations?user=eouAYvcAAAAJ&hl=en" target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#google-scholar></use></svg></a> <a class="svelte-1pltrfa svg-icon" href=http://twitter.com/jay4w target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#twitter-brands></use></svg></a> <a class="svelte-1pltrfa svg-icon" href=https://www.linkedin.com/in/zijiewang/ target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#linkedin-brands></use></svg></a> <a class="svelte-1pltrfa svg-icon" href=mailto:jayw@gatech.edu target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#envelope-regular></use></svg></a></div> <div>© 2021 <a class="svelte-1pltrfa raleway" href=.>Zijie Jay Wang</a></div></div></div></div> <div class=right-padding></div></footer></div> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,null,(function(a,b,c){return {curPub:{id:"bluff",title:"Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks",authors:[a,b,"Zijie J. Wang","Fred Hohman","Robert Firstman","Emily Rogers","Duen Horng (Polo) Chau"],equals:[a,b],venue:"IEEE Visualization Conference",venueURL:"http:\u002F\u002Fieeevis.org\u002Fyear\u002F2020\u002Fwelcome",venueShort:"VIS",location:"Salt Lake City, UT, USA",year:2020,url:"\u002Fpapers\u002Fbluff",pdf:"https:\u002F\u002Farxiv.org\u002Fabs\u002F2009.02608",repo:"poloclub\u002Fbluff",showStar:false,demo:"https:\u002F\u002Fpoloclub.github.io\u002Fbluff\u002F",abstract:"Deep neural networks (DNNs) are now commonly used in many domains. However,\nthey are vulnerable to adversarial attacks: carefully crafted perturbations\non data inputs that can fool a model into making incorrect predictions.\nDespite significant research on developing DNN attack and defense\ntechniques, people still lack an understanding of how such attacks penetrate\na model's internals. We present Bluff, an interactive system for\nvisualizing, characterizing, and deciphering adversarial attacks on\nvision-based neural networks. Bluff allows people to flexibly visualize and\ncompare the activation pathways for benign and attacked images, revealing\nmechanisms that adversarial attacks employ to inflict harm on a model. Bluff\nis open-sourced and runs in modern web browsers. ",crownCaption:"With Bluff, users interactively visualize how adversarial attacks penetrate\na deep neural network to induce incorrect outcomes. Here, a user inspects\nwhy Inception V1 misclassifies adversarial giant panda images, crafted by\nthe Projected Gradient Descent (PGD) attack, as armadillo. PGD successfully\nperturbed pixels to induce the “brown bird” feature, an appearance more\nlikely shared by an armadillo (small, roundish, brown body) than a panda,\nactivating more features that contribute to the armadillo (mis)classification\n(e.g., “scales,” “bumps,” “mesh”). The adversarial pathways, formed by these\nneurons and their connections, overwhelm the benign panda pathways and lead\nto the ultimate misclassification. (A) Control Side bar allows users to\nspecify what data is to be included and highlighted. (B) Graph Summary View\nvisualizes pathways most activated or changed by an attack as a network\ngraph of neurons (each labeled by the channel ID in its layer) and their\nconnections. When hovering over a neuron, (C) Detail View displays its\nfeature visualization, representative dataset examples, and activation\npatterns over attack strengths.",bibtex:"@article{dasBluffInteractivelyDeciphering2020,\n  title={Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks},\n  author={Das, Nilaksh and Park, Haekyu and Wang, Zijie J and Hohman, Fred and Firstman, Robert and Rogers, Emily and Chau, Duen Horng},\n  booktitle={IEEE Visualization Conference (VIS)},\n  publisher={IEEE},\n  year={2020}\n}"},people:{"Zijie J. Wang":{url:"https:\u002F\u002Fzijie.wang",isMe:true},"Anthony Gitter":{url:"https:\u002F\u002Fwww.biostat.wisc.edu\u002F~gitter"},"Melissa C. Skala":{url:"https:\u002F\u002Fmorgridge.org\u002Fresearch\u002Fmedical-engineering\u002Foptical-microscopy"},"Alex J. Walsh":{url:"https:\u002F\u002Fqoil.engr.tamu.edu"},"Duen Horng (Polo) Chau":{url:c},"Polo Chau":{url:c},"Fred Hohman":{url:"https:\u002F\u002Ffredhohman.com"},"Minsuk Kahng":{url:"https:\u002F\u002Fminsuk.com"},"Haekyu Park":{url:"https:\u002F\u002Fhaekyu.com"},"Nilaksh Das":{url:"https:\u002F\u002Fnilakshdas.com"},"Robert Turko":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Frobert-turko\u002F"},"Omar Shaikh":{url:"http:\u002F\u002Foshaikh.com\u002F"},"Michael Gleicher":{url:"http:\u002F\u002Fpages.cs.wisc.edu\u002F~gleicher\u002F"},"Yu Hen Hu":{url:"http:\u002F\u002Fhomepages.cae.wisc.edu\u002F~hu\u002F"},"Tiffany M. Heaster":{url:"https:\u002F\u002Fmorgridge.org\u002Fprofile\u002Ftiffany-heaster\u002F"},"Quan Yin":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fquan-yin\u002F"},"Emily Rogers":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Femily-rogers-1a828598"},"Robert Firstman":{url:"https:\u002F\u002Fwww.robfirstman.com\u002F"},"Scott Freitas":{url:"https:\u002F\u002Fwww.scottfreitas.com\u002F"},"Shang-Tse Chen":{url:"https:\u002F\u002Fwww.cc.gatech.edu\u002F~schen351\u002F"},"Jon Saad-Falcon":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fjonsaadfalcon\u002F"},"Austin P. Wright":{url:"https:\u002F\u002Faustinpwright.com\u002F"},"Sasha Richardson":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fsasha-richardson\u002F"},"Siwei Li":{url:"https:\u002F\u002Frsli.github.io\u002F"},"Zhiyan Zhou":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Ffrank-zhou-b19515159\u002F"},"Anish Upadhayay":{url:"https:\u002F\u002Fgithub.com\u002Faupadhayay3"},"Susanta Routray":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fsusantaroutray\u002F"},"Matthew Hull":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fmdhull\u002F"},"Liang Gou":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Flianggou\u002F"},"Grace Guo":{url:"https:\u002F\u002Fgracegsy.github.io\u002F"},"Fabian Sperrle":{url:"https:\u002F\u002Fwww.vis.uni-konstanz.de\u002Fmitglieder\u002Fsperrle\u002F"},"Mennatallah El-Assady":{url:"https:\u002F\u002Fel-assady.com\u002F"},"Alex Endert":{url:"https:\u002F\u002Fva.gatech.edu\u002Fendert\u002F"},"Daniel Keim":{url:"https:\u002F\u002Fwww.vis.uni-konstanz.de\u002Fen\u002Fmembers\u002Fkeim"},"Anindya S. Paul":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fanindyasankar\u002F"},"Pruthvi Perumalla":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fpruthvi-perumalla\u002F"},"Dongjin Choi":{url:"https:\u002F\u002Fwww.jinchoi.xyz"},"Shenyu Xu":{url:"https:\u002F\u002Fthomasxu2009.github.io"},"Diyi Yang":{url:"https:\u002F\u002Fwww.cc.gatech.edu\u002F~dyang888\u002F"}}}}("Nilaksh Das","Haekyu Park","https:\u002F\u002Fwww.cc.gatech.edu\u002F~dchau"))]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');(function(){try{eval("async function x(){}");var main="/client/client.53600047.js"}catch(e){main="/client/legacy/client.9fac1354.js"};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src=main;s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@1.0.1.js";s.setAttribute("data-main",main);}document.head.appendChild(s);}());</script> 