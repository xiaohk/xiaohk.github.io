<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#333333 name=theme-color> <base href=/ > <link href=global.css rel=stylesheet> <link href=manifest.json rel=manifest> <link href=favicon.ico rel=icon type=image/png> <link href="https://fonts.googleapis.com/css2?family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Roboto+Mono:ital,wght@0,100;0,300;0,400;0,500;0,700;1,100;1,300;1,400;1,500;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet> <link href=client/main.3754935911.css rel=stylesheet><link href=client/[slug].c1740130.css rel=stylesheet><link href=client/client.53600047.css rel=stylesheet> <noscript id=sapper-head-start></noscript><title>Dodrio: Exploring Transformer Models with Interactive Visualization — Jay Wang</title><meta content="Dodrio: Exploring Transformer Models with Interactive Visualization — Jay Wang" name=title><meta content="Why do large pre-trained transformer-based models perform so well across a
wide variety of NLP tasks? Recent research suggests the key may lie in
mult..." name=description><meta content=website property=og:type><meta content=https://zijie.wang property=og:url><meta content="Dodrio: Exploring Transformer Models with Interactive Visualization — Jay Wang" property=og:title><meta content="Why do large pre-trained transformer-based models perform so well across a
wide variety of NLP tasks? Recent research suggests the key may lie in
mult..." property=og:description><meta content=https://zijie.wang/images/crowns/dodrio.png property=og:image><meta content=summary_large_image property=twitter:card><meta content=https://zijie.wang property=twitter:url><meta content="Dodrio: Exploring Transformer Models with Interactive Visualization — Jay Wang" property=twitter:title><meta content="Why do large pre-trained transformer-based models perform so well across a
wide variety of NLP tasks? Recent research suggests the key may lie in
mult..." property=twitter:description><meta content=https://zijie.wang/images/crowns/dodrio.png property=twitter:image><meta content=@jay4w property=twitter:site><meta content=@jay4w property=twitter:creator><script async src="https://www.googletagmanager.com/gtag/js?id=UA-130177683-1"></script><script>window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-130177683-1'); </script><noscript id=sapper-head-end></noscript> </head> <body> <div id=sapper> <nav class=svelte-1w9yw1c><div class=left-padding></div> <div class="svelte-1w9yw1c header-main"><div class="svelte-1w9yw1c header"><a href=. class=svelte-1w9yw1c><div class="svelte-1w9yw1c header-item header-item-name">Jay Wang</div></a> <div class="svelte-1w9yw1c header-other"><a href=/cv class=svelte-1w9yw1c><div class="svelte-1w9yw1c header-item header-other-item">CV</div></a> <a href=/cv#publications class=svelte-1w9yw1c><div class="svelte-1w9yw1c header-item header-other-item">Publications</div></a></div></div></div> <div class=right-padding></div></nav> <main class=svelte-1jybnva> <div class="svelte-1a8t81v page"><div class=left-padding></div> <div class="svelte-1a8t81v papers-content"><h1 class=svelte-1a8t81v>Dodrio: Exploring Transformer Models with Interactive Visualization</h1> <div class="svelte-1a8t81v author-list"><a href=https://zijie.wang class=svelte-1a8t81v target=_self><div class="svelte-1a8t81v author"><img alt="Zijie J. Wang picture" class=svelte-1a8t81v src="images/people/Zijie J. Wang.jpg"> <div class="svelte-1a8t81v author-name">Zijie J. Wang</div> <div class=author-comma>,</div></div> </a><a href=https://www.linkedin.com/in/robert-turko/ class=svelte-1a8t81v target=_self><div class="svelte-1a8t81v author"><img alt="Robert Turko picture" class=svelte-1a8t81v src="images/people/Robert Turko.jpg"> <div class="svelte-1a8t81v author-name">Robert Turko</div> <div class=author-comma>,</div></div> </a><a href=https://www.cc.gatech.edu/~dchau class=svelte-1a8t81v target=_self><div class="svelte-1a8t81v author"><img alt="Duen Horng (Polo) Chau picture" class=svelte-1a8t81v src="images/people/Duen Horng (Polo) Chau.jpg"> <div class="svelte-1a8t81v author-name">Duen Horng (Polo) Chau</div> <div class=author-comma></div></div> </a></div> <div class="svelte-1a8t81v venue"><a href=https://arxiv.org/abs/2103.14625 class=svelte-1a8t81v target=_self>arXiv:2103.14625 (arXiv), 2021</a></div> <figure class="svelte-1a8t81v crown-img"><img alt="crown jewel figure" class=svelte-1a8t81v src=images/crowns/dodrio.png style=""> <figcaption class="svelte-1a8t81v crown-caption">The Dodrio user interface showing user exploration of connections between attention weights from a fine-tuned BERT model and syntactic dependencies as well as semantic saliency scores on the SST2 dataset. (A) In the Dependency View, a user hovers over a word from the input sentence, highlighting its associated dependency directed links as orange arcs (lighter is source; darker is target). (B) Semantic Attention Graph highlights the word’s related tokens and their attentions; nodes are tokens (darker means more salient), a directed edge encodes attention weight between two tokens.(C) The Attention Head Overview shows all attention heads in a multi-layer and multi-head model as a grid of circles, each head is (D) colored based on its linguistic knowledge in the model (more red → more semantic-aligned, more blue → more syntactic-aligned; darker → more aligned), and sized based on its importance score in the model (larger → more important)</figcaption></figure> <div class=block-container> <div class="svelte-1a8t81v block video-block"><div class="svelte-1a8t81v block-name">Demo Video</div> <div class="svelte-1qjupgm video"><div class="svelte-1qjupgm video-container"><iframe allowfullscreen class=svelte-1qjupgm frameborder=0 height=315 src=https://www.youtube.com/embed/qB-T9j7UTgE title=Video width=560></iframe></div></div></div> <div class="svelte-1a8t81v block"><div class="svelte-1a8t81v block-name">Abstract</div> <div class=block-abstract-text>Why do large pre-trained transformer-based models perform so well across a wide variety of NLP tasks? Recent research suggests the key may lie in multi-headed attention mechanism's ability to learn and represent linguistic information. Understanding how these models represent both syntactic and semantic knowledge is vital to investigate why they succeed and fail, what they have learned, and how they can improve. We present Dodrio, an open-source interactive visualization tool to help NLP researchers and practitioners analyze attention mechanisms in transformer-based models with linguistic knowledge. Dodrio tightly integrates an overview that summarizes the roles of different attention heads, and detailed views that help users compare attention weights with the syntactic structure and semantic information in the input text. To facilitate the visual comparison of attention weights and linguistic knowledge, Dodrio applies different graph visualization techniques to represent attention weights with longer input text. Case studies highlight how Dodrio provides insights into understanding the attention mechanism in transformer-based models. Dodrio is available at <a href=https://poloclub.github.io/dodrio/ >https://poloclub.github.io/dodrio/</a>. </div></div> <div class="svelte-1a8t81v block citation-block"><div class="svelte-1a8t81v block-name">Citation</div> <div class="svelte-1a8t81v pub-title">Dodrio: Exploring Transformer Models with Interactive Visualization</div> <div class="svelte-1a8t81v pub-author"><a href=https://zijie.wang class=svelte-1a8t81v target=_self><div class="svelte-1a8t81v author citation"><div class="svelte-1a8t81v author-name citation">Zijie J. Wang</div> <div class=author-comma>,</div></div> </a><a href=https://www.linkedin.com/in/robert-turko/ class=svelte-1a8t81v target=_self><div class="svelte-1a8t81v author citation"><div class="svelte-1a8t81v author-name citation">Robert Turko</div> <div class=author-comma>,</div></div> </a><a href=https://www.cc.gatech.edu/~dchau class=svelte-1a8t81v target=_self><div class="svelte-1a8t81v author citation"><div class="svelte-1a8t81v author-name citation">Duen Horng (Polo) Chau</div> <div class=author-comma></div></div> </a></div> <div class="svelte-1a8t81v pub-venue"><a href=https://arxiv.org/abs/2103.14625 class=svelte-1a8t81v target=_self>arXiv:2103.14625 (arXiv), 2021</a></div> <div class="svelte-1a8t81v pub-icons"><a href=https://poloclub.github.io/dodrio/ class="svelte-1a8t81v icon-container" target=_self><div class="svelte-1a8t81v svg-icon"><svg class=svelte-1a8t81v viewBox="0 0 100 100"><use xlink:href=/sprite.svg#rocket-sharp></use></svg></div> <span class=svelte-1a8t81v>Demo</span></a> <a href=https://youtu.be/qB-T9j7UTgE class="svelte-1a8t81v icon-container" target=_self><div class="svelte-1a8t81v svg-icon"><svg class=svelte-1a8t81v viewBox="0 0 100 100"><use xlink:href=/sprite.svg#play-solid></use></svg></div> <span class=svelte-1a8t81v>Video</span></a> <a href=https://arxiv.org/abs/2103.14625 class="svelte-1a8t81v icon-container" target=_self><div class="svelte-1a8t81v svg-icon"><svg class=svelte-1a8t81v viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-pdf-solid></use></svg></div> <span class=svelte-1a8t81v>PDF</span></a> <div class="svelte-1a8t81v icon-container"><a href=https://github.com/poloclub/dodrio class="svelte-1a8t81v icon-container no-right-margin" target=_self><div class="svelte-1a8t81v svg-icon"><svg class=svelte-1a8t81v viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></div> <span class=svelte-1a8t81v>Code</span></a> <div class="svelte-1a8t81v star-container"><div style=display:flex>(<a href=https://github.com/poloclub/dodrio/stargazers class="svelte-1a8t81v svg-icon" target=_self style=font-weight:500;margin-right:-3px> loading </a>)</div></div></div> </div> <div class="svelte-1a8t81v bibtex"><pre class=svelte-1a8t81v>@article{wangDodrioExploringTransformer2021,
  title = {Dodrio: {{Exploring Transformer Models}} with {{Interactive Visualization}}},
  shorttitle = {Dodrio},
  author = {Wang, Zijie J. and Turko, Robert and Chau, Duen Horng},
  year = {2021},
  month = mar,
  url = {http://arxiv.org/abs/2103.14625},
  archiveprefix = {arXiv},
  eprint = {2103.14625},
  journal = {arXiv:2103.14625}
}</pre></div></div></div> </div> <div class=right-padding></div></div></main> <footer class=svelte-1pltrfa><div class=left-padding></div> <div class="svelte-1pltrfa footer-main"><div class="svelte-1pltrfa footer"><div class="svelte-1pltrfa footer-item"><span>Designed and built by <a href=. class="svelte-1pltrfa raleway">Jay Wang</a> with</span> <div class="svelte-1pltrfa svg-icon"><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#t-heart></use></svg></div> <span>using <a href=https://svelte.dev/ class=svelte-1pltrfa target=_self>Svelte</a> and <a href=https://sapper.svelte.dev/ class=svelte-1pltrfa target=_self>Sapper</a>.</span></div> <div class="svelte-1pltrfa footer-other"><div class=footer-icons><a href=cv class="svelte-1pltrfa svg-icon" target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#file-alt-regular></use></svg></a> <a href=https://github.com/xiaohk class="svelte-1pltrfa svg-icon" target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#github-alt-brands></use></svg></a> <a href="https://scholar.google.com/citations?user=eouAYvcAAAAJ&hl=en" class="svelte-1pltrfa svg-icon" target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#google-scholar></use></svg></a> <a href=http://twitter.com/jay4w class="svelte-1pltrfa svg-icon" target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#twitter-brands></use></svg></a> <a href=https://www.linkedin.com/in/zijiewang/ class="svelte-1pltrfa svg-icon" target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#linkedin-brands></use></svg></a> <a href=mailto:jayw@gatech.edu class="svelte-1pltrfa svg-icon" target=_self><svg class=svelte-1pltrfa viewBox="0 0 100 100"><use xlink:href=/sprite.svg#envelope-regular></use></svg></a></div> <div>© 2021 <a href=. class="svelte-1pltrfa raleway">Zijie Jay Wang</a></div></div></div></div> <div class=right-padding></div></footer></div> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,null,(function(a,b,c){return {curPub:{id:"dodrio",title:"Dodrio: Exploring Transformer Models with Interactive Visualization",authors:["Zijie J. Wang","Robert Turko","Duen Horng (Polo) Chau"],venue:"arXiv:2103.14625",venueURL:a,venueShort:"arXiv",year:2021,url:"\u002Fpapers\u002Fdodrio",pdf:a,repo:"poloclub\u002Fdodrio",showStar:b,video:"https:\u002F\u002Fyoutu.be\u002FqB-T9j7UTgE",demo:"https:\u002F\u002Fpoloclub.github.io\u002Fdodrio\u002F",abstract:"Why do large pre-trained transformer-based models perform so well across a\nwide variety of NLP tasks? Recent research suggests the key may lie in\nmulti-headed attention mechanism's ability to learn and represent linguistic\ninformation. Understanding how these models represent both syntactic and\nsemantic knowledge is vital to investigate why they succeed and fail, what\nthey have learned, and how they can improve. We present Dodrio, an\nopen-source interactive visualization tool to help NLP researchers and\npractitioners analyze attention mechanisms in transformer-based models with\nlinguistic knowledge. Dodrio tightly integrates an overview that summarizes\nthe roles of different attention heads, and detailed views that help users\ncompare attention weights with the syntactic structure and semantic\ninformation in the input text. To facilitate the visual comparison of\nattention weights and linguistic knowledge, Dodrio applies different graph\nvisualization techniques to represent attention weights with longer input\ntext. Case studies highlight how Dodrio provides insights into understanding\nthe attention mechanism in transformer-based models. Dodrio is available at\n\u003Ca href='https:\u002F\u002Fpoloclub.github.io\u002Fdodrio\u002F'\u003Ehttps:\u002F\u002Fpoloclub.github.io\u002Fdodrio\u002F\u003C\u002Fa\u003E. ",crownCaption:"The Dodrio user interface showing user exploration of connections between\nattention weights from a fine-tuned BERT model and syntactic dependencies as\nwell as semantic saliency scores on the SST2 dataset. (A) In the Dependency\nView, a user hovers over a word from the input sentence, highlighting its\nassociated dependency directed links as orange arcs (lighter is source;\ndarker is target). (B) Semantic Attention Graph highlights the word’s related\ntokens and their attentions; nodes are tokens (darker means more salient), a\ndirected edge encodes attention weight between two tokens.(C) The Attention\nHead Overview shows all attention heads in a multi-layer and multi-head model\nas a grid of circles, each head is (D) colored based on its linguistic\nknowledge in the model (more red → more semantic-aligned, more blue → more\nsyntactic-aligned; darker → more aligned), and sized based on its importance\nscore in the model (larger → more important)",bibtex:"@article{wangDodrioExploringTransformer2021,\n  title = {Dodrio: {{Exploring Transformer Models}} with {{Interactive Visualization}}},\n  shorttitle = {Dodrio},\n  author = {Wang, Zijie J. and Turko, Robert and Chau, Duen Horng},\n  year = {2021},\n  month = mar,\n  url = {http:\u002F\u002Farxiv.org\u002Fabs\u002F2103.14625},\n  archiveprefix = {arXiv},\n  eprint = {2103.14625},\n  journal = {arXiv:2103.14625}\n}"},people:{"Zijie J. Wang":{url:"https:\u002F\u002Fzijie.wang",isMe:b},"Anthony Gitter":{url:"https:\u002F\u002Fwww.biostat.wisc.edu\u002F~gitter"},"Melissa C. Skala":{url:"https:\u002F\u002Fmorgridge.org\u002Fresearch\u002Fmedical-engineering\u002Foptical-microscopy"},"Alex J. Walsh":{url:"https:\u002F\u002Fqoil.engr.tamu.edu"},"Duen Horng (Polo) Chau":{url:c},"Polo Chau":{url:c},"Fred Hohman":{url:"https:\u002F\u002Ffredhohman.com"},"Minsuk Kahng":{url:"https:\u002F\u002Fminsuk.com"},"Haekyu Park":{url:"https:\u002F\u002Fhaekyu.com"},"Nilaksh Das":{url:"https:\u002F\u002Fnilakshdas.com"},"Robert Turko":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Frobert-turko\u002F"},"Omar Shaikh":{url:"http:\u002F\u002Foshaikh.com\u002F"},"Michael Gleicher":{url:"http:\u002F\u002Fpages.cs.wisc.edu\u002F~gleicher\u002F"},"Yu Hen Hu":{url:"http:\u002F\u002Fhomepages.cae.wisc.edu\u002F~hu\u002F"},"Tiffany M. Heaster":{url:"https:\u002F\u002Fmorgridge.org\u002Fprofile\u002Ftiffany-heaster\u002F"},"Quan Yin":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fquan-yin\u002F"},"Emily Rogers":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Femily-rogers-1a828598"},"Robert Firstman":{url:"https:\u002F\u002Fwww.robfirstman.com\u002F"},"Scott Freitas":{url:"https:\u002F\u002Fwww.scottfreitas.com\u002F"},"Shang-Tse Chen":{url:"https:\u002F\u002Fwww.cc.gatech.edu\u002F~schen351\u002F"},"Jon Saad-Falcon":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fjonsaadfalcon\u002F"},"Austin P. Wright":{url:"https:\u002F\u002Faustinpwright.com\u002F"},"Sasha Richardson":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fsasha-richardson\u002F"},"Siwei Li":{url:"https:\u002F\u002Frsli.github.io\u002F"},"Zhiyan Zhou":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Ffrank-zhou-b19515159\u002F"},"Anish Upadhayay":{url:"https:\u002F\u002Fgithub.com\u002Faupadhayay3"},"Susanta Routray":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fsusantaroutray\u002F"},"Matthew Hull":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fmdhull\u002F"},"Liang Gou":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Flianggou\u002F"},"Grace Guo":{url:"https:\u002F\u002Fgracegsy.github.io\u002F"},"Fabian Sperrle":{url:"https:\u002F\u002Fwww.vis.uni-konstanz.de\u002Fmitglieder\u002Fsperrle\u002F"},"Mennatallah El-Assady":{url:"https:\u002F\u002Fel-assady.com\u002F"},"Alex Endert":{url:"https:\u002F\u002Fva.gatech.edu\u002Fendert\u002F"},"Daniel Keim":{url:"https:\u002F\u002Fwww.vis.uni-konstanz.de\u002Fen\u002Fmembers\u002Fkeim"},"Anindya S. Paul":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fanindyasankar\u002F"},"Pruthvi Perumalla":{url:"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fpruthvi-perumalla\u002F"},"Dongjin Choi":{url:"https:\u002F\u002Fwww.jinchoi.xyz"},"Shenyu Xu":{url:"https:\u002F\u002Fthomasxu2009.github.io"},"Diyi Yang":{url:"https:\u002F\u002Fwww.cc.gatech.edu\u002F~dyang888\u002F"}}}}("https:\u002F\u002Farxiv.org\u002Fabs\u002F2103.14625",true,"https:\u002F\u002Fwww.cc.gatech.edu\u002F~dchau"))]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');(function(){try{eval("async function x(){}");var main="/client/client.53600047.js"}catch(e){main="/client/legacy/client.9fac1354.js"};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src=main;s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@1.0.1.js";s.setAttribute("data-main",main);}document.head.appendChild(s);}());</script> 